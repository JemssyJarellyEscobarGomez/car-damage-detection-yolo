{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga librer铆as</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import sklearn\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalaci贸n de herramientas de etiquetado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n para instalar los paquetes\n",
    "def package_verification(package):\n",
    "    try:\n",
    "        output = os.popen('pip list').read()\n",
    "        return f'{package}' in output\n",
    "    except Exception as e:\n",
    "        print(f'Error en la verificaci贸n: {e}')\n",
    "        return False\n",
    "\n",
    "def package_installation(package_name):\n",
    "    if package_verification(package_name):\n",
    "        print(f\"El paquete '{package_name}' ya est谩 instalado. \")\n",
    "    else:\n",
    "        print('Instalando el paquete... ')\n",
    "        try:\n",
    "            os.system(f'pip install {package_name}')\n",
    "            print(f'libreria {package_name} instalada correctamente! ')\n",
    "        except Exception as e:\n",
    "            print(f'Error en la instalaci贸n de {package_name}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('labelme') # Instalaci贸n de la herramienta de etiquetado Labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir la herramienta para el proceso de etiquetado \n",
    "try:\n",
    "    subprocess.check_call([\"labelme\"]) \n",
    "except Exception as e:\n",
    "    print(f'No fue posible abrir labelme: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('labelme2yolo') # Instalaci贸n de la herramienta de conversi贸n para el formato JSON de labelme a formato texto requerido por los modelos de detecci贸n de objetos YOLO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga rutas</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder= os.getcwd() # Obtener ubicaci贸n actual\n",
    "main_folder= os.path.abspath(os.path.join(current_folder, \"../../../\")) # Carpeta main del proyecto\n",
    "main_staticos= os.path.abspath(os.path.join(main_folder))+'\\\\dist' # Carpeta main de los archivos estaticos\n",
    "main_production= os.path.abspath(main_folder) +'\\\\src' # Carpeta main de los archivos listos para producci贸n \n",
    "dir_prueba= os.path.abspath(main_folder) + \"\\\\src\\\\assets\"  # Carpeta de imagenes prueba para el proceso de predecir\n",
    "\n",
    "training_structure=\"lote2_2\" # Indica el nombre de la carpeta que tiene los archivos para el entrenamiento (image, json)\n",
    "dir_train= os.path.abspath(main_staticos) + f'\\\\{training_structure}' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuraci贸n de rutas de entrenamiento</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos de entrenamiento: 399\n",
      "Cantidad de archivos de validaci贸n: 98\n"
     ]
    }
   ],
   "source": [
    "# Funci贸n para separar la carpeta global de todos los datos en un 80% entrenamiento y 20% validaci贸n. Utilice esta funci贸n solo si no ha ordenado los datos en una carpeta para entrenamiento y otra para validaci贸n.\n",
    "\n",
    "def file_separation(orig_folder):\n",
    "    file_list = os.listdir(orig_folder)\n",
    "    train, val = train_test_split(file_list, test_size=0.2, random_state=100)\n",
    "    if not os.path.exists(\"train\"):\n",
    "        train_path = os.path.join(orig_folder, \"train\")\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "    move_files(train, orig_folder, train_path)\n",
    "    \n",
    "    if not os.path.exists(\"val\"):\n",
    "        val_path = os.path.join(orig_folder, \"val\")\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "    move_files(val, orig_folder, val_path)\n",
    "\n",
    "def move_files(file_list, orig_folder, dest_folder):\n",
    "    for file in file_list:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            orig_image_path = os.path.join(orig_folder, file)\n",
    "            json_name = os.path.splitext(file)[0] + \".json\"\n",
    "            \n",
    "            orig_json_path = os.path.join(orig_folder, json_name)\n",
    "            dest_image_path = os.path.join(dest_folder, file)\n",
    "            dest_json_path = os.path.join(dest_folder, json_name)\n",
    "            \n",
    "            shutil.copy(orig_image_path, dest_image_path)\n",
    "            shutil.copy(orig_json_path, dest_json_path)\n",
    "\n",
    "file_separation(dir_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Conversi贸n a formato YOLO</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversi贸n completada para la carpeta c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\lote2_2\\train\n",
      "Conversi贸n completada para la carpeta c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\lote2_2\\val\n"
     ]
    }
   ],
   "source": [
    "# Funci贸n para convertir la carpeta de entrenamiento y validaci贸n en formato YOLO\n",
    "\n",
    "def convert_to_yolo_format(training_directory, validation_directory):\n",
    "    try:\n",
    "        subprocess.check_call([\"labelme2yolo\", \"--json_dir\", training_directory])\n",
    "        print(f'Conversi贸n completada para la carpeta {training_directory}')\n",
    "        subprocess.check_call([\"labelme2yolo\", \"--json_dir\", validation_directory])\n",
    "        print(f'Conversi贸n completada para la carpeta {validation_directory}')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar funci贸n labelme2yolo: {e}')\n",
    "\n",
    "train_path= os.path.abspath(dir_train) + \"\\\\train\"\n",
    "val_path= os.path.abspath(dir_train) + \"\\\\val\"\n",
    "\n",
    "convert_to_yolo_format(train_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizaci贸n de la estructura del repositorio YOLODataset (resultado de la conversi贸n .json a formato YOLO) creado por defecto\n",
    "\n",
    "def reorganization(path):\n",
    "    try:\n",
    "        new_path = os.path.abspath(os.path.join(path, \"YOLODataset\"))\n",
    "        main_folders = os.listdir(new_path)\n",
    "        for folder_instance in main_folders:\n",
    "            secondary_folder_path = os.path.join(new_path, folder_instance)\n",
    "            if os.path.isdir(secondary_folder_path):\n",
    "                secondary_folders = os.listdir(secondary_folder_path)\n",
    "                for secondary_folder in secondary_folders:\n",
    "                    subfolder_secondary_path = os.path.join(secondary_folder_path, secondary_folder)\n",
    "                    try:\n",
    "                        if os.listdir(subfolder_secondary_path) != []:\n",
    "                            for file in os.listdir(subfolder_secondary_path):\n",
    "                                orig_path = os.path.join(subfolder_secondary_path, file)\n",
    "                                dest_path = os.path.abspath(os.path.join(subfolder_secondary_path, \"../\"))\n",
    "                                new_dest_path = os.path.join(dest_path, file)\n",
    "                                shutil.move(orig_path, new_dest_path)\n",
    "                            os.rmdir(subfolder_secondary_path)\n",
    "                        else:\n",
    "                            os.rmdir(subfolder_secondary_path)\n",
    "                    except NotADirectoryError as e:\n",
    "                        print(f'Error: the element is not a folder: {e}')\n",
    "        return new_path\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "yolo_train_data= reorganization(train_path)\n",
    "yolo_val_data= reorganization(val_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpetas movidas exitosamente a c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion \n"
     ]
    }
   ],
   "source": [
    "# Funci贸n para mover las carpetas yolo \n",
    "\n",
    "def acomodar_rutas_dataset(main_staticos, dataset_train, dataset_val):\n",
    "    try:\n",
    "        if not os.path.exists(\"data_afectacion\"):\n",
    "            try: \n",
    "                paths_segmentation= os.path.join(main_staticos, \"data_afectacion\")\n",
    "                os.makedirs(paths_segmentation, exist_ok=True)\n",
    "                if os.listdir(paths_segmentation) == []:\n",
    "                    shutil.move(dataset_train, os.path.join(paths_segmentation, \"YOLODataset_train\"))\n",
    "                    shutil.move(dataset_val, os.path.join(paths_segmentation, \"YOLODataset_val\"))\n",
    "                    print(f'Carpetas movidas exitosamente a {paths_segmentation} ')\n",
    "                else:\n",
    "                    print(f'Las carpetas ya se encuentran en {paths_segmentation} ')\n",
    "            except OSError as e:\n",
    "                print(f'Error al intentar crear la carpeta en {paths_segmentation}: {e}')\n",
    "        return paths_segmentation  \n",
    "    except TypeError as e:\n",
    "        print(f'Tipo de dato incorrecto para el argumento: {e}')\n",
    "\n",
    "segmentation_routes= acomodar_rutas_dataset(main_staticos, yolo_train_data, yolo_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set de funciones para ordenar la estructura de los dataset individuales.\n",
    "\n",
    "def arrange_dataset_paths(train, val):\n",
    "    destination = os.path.abspath(os.path.join(train, \"../../\"))\n",
    "    shutil.move(train, destination)\n",
    "    if \"dataset.yaml\" in os.listdir(os.path.join(val, \"../\")):\n",
    "        os.remove(val)\n",
    "\n",
    "# Funci贸n para reescribir el dataset\n",
    "def rewrite_dataset(dir_train_converted, combined_list):\n",
    "    with open(dir_train_converted, 'w') as new_dataset:\n",
    "        new_dataset.write(\n",
    "            f'train: {os.path.abspath(os.path.join(dir_train_converted, \"../\"))}\\n'\n",
    "            f'val: {os.path.abspath(os.path.join(dir_train_converted, \"../../\"))}\\\\YOLODataset_val\\n'\n",
    "            'test: \\n'\n",
    "            f'nc: {len(combined_list)}\\n'\n",
    "            f'names: {combined_list}\\n'\n",
    "        )\n",
    "        \n",
    "# Funci贸n para combinar los dos dataset generados\n",
    "def total_labels(list1, list2, update_dataset_train):\n",
    "    set1=set(list1)\n",
    "    set2=set(list2)\n",
    "    union_without_repeating = set1.union(set2)\n",
    "    combined_list = list(union_without_repeating)\n",
    "    rewrite_dataset(update_dataset_train, combined_list)\n",
    "\n",
    "# Funci贸n para extraer los nombres de las etiquetas de los dos dataset separados\n",
    "def extract_labels(main_route):\n",
    "    try:\n",
    "        route_dataset_train= os.path.abspath(main_route) + \"\\\\YOLODataset_train\\\\dataset.yaml\"\n",
    "        route_dataset_val= os.path.abspath(main_route) + \"\\\\YOLODataset_val\\\\dataset.yaml\"\n",
    "        \n",
    "        with open(route_dataset_train, 'r') as file_train:\n",
    "            data_train = yaml.safe_load(file_train)\n",
    "            labels_train = data_train['names']\n",
    "        with open(route_dataset_val,'r') as file_val:\n",
    "            data_val= yaml.safe_load(file_val)\n",
    "            labels_val= data_val['names']\n",
    "        total_labels(labels_train, labels_val, route_dataset_train)\n",
    "        \n",
    "        return route_dataset_train, route_dataset_val\n",
    "    except (TypeError, FileNotFoundError) as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "try:\n",
    "    train, val= extract_labels(segmentation_routes)\n",
    "    arrange_dataset_paths(train, val)\n",
    "except TypeError as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar la carpeta que contiene la configuraci贸n completa para el entrenamiento\n",
    "data_train= os.path.abspath(main_staticos) + \"\\\\data_afectacion\\\\dataset.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Selecci贸n versi贸n de modelo YOLOv8</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificaci贸n de las rutas de las carpetas predeterminadas de ultralytics YOLO\n",
    "\n",
    "def set_config_ultralytics(main):\n",
    "    settings.update({'datasets_dir': f'{main}\\\\dist', 'weights_dir': f'{main}\\\\src', 'runs_dir': f'{main}\\\\src\\\\runs'})\n",
    "set_config_ultralytics(main_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Modelo original</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de variantes en la detecci贸n de objetos con YOLOv8\n",
    "\n",
    "| Modelo      | Nombres de archivo                                      | Identificador |\n",
    "|-------------|-----------------------------------------------------|------------|\n",
    "| YOLOv8      | yolov8n.pt yolov8s.pt yolov8m.pt yolov8l.pt yolov8x.pt | n, s, m, l, x |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('gdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se est谩 utilizando la versi贸n \"yolov8x-seg.pt\" del modelo. \n"
     ]
    }
   ],
   "source": [
    "def get_model_version():\n",
    "    available_versions= ['n', 's', 'm', 'l', 'x'] # yolov8n.pt , yolov8s.pt , yolov8m.pt , yolov8l.pt , yolov8x.pt\n",
    "    control= True\n",
    "    while control:\n",
    "        version_selection= input(\"Ingrese la versi贸n del modelo que desea utilizar, entre las disponibles est谩n: n, s, m, l, x. Advertencia: Si no desea instalar ninguna ingrese la palabra 'salir'! \") \n",
    "        if version_selection in available_versions:\n",
    "            id_version= f'yolov8{version_selection}-seg.pt' \n",
    "            return id_version\n",
    "        elif version_selection == \"salir\":\n",
    "            control=False\n",
    "            return None\n",
    "        else:\n",
    "            print('Version de modelo inexistente, ingrese nuevamente! ')\n",
    "     \n",
    "def model_installation(url, version_name):\n",
    "    try:\n",
    "        path_save = os.path.abspath(main_folder) + \"\\\\dist\\\\model_version\\\\\" + version_name\n",
    "        if os.path.exists(path_save):\n",
    "            print(f'Se est谩 utilizando la versi贸n \"{version_name}\" del modelo. ')\n",
    "        else:\n",
    "            url_installation = f'{url}/{version_name}'\n",
    "            gdown.download(url_installation, path_save, quiet=False)\n",
    "            print('Versi贸n instalada correctamente!')\n",
    "    except (NameError, UnboundLocalError) as e:\n",
    "        print(f'Error en la instalaci贸n de la versi贸n del modelo: {e}')\n",
    "    return path_save\n",
    "\n",
    "model_url= 'https://github.com/ultralytics/assets/releases/download/v0.0.0' \n",
    "model_version= get_model_version()\n",
    "\n",
    "if model_version is not None:\n",
    "    model_orig= model_installation(model_url, model_version) \n",
    "else:\n",
    "    print('Ha salido con exito! ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Modelo entrenado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los pesos del experimento que se van a utilizar son c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_segmentacion\\segmentacion\\pruebaEntrenamiento\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Funci贸n para obtener el 煤ltimo entrenamiento\n",
    "\n",
    "def get_last_training(dir_src):\n",
    "    try:\n",
    "        yolo_model_folders= os.listdir(dir_src)\n",
    "        for folder_name in yolo_model_folders:\n",
    "            if folder_name == \"segmentacion\":\n",
    "                base_path = os.path.abspath(os.path.join(dir_src, folder_name))\n",
    "                files= os.listdir(base_path)\n",
    "                last_experiment = sorted(files)[-1]\n",
    "                return os.path.join(base_path, last_experiment, \"weights\", \"best.pt\")\n",
    "        return None\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "version= \"srcv3\"\n",
    "dir_model_version=os.path.abspath(os.path.join(main_production, version)+ \"\\\\modelo_segmentacion\")\n",
    "model_train= get_last_training(dir_model_version) \n",
    "\n",
    "if model_train:\n",
    "    print(f'Los pesos del experimento que se van a utilizar son {model_train}')\n",
    "else:\n",
    "    print(f'No existe ning煤n experimento de entrenamiento en la carpeta {dir_model_version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalaci贸n de recursos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('ultralytics') # Instalaci贸n de la biblioteca Ultralytics\n",
    "#ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarjeta Grafica: Caption                  \n",
      "\n",
      "AMD Radeon(TM) Graphics.\n",
      " \n",
      "Advertencia: Debe utilizar la CPU para instalaci贸n de PyTorch! \n"
     ]
    }
   ],
   "source": [
    "#Funci贸n para determinar si tiene GPU Cuda para instalaci贸n de PYTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'CUDA: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    try:\n",
    "        command = 'wmic path win32_videocontroller get caption'\n",
    "        device = subprocess.check_output(command, shell=True, universal_newlines=True)\n",
    "        print(f'Tarjeta Grafica: {device.strip()}.\\n \\nAdvertencia: Debe utilizar la CPU para instalaci贸n de PyTorch! ')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar el comando: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Direcci贸n para instalar mediante el comando la versi贸n de PyTorch en funci贸n de los requerimientos computacionales: </span>[Versi贸n PyTorch](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_pytorch = 'pip3 install torch torchvision torchaudio' # Comando de instalaci贸n seg煤n la version personalizada a sus requerimientos computacionales # idear solucion mas amena al cliente\n",
    "substrings = command_pytorch.split(\" \")\n",
    "try:\n",
    "    subprocess.check_call(substrings)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f'Error al instalar la version de PyTorch: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">ENTRENAMIENTO</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.17 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.220  Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\model_version\\yolov8n-seg.pt, data=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\dataset.yaml, epochs=30, patience=30, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=1, project=segmentacion, name=pruebaEntrenamiento4, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=1, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=segmentacion\\pruebaEntrenamiento4\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004470  ultralytics.nn.modules.head.Segment          [2, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3264006 parameters, 3263990 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA not detected, using default CPU batch-size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_train\\labels... 199 images, 0 backgrounds, 0 corrupt: 100%|| 199/199 [00:00<00:00, 235.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_val\\labels... 49 images, 0 backgrounds, 0 corrupt: 100%|| 49/49 [00:00<00:00, 295.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_val\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to segmentacion\\pruebaEntrenamiento4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1msegmentacion\\pruebaEntrenamiento4\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      2.114      4.487      3.576      1.754        100        640: 100%|| 13/13 [02:19<00:00, 10.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00607      0.545     0.0342     0.0101    0.00247      0.303    0.00608    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.977      3.851      2.991      1.633         75        640: 100%|| 13/13 [02:04<00:00,  9.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00722      0.596     0.0456     0.0151    0.00304      0.267    0.00374   0.000882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.946      3.587      2.824       1.63         61        640: 100%|| 13/13 [02:08<00:00,  9.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00696      0.593     0.0222    0.00819    0.00263      0.218    0.00265   0.000637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.908      3.491      2.688      1.582         94        640: 100%|| 13/13 [02:03<00:00,  9.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0685     0.0922     0.0426      0.015     0.0339     0.0353      0.012    0.00192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G      1.944      3.507      2.554      1.578         93        640: 100%|| 13/13 [02:08<00:00,  9.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235       0.64     0.0652     0.0456     0.0141      0.586     0.0435     0.0182    0.00392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G      1.976      3.461      2.542      1.569        123        640: 100%|| 13/13 [02:13<00:00, 10.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0531       0.16     0.0218    0.00782     0.0379     0.0217    0.00692    0.00152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.963      3.455      2.523      1.586         76        640: 100%|| 13/13 [02:11<00:00, 10.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.219      0.111     0.0727     0.0226     0.0243     0.0217     0.0163    0.00478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G      1.994      3.408      2.486      1.571        127        640: 100%|| 13/13 [02:11<00:00, 10.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.105      0.103     0.0442     0.0162     0.0991     0.0705     0.0152    0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.929      3.396      2.422      1.543        105        640: 100%|| 13/13 [02:09<00:00,  9.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.102       0.13     0.0404     0.0147     0.0311     0.0591    0.00873    0.00232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G        1.9      3.292      2.417      1.548        106        640: 100%|| 13/13 [02:28<00:00, 11.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:12<00:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0715      0.118     0.0441     0.0163     0.0476     0.0455    0.00814    0.00202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G       1.86      3.164      2.356      1.514         61        640: 100%|| 13/13 [02:15<00:00, 10.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.154      0.113     0.0761     0.0254     0.0718     0.0511    0.00985    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G       1.94      3.168      2.351      1.562        142        640: 100%|| 13/13 [02:15<00:00, 10.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:12<00:00,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.145      0.166     0.0792     0.0315      0.144     0.0829     0.0345    0.00648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G      1.862      3.171      2.278      1.495         75        640: 100%|| 13/13 [02:11<00:00, 10.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:12<00:00,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235       0.13      0.268     0.0911     0.0372      0.102     0.0773     0.0344    0.00821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.807      3.116      2.162      1.452        140        640: 100%|| 13/13 [02:09<00:00,  9.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.192      0.215      0.117     0.0472     0.0987      0.113     0.0429     0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.788      3.053      2.098      1.447        121        640: 100%|| 13/13 [02:14<00:00, 10.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.249       0.15      0.099     0.0353      0.219     0.0752     0.0474     0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.771      3.071      2.125      1.466         93        640: 100%|| 13/13 [02:08<00:00,  9.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.216      0.224       0.11     0.0407      0.109      0.112     0.0385     0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.754      3.004      2.051      1.405         65        640: 100%|| 13/13 [02:14<00:00, 10.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.176      0.156     0.0993     0.0462      0.162     0.0726     0.0439     0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.738      3.028      2.021        1.4        137        640: 100%|| 13/13 [02:11<00:00, 10.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.151       0.18      0.093      0.042      0.122     0.0834     0.0431     0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.689      2.897      1.991      1.386         78        640: 100%|| 13/13 [02:09<00:00,  9.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:12<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.224      0.197      0.128     0.0594      0.199      0.116     0.0718     0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.729      2.909      2.014      1.393         53        640: 100%|| 13/13 [02:07<00:00,  9.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.257      0.232      0.142     0.0549      0.181      0.181     0.0708     0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G      1.808      2.967      2.239      1.483         34        640: 100%|| 13/13 [01:59<00:00,  9.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.171      0.145      0.105     0.0442      0.124      0.094     0.0391     0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.746      2.866      2.135       1.44         59        640: 100%|| 13/13 [01:59<00:00,  9.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.217       0.18      0.115     0.0497      0.131     0.0967     0.0437      0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G      1.705      2.897      2.078       1.45         28        640: 100%|| 13/13 [01:55<00:00,  8.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.279      0.172      0.144     0.0621      0.209      0.149     0.0806     0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.677      2.766       2.04      1.431         28        640: 100%|| 13/13 [01:57<00:00,  9.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.221      0.232      0.149     0.0707      0.162      0.157     0.0897     0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.623        2.7      1.961      1.374         55        640: 100%|| 13/13 [02:00<00:00,  9.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.255      0.257      0.186     0.0816      0.326      0.157      0.123     0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G      1.608      2.732      1.886      1.362         52        640: 100%|| 13/13 [01:57<00:00,  9.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:10<00:00,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.227      0.303      0.186     0.0918      0.164      0.197        0.1     0.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G       1.61      2.648      1.897      1.351         53        640: 100%|| 13/13 [02:00<00:00,  9.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.248      0.265      0.175     0.0822      0.244      0.162      0.126     0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G      1.602      2.684      1.841      1.354         82        640: 100%|| 13/13 [01:59<00:00,  9.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.282      0.239      0.186     0.0785      0.231      0.138     0.0888     0.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G      1.542      2.611      1.792       1.34         32        640: 100%|| 13/13 [01:55<00:00,  8.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.309      0.243      0.191     0.0709        0.2      0.149      0.083     0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G      1.524       2.52      1.736      1.307         35        640: 100%|| 13/13 [01:54<00:00,  8.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:11<00:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.282      0.289      0.205     0.0776      0.181      0.175      0.086     0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 1.160 hours.\n",
      "Optimizer stripped from segmentacion\\pruebaEntrenamiento4\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from segmentacion\\pruebaEntrenamiento4\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating segmentacion\\pruebaEntrenamiento4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.220  Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:09<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.226      0.303      0.186     0.0919      0.252       0.13      0.108     0.0408\n",
      "Speed: 2.0ms preprocess, 101.1ms inference, 0.0ms loss, 8.4ms postprocess per image\n",
      "Results saved to \u001b[1msegmentacion\\pruebaEntrenamiento4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --Inicio Men煤\n",
    "while True:\n",
    "    try:\n",
    "        model_type = input('Qu茅 tipo de modelo desea utilizar, indique \"original\" o \"entrenado\": ')\n",
    "        if model_type == \"original\":\n",
    "            model_segmentation = YOLO(model_orig)\n",
    "            break  # Sale del bucle si la entrada es v谩lida\n",
    "        elif model_type == \"entrenado\":\n",
    "            model_segmentation = YOLO(model_train) \n",
    "            break  # Sale del bucle si la entrada es v谩lida\n",
    "        else:\n",
    "            print('Caracter no valido! Intente nuevamente.')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "# --Finalizaci贸n Men煤\n",
    "\n",
    "PROJECT='segmentacion' # Permite asignar un nombre al directorio de inicio que contendr谩 los experimentos de segmentaci贸n de objetos, y debe estar entre comillas; se recomienda no utilsizar espacios en el nombre.\n",
    "NAME='pruebaEntrenamiento' # El nombre del experimento entrenamiento para segmentaci贸n de instancias debe ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice alg煤n formato de nombres como camelCase, snake_case o PascalCase.\n",
    "TASK='segment' # Define la tarea principal que desea realizar con el modelo YOLO v8; en este caso, la segmentaci贸n implica el uso de m谩scaras para identificar objetos individuales en una imagen y segmentarlos del resto de la imagen.\n",
    "IMGSZ=640 # Establezca las dimensiones en p铆xeles de la imagen de entrada. Puede especificarlo como un n煤mero entero, como imgsz a 640 para obtener un cuadrado perfecto, o como una tupla, como imgsz=(640,480) para establecer dimensiones espec铆ficas de ancho y alto. Se recomienda ajustar este valor seg煤n el tama帽o del objeto que desea segmentar. Para la segmentaci贸n de objetos peque帽os, se recomienda aumentar el valor a m谩s de 640 p铆xeles para obtener una resoluci贸n m谩s alta.\n",
    "DATA= data_train # Le permite indicar la ruta al archivo que contiene los metadatos que utilizara el modelo segmentaci贸n de objetos y su configuraci贸n en formato YAML. Si especifica el valor data=None, el conjunto de datos coco128-seg.yaml se utiliza de forma predeterminada; de lo contrario, escriba la ruta al archivo YAML entre comillas utilizando barras diagonales (/) en lugar de barras invertidas (\\).\n",
    "EPOCHS=30 # Establezca el n煤mero de 茅pocas del modelo YOLO v8 en la tarea de segmentaci贸n. Este valor representa el n煤mero total de iteraciones en todo el conjunto de datos de entrenamiento. Se recomienda experimentar con este par谩metro dependiendo de la cantidad de im谩genes disponibles. Si tiene un conjunto de datos grande, considere aumentar este valor por encima de 30 para obtener mejores resultados. Por otro lado, establecer epochs=None har谩 que el modelo contin煤e entren谩ndose hasta que la p茅rdida de validaci贸n deje de mejorar.\n",
    "BATCH=-1 # Define la cantidad de im谩genes procesadas simult谩neamente en una iteraci贸n del modelo YOLO v8 en la segmentaci贸n. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta autom谩ticamente el tama帽o del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del par谩metro como un n煤mero entero.\n",
    "OPTIMIZER='auto' # Define el algoritmo de optimizaci贸n para el modelo de segmentaci贸n YOLO. Su elecci贸n ajusta los pesos del modelo durante el entrenamiento y es crucial para la velocidad y rendimiento. Puede tomar valores como 'SGD', 'Adam', 'Adamax', 'AdamW', 'NAdam', 'RAdam', 'RMSProp' y 'auto', este 煤ltimo selecciona autom谩ticamente el optimizador m谩s adecuado a la tarea segmentaci贸n de objetos.\n",
    "WORKERS=1 # Especifica la cantidad de subprocesos o n煤cleos utilizados para cargar datos en el modelo segmentaci贸n YOLO. Se recomienda ajustar la cantidad de subprocesos a la cantidad de n煤cleos de CPU disponibles en el sistema.\n",
    "DEVICE= 'cpu' # Especifica el dispositivo de ejecuci贸n para la versi贸n del modelo yolov8 en la operaci贸n de segmentaci贸n. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el par谩metro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el n煤mero representa el identificador de la GPU disponible en el sistema. Tambi茅n es posible utilizar m煤ltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generaci贸n de gr谩ficos que permite visualizar y monitorear la p茅rdida y la precisi贸n durante el entrenamiento de segmentaci贸n de objetos. Establecer plots=True activara la funci贸n; si desea desactivarla, establezca el valor del hiperpar谩metro en False.\n",
    "SAVE=False # Cuando se establece en True, el modelo guarda puntos de control peri贸dicamente durante el entrenamiento de segmentaci贸n. Se recomienda tener cuidado al establecer este valor en Verdadero, ya que est谩 relacionado con el hiperpar谩metro SAVE_PERIOD; si establece el valor del hiperparametro a False, la funci贸n Save_Period se desactivar谩.\n",
    "SAVE_PERIOD=-1 # Se utiliza para especificar con qu茅 frecuencia se guardan los puntos de control durante el entrenamiento de segmentaci贸n. Si se establece en un valor mayor que 0, el modelo guardar谩 puntos de control cada n煤mero especificado de 茅pocas. Sin embargo, si save_period se establece en -1, significa que la funci贸n esta deshabilitada.\n",
    "PATIENCE=30 # Representa el n煤mero esperado de 茅pocas durante el entrenamiento de segmentaci贸n. Si no se observa mejora en el conjunto de validaci贸n dentro de un per铆odo espec铆fico, se detiene el proceso. Esta t茅cnica de parada temprana se utiliza para evitar el sobreajuste del modelo. Se recomienda ajustar este hiperpar谩metro en funci贸n de la duraci贸n esperada del entrenamiento.\n",
    "VERBOSE=False # Se utiliza para controlar el n煤mero de impresiones durante la ejecuci贸n del entrenamiento de segmentaci贸n. Para suprimir la salida de informaci贸n b谩sica 煤nicamente, debe establecer el valor del hiperpar谩metro en False, pero si desea una salida de progreso m谩s detallada, establezca el valor en True.\n",
    "RECT= False # Habilita la formaci贸n rectangular en cada lote, redimensionando las im谩genes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de entrenamiento en la segmentaci贸n de instancias. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente lote.\n",
    "COS_LR=False # Reemplaza el decaimiento escalonado predeterminado de YOLOv8, que reduce la tasa de aprendizaje en ciertas 茅pocas, con el decaimiento escalonado cos_lr. Este ajusta la tasa de aprendizaje seg煤n las 茅pocas restantes y la tasa de aprendizaje inicial, proporcionando una disminuci贸n m谩s suave. Establezca este hiperpar谩metro en True para una reducci贸n gradual de la tasa de aprendizaje, de lo contrario establezca en False.\n",
    "FRACTION= 1.0 # Controla la fracci贸n del conjunto de datos que se utilizara para el entrenamiento de segmentaci贸n. Debes establecer este par谩metro entre 0.0 y 1.0. Por defecto, cuando es 1.0, se emplea el 100% de las im谩genes disponibles en el conjunto de datos.\n",
    "EXIST_OK=False # Controla la sobreescritura de un experimento de segmentaci贸n existente. Cuando se establece en False, el sistema no sobrescribir谩, en su lugar devolver谩 una ruta incrementada. Esto es 煤til para prevenir la sobreescritura accidental de experimentos anteriores. Para activar la funci贸n, asigna el valor True.\n",
    "OVERLAP_MASK=True # Determina si las m谩scaras que representan 谩reas de inter茅s en la imagen deben superponerse. Establecer el valor del hiperparametro a True permite que estas m谩scaras compartan 谩reas, lo que significa que los l铆mites de los objetos en la imagen puede coincidir parcialmente. Esta opci贸n ahorra memoria, acelera el entrenamiento, y es especialmente 煤til para grandes conjuntos de datos o modelos complejos.\n",
    "MASK_RATIO=1 # Configure la reducci贸n de muestreo para la m谩scara de segmentaci贸n. Se sugiere fijar el valor en el rango de 1 para entrenamiento en resoluci贸n nativa, ideal para aplicaciones que demandan alta precisi贸n, hasta 4 para una reducci贸n en un factor de 4, acelerando el entrenamiento con una precisi贸n aceptable y ahorrando memoria. Este hiperpar谩metro solo acepta valores enteros.\n",
    "try:\n",
    "    model_segmentation.train(project=PROJECT,name=NAME, task=TASK, data=DATA, imgsz=IMGSZ, epochs=EPOCHS, batch=BATCH, workers=WORKERS, device=DEVICE, plots=PLOTS, verbose=VERBOSE, rect=RECT, cos_lr=COS_LR, optimizer=OPTIMIZER, patience=PATIENCE, exist_ok=EXIST_OK, overlap_mask=OVERLAP_MASK, mask_ratio=MASK_RATIO, fraction=FRACTION)\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train= get_last_training(dir_model_version) # Llamado a la funci贸n que selecciona el 煤ltimo modelo entrenado por si acaso no se proporciona\n",
    "print(model_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">Configuraci贸n para la exportaci贸n</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px;\">A continuaci贸n se muestra una tabla de referencia para exportar un modelo YOLOv8 entrenado en la tarea segmentaci贸n de instancias. Tenga en cuenta que configurar el par谩metro de `format` es fundamental para el proceso de exportaci贸n. Antes de continuar, aseg煤rese de verificar y ajustar estos valores a sus requisitos espec铆ficos: </span>\n",
    "\n",
    "| Formatos                                                             | Asignaci贸n | Extensi贸n                     | Hyperpar谩metros                                            | Descripci贸n                                        |\n",
    "|--------------------------------------------------------------------|-------------------|---------------------------|-----------------------------------------------------|----------------------------------------------------|\n",
    "| [PyTorch](https://pytorch.org/)                                    | -                 | `yolov8n.pt`              | -                                                   | Modelo en formato PyTorch                           |\n",
    "| [TorchScript](https://pytorch.org/docs/stable/jit.html)            | \"torchscript\"     | `yolov8n.torchscript`     | `imgsz`, `optimize`                                 | Simplifica la implementaci贸n de modelos PyTorch en entornos de producci贸n y aplicaciones eficientes, mejorando la portabilidad y el rendimiento al permitir ejecutar una representaci贸n intermedia en entornos sin Python.                       |\n",
    "| [ONNX](https://onnx.ai/)                                           | \"onnx\"            | `yolov8n.onnx`            | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     | Desarrollado para promover la interoperabilidad, la optimizaci贸n del hardware y la colaboraci贸n entre comunidades, al tiempo que responde a la necesidad de portabilidad de los modelos entre distintos marcos y herramientas de aprendizaje autom谩tico.                              |\n",
    "| [OpenVINO](https://docs.openvino.ai/latest/index.html)             | \"openvino\"        | `yolov8n_openvino_model/` | `imgsz`, `half`, `int8`                             | Elaborado para promover la interoperabilidad, la optimizaci贸n del hardware y el despliegue eficiente de modelos a trav茅s de diferentes marcos y herramientas de aprendizaje autom谩tico, con especial atenci贸n a las plataformas de hardware Intel.                     |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt)                  | \"engine\"          | `yolov8n.engine`          | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` | Permite promover la interoperabilidad, la optimizaci贸n del hardware y la implantaci贸n eficiente de modelos en distintos marcos y herramientas de aprendizaje autom谩tico, con especial atenci贸n a las plataformas de hardware de NVIDIA.                     |\n",
    "| [CoreML](https://github.com/apple/coremltools)                     | \"coreml\"          | `yolov8n.mlpackage`       | `imgsz`, `half`, `int8`, `nms`                      | Posibilita promover la interoperabilidad, la optimizaci贸n del hardware y el despliegue eficiente de modelos a trav茅s de diferentes marcos y herramientas de aprendizaje autom谩tico, con especial atenci贸n a las plataformas de hardware de Apple.                            |\n",
    "| [TF SavedModel](https://www.tensorflow.org/guide/saved_model)      | \"saved_model\"     | `yolov8n_saved_model/`    | `imgsz`, `keras`, `int8`                            | Empleado para guardar, compartir y desplegar modelos entrenados con TensorFlow. Vers谩til y facilita el despliegue en diversas plataformas como servidores, dispositivos m贸viles, embebidos y navegadores.                     |\n",
    "| [TF Lite](https://www.tensorflow.org/lite)                         | \"tflite\"          | `yolov8n.tflite`          | `imgsz`, `half`, `int8`                             | Dise帽ado para el aprendizaje autom谩tico en dispositivos, TF Lite aborda restricciones clave como latencia, privacidad, conectividad, tama帽o y consumo de energ铆a. Es esencial para desplegar modelos en dispositivos m贸viles e integrados, ofreciendo una soluci贸n ligera y eficiente.                           |\n",
    "| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | \"edgetpu\"         | `yolov8n_edgetpu.tflite`  | `imgsz`                                             | Utilizado para desplegar modelos de aprendizaje autom谩tico en el Edge TPU de TensorFlow. El Edge TPU es un peque帽o ASIC (Circuito Integrado Espec铆fico de Aplicaci贸n) dise帽ado por Google para ofrecer inferencias de aprendizaje autom谩tico de alto rendimiento en dispositivos de bajo consumo.                       |\n",
    "| [TF.js](https://www.tensorflow.org/js)                             | \"tfjs\"            | `yolov8n_web_model/`      | `imgsz`                                             | Facilita el despliegue de modelos de aprendizaje autom谩tico en navegadores web y Node.js, destacando la portabilidad y la facilidad de uso.                    |\n",
    "| [PaddlePaddle](https://github.com/PaddlePaddle)                    | \"paddle\"          | `yolov8n_paddle_model/`   | `imgsz`                                             | Utilizado para desplegar modelos en PaddlePaddle, una plataforma de aprendizaje profundo de c贸digo abierto, paralela y distribuida que tiene su origen en la pr谩ctica industrial.                      |\n",
    "| [ncnn](https://github.com/Tencent/ncnn)                            | \"ncnn\"            | `yolov8n_ncnn_model/`     | `imgsz`, `half`                                     | Formato optimizado para plataformas m贸viles, ofreciendo alto rendimiento. Puede incluir una estructura de archivo de modelo con informaci贸n sobre capas, blobs de entrada y salida, y otros par谩metros.                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">EXPORTACIN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.220  Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_segmentacion\\segmentacion\\pruebaEntrenamiento4\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 38, 8400), (1, 32, 160, 160)) (6.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as 'c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_segmentacion\\segmentacion\\pruebaEntrenamiento4\\weights\\best.onnx' (12.6 MB)\n",
      "\n",
      "Export complete (7.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_segmentacion\\segmentacion\\pruebaEntrenamiento4\\weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_segmentacion\\segmentacion\\pruebaEntrenamiento4\\weights\\best.onnx imgsz=640 int8 \n",
      "Validate:        yolo val task=segment model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_segmentacion\\segmentacion\\pruebaEntrenamiento4\\weights\\best.onnx imgsz=640 data=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\dataset.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "selected_model_seg=YOLO(model_train)\n",
    "\n",
    "FORMAT='onnx' # Seleccione el formato de exportaci贸n del modelo segmentaci贸n, empleando la tabla previamente proporcionada; en la columna \"Asignaci贸n\" se indican las opciones para ajustar este valor.\n",
    "INT8=True # Establezca este par谩metro en True al utilizar la CPU y en False en caso contrario. La cuantificaci贸n a INT8 mejora la eficiencia del modelo segmentaci贸n en cuanto a memoria y velocidad de inferencia, especialmente en hardware que admite esta precisi贸n.\n",
    "HALF=False # Config煤relo en True cuando use la GPU; en caso contrario, False. La cuantificaci贸n a FP16 mejora la eficiencia de la memoria del modelo segmentaci贸n y la velocidad de inferencia, especialmente en hardware que admite precisi贸n de punto flotante de 16 bits.\n",
    "IMGSZ=640 # Establezca las dimensiones en p铆xeles de la imagen de entrada para la exportaci贸n del modelo de segmentaci贸n. Puede especificarlo como un n煤mero entero, por ejemplo, 640 para un cuadrado perfecto, o como una tupla, por ejemplo, (640, 480) para dimensiones espec铆ficas de ancho y alto. Las im谩genes que ingreses al modelo despu茅s de la exportaci贸n deben tener las mismas dimensiones espec铆ficas que has configurado para adaptarse a los requisitos del escenario de despliegue.\n",
    "OPTIMIZE=False # Controla la optimizaci贸n en modelos de segmentaci贸n de instancias a TorchScript para su implementaci贸n m贸vil. Es importante destacar que esta funci贸n puede resultar en un aumento significativo en el tama帽o del modelo exportado, lo cual puede no ser ideal para aplicaciones m贸viles. Se configura con True para activar y False para desactivar.\n",
    "DYNAMIC=False # Controla la habilitaci贸n de ejes din谩micos en modelos de segmentaci贸n, lo cual es particularmente 煤til para gestionar tama帽os de lote variables. Esta caracter铆stica funciona bien en escenarios donde el tama帽o del lote puede cambiar durante la inferencia, como aplicaciones en tiempo real o de transmisi贸n por secuencias. Los valores aceptados son Verdadero para habilitar la funci贸n y Falso para deshabilitarla.\n",
    "SIMPLIFY=False # En la exportaci贸n de modelos de segmentaci贸n a ONNX|TensorRT, este hiperpar谩metro personaliza la complejidad del modelo, optimizando, eliminando capas redundantes y reduciendo la precisi贸n de los par谩metros. Se activa con True y se desactiva con False.\n",
    "OPSET=None # Especifica la versi贸n del conjunto de operadores en ONNX al exportar el modelo segmentaci贸n desde marcos como PyTorch o TensorFlow. Si se deja en \"None\", ONNX utilizar谩 autom谩ticamente la versi贸n m谩s reciente disponible; para una versi贸n espec铆fica, asigne el n煤mero entre comillas, por ejemplo, \"11\".\n",
    "WORKSPACE=4 # En la exportaci贸n de modelos de segmentaci贸n a TensorRT, establece el tama帽o del espacio de trabajo en GB asignado para optimizar y preparar el modelo de red neuronal. Este espacio se utiliza durante el proceso de construcci贸n del motor para lograr una ejecuci贸n eficiente en hardware GPU mediante la biblioteca TensorRT.\n",
    "NMS=False # En la exportaci贸n de modelos de segmentaci贸n a CoreML, controla la inclusi贸n de la Supresi贸n No M谩xima (NMS) en el modelo para eliminar cuadros delimitadores redundantes en la segmentaci贸n de instancias y mejorar la precisi贸n de las predicciones. Establecer 'NMS' en 'False' ignora NMS en los modelos CoreML exportados.  Este ajuste, configurable durante la exportaci贸n del modelo YOLO, lo que permite a los usuarios optimizar la implementaci贸n del modelo en una variedad de plataformas y dispositivos.\n",
    "KERAS= False # En la exportaci贸n de modelos de segmentaci贸n a TF SavedModel y TF Lite, permite optimizar el despliegue en diversas plataformas y dispositivos. Incluye tambi茅n el formato del archivo, el dispositivo de ejecuci贸n y la posibilidad de manejar m煤ltiples etiquetas por caja. Establezca el valor del hiperpar谩metro en True si est谩 familiarizado con Keras; de lo contrario, en False para excluir su uso en la exportaci贸n.\n",
    "try:\n",
    "    selected_model_seg.export(format=FORMAT, imgsz=IMGSZ, dynamic=DYNAMIC, opset=OPSET, workspace=WORKSPACE, nms=NMS, keras=KERAS, int8=INT8, half=HALF, optimize=OPTIMIZE, simplify=SIMPLIFY)\n",
    "except Exception as e: \n",
    "    print(f'Error en la exportaci贸n del modelo: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">VALIDACIN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.220  Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_val\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|| 49/49 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|| 4/4 [00:10<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235          1      0.865      0.929      0.929       0.01     0.0109    0.00502      0.001\n",
      "            abolladura         49         46          1          1      0.995      0.995     0.0201     0.0217       0.01    0.00201\n",
      "                 rayon         49        189          1       0.73      0.863      0.863          0          0          0          0\n",
      "Speed: 5.6ms preprocess, 153.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Saving c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\pruebaValidacionSeg\\predictions.json...\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\pruebaValidacionSeg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --Inicio Men煤\n",
    "while True:\n",
    "    try:\n",
    "        model_type = input('Qu茅 tipo de modelo desea utilizar, indique \"original\" o \"entrenado\": ')\n",
    "        if model_type == \"original\":\n",
    "            selected_model_seg=YOLO(model_orig)\n",
    "            break  # Sale del bucle si la entrada es v谩lida\n",
    "        elif model_type == \"entrenado\":\n",
    "            selected_model_seg=YOLO(model_train)\n",
    "            break  # Sale del bucle si la entrada es v谩lida\n",
    "        else:\n",
    "            print('Caracter no valido! Intente nuevamente.')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "# --Finalizaci贸n Men煤\n",
    "\n",
    "NAME='pruebaValidacionSeg' # El nombre del experimento de validaci贸n para segmentaci贸n de instancias deben ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice alg煤n formato de nombres como camelCase, snake_case o PascalCase.\n",
    "DATA= data_train # Permite indicar la ruta al archivo que contiene los metadatos necesarios para el proceso de validaci贸n, la ruta debe ser proporcionada entre comillas.\n",
    "SAVE_JSON=True # Si se configura como True, habilita la funcionalidad de guardar los resultados obtenidos de manera detallada del proceso de validaci贸n en un formato estructurado JSON.\n",
    "IMGSZ=640 # Establece las dimensiones en p铆xeles de la imagen de entrada para la validaci贸n del modelo de segmentaci贸n. Puede ser un n煤mero entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones espec铆ficas de ancho y alto. Se recomienda usar el mismo valor que utilizo durante el entrenamiento del modelo.\n",
    "BATCH=16 # Define la cantidad de im谩genes procesadas simult谩neamente en una iteraci贸n para la validaci贸n de segmentos. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta autom谩ticamente el tama帽o del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del par谩metro como un n煤mero entero.\n",
    "SAVE_HYBRID=True # Activa la funci贸n con True para guardar una versi贸n h铆brida de la etiqueta, incluyendo la original y predicciones adicionales. til para el an谩lisis detallado del rendimiento del modelo segmentaci贸n durante la validaci贸n; establezca en False para mostrar solo las predicciones.\n",
    "CONF=0.5 # Establece el umbral de confianza para la validaci贸n de clases en la tarea de segmentaci贸n. Se recomienda un valor entre 0.5 y 0.10. Un umbral m谩s alto mejora la precisi贸n pero reduce la frecuencia de predicciones, mientras que un umbral m谩s bajo aumenta la frecuencia pero disminuye la precisi贸n. \n",
    "MAX_DET=10 # Toma como valor solo n煤meros enteros. ndica el l铆mite de la cantidad m谩xima de objetos que el modelo intentara segmentar en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "DEVICE='CPU' # Especifica el dispositivo de ejecuci贸n para la prueba de validaci贸n en la operaci贸n de segmentaci贸n. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el par谩metro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el n煤mero representa el identificador de la GPU disponible en el sistema. Tambi茅n es posible utilizar m煤ltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generaci贸n de gr谩ficos que permite visualizar y monitorear la p茅rdida y la precisi贸n durante la validaci贸n en la segmentaci贸n de instancias. Establecer plots=True activara la funci贸n; si desea desactivarla, establezca el valor del hiperpar谩metro en False.\n",
    "RECT=False # Habilita la formaci贸n rectangular en cada lote, redimensionando las im谩genes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de validaci贸n en la segmentaci贸n de instancias. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente.\n",
    "IOU=0.6 # El umbral predeterminado para la supresi贸n no m谩xima (NMS) en la validaci贸n YOLO es 0,6. Este umbral de IoU (intersecci贸n sobre uni贸n) es fundamental para NMS porque determina el grado m铆nimo de superposici贸n requerido para que dos cuadros delimitadores se consideren el mismo segmento. Un umbral de IoU m谩s bajo hace que NMS sea m谩s conservador, mientras que un umbral de IoU m谩s alto permite que un NMS m谩s relajado evite eliminar los verdaderos positivos.\n",
    "\n",
    "try:\n",
    "    selected_model_seg.val(name=NAME, data=DATA, save_json=SAVE_JSON, imgsz=IMGSZ, batch=BATCH, save_hybrid=SAVE_HYBRID, conf=CONF, max_det=MAX_DET, device=DEVICE, plots=PLOTS, rect=RECT, iou=IOU)\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuraci贸n de fuentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Para utilizar m煤ltiples fuentes de datos al realizar predicciones con el modelo, se requiere que se ajuste el par谩metro'source' a sus necesidades, tal como se indica en la siguiente tabla:</span>\n",
    "\n",
    "\n",
    "| Fuentes          | Asignaci贸n                             | Tipo             | Notas                                                           |\n",
    "| --------------- | ------------------------------------ | ----------------- | --------------------------------------------------------------- |\n",
    "| `image`           | 'image.jpg'                          | str or Path       | Archivo que contiene una 煤nica imagen.                                              |\n",
    "| `URL`             | 'https://ultralytics.com/images/bus.jpg' | str               | Direcci贸n que especifica la ubicaci贸n de una imagen en la web.                                                 |\n",
    "| `screenshot`      | 'screen'                             | str               | El sistema captura la imagen actualmente visible en la pantalla y la utiliza como entrada para el modelo.                                           |\n",
    "| `PIL`             | Image.open('im.jpg')                 | PIL.Image         | Utilizado para cargar im谩genes en formato HWC (altura, ancho, canales) con canales RGB (rojo, verde y azul) mediante la biblioteca Python Imaging Library (PIL).                                   |\n",
    "| `OpenCV`          | cv2.imread('im.jpg')                 | np.ndarray        | Permite la lectura de una imagen desde un archivo en formato HWC con canales BGR (azul, verde, rojo) utilizando la biblioteca OpenCV, almacenando la imagen como un array de NumPy.                    |\n",
    "| `numpy`           | np.zeros((640,1280,3))               | np.ndarray        | Genera un array de ceros con las dimensiones especificadas para un formato HWC con canales BGR, utilizando la biblioteca NumPy.                    |\n",
    "| `torch`           | torch.zeros(16,3,320,640)            | torch.Tensor      | Crea un tensor de ceros con las dimensiones especificadas para un formato HWC con canales RGB, empleando el framework PyTorch.               |\n",
    "| `CSV`             | 'sources.csv'                        | str or Path       | Archivo de texto que almacena las rutas a las im谩genes que se procesar谩n.   |\n",
    "| `video`          | 'video.mp4'                          | str or Path       | Proporciona acceso a un archivo de video 煤nico.                       |\n",
    "| `directory`      | 'path/'                              | str or Path       | Directorio que contiene m煤ltiples archivos de imagen.               |\n",
    "| `glob`           | 'path/*.jpg'                         | str               | Permite acceder a varias im谩genes en un directorio usando expresiones de coincidencia de patrones. |\n",
    "| `YouTube`        | 'https://youtu.be/LNwODJXcvt4'       | str               | Facilita el acceso a videos desde la plataforma YouTube.                                         |\n",
    "| `stream`         | 'rtsp://example.com/media.mp4'      | str               | Permite la conexi贸n a flujos de video o audio en tiempo real mediante protocolos como RTSP, RTMP, TCP o IP, ya sea a trav茅s de internet o una red local. |\n",
    "| `multi-stream`   | 'list.streams'                       | str or Path       | Se utiliza para transmitir varios flujos de medios simult谩neamente, permitiendo el procesamiento y an谩lisis paralelo de m煤ltiples flujos de medios. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Formatos para las im谩genes: </span>\n",
    "\n",
    "| Image Suffixes | Reference                           |\n",
    "| --------------- | ----------------------------------- |\n",
    "| .bmp            | [Microsoft BMP File Format](https://docs.fileformat.com/es/image/bmp/)           |\n",
    "| .dng            | [Adobe DNG](https://docs.fileformat.com/es/image/dng/)                           |\n",
    "| .jpeg           | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .jpg            | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .mpo            | [Multi Picture Object](https://docs.fileformat.com/es/image/mpo/)                |\n",
    "| .png            | [Portable Network Graphics](https://docs.fileformat.com/es/image/png/)           |\n",
    "| .tif            | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .tiff           | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .webp           | [WebP](https://docs.fileformat.com/es/image/webp/)                                |\n",
    "| .pfm            | [Portable FloatMap](https://docs.fileformat.com/font/pfm/)                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Formatos para los videos: </span>\n",
    "\n",
    "| Video Suffixes | Reference                           |\n",
    "| -------------- | ----------------------------------- |\n",
    "| .asf           | [Advanced Systems Format](https://docs.fileformat.com/es/video/asf/)             |\n",
    "| .avi           | [Audio Video Interleave](https://docs.fileformat.com/es/video/avi/)              |\n",
    "| .gif           | [Graphics Interchange Format]()          |\n",
    "| .m4v           | [MPEG-4 Part 14](https://docs.fileformat.com/es/video/m4v/)                      |\n",
    "| .mkv           | [Matroska](https://docs.fileformat.com/es/video/mkv/)                            |\n",
    "| .mov           | [QuickTime File Format](https://docs.fileformat.com/es/video/mov/)               |\n",
    "| .mp4           | [MPEG-4](https://docs.fileformat.com/es/video/mp4/)          |\n",
    "| .mpeg          | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .mpg           | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .ts            | [MPEG Transport Stream](https://docs.fileformat.com/es/video/ts/)               |\n",
    "| .wmv           | [Windows Media Video](https://docs.fileformat.com/es/video/wmv/)                 |\n",
    "| .webm          | [WebM Project](https://docs.fileformat.com/es/video/webm/)                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">PREDICCIN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 3 rayons, 317.8ms\n",
      "image 2/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 (no detections), 256.9ms\n",
      "image 3/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 (no detections), 134.0ms\n",
      "image 4/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 5 rayons, 235.0ms\n",
      "image 5/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 (no detections), 218.0ms\n",
      "image 6/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 5 rayons, 239.0ms\n",
      "image 7/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 318.9ms\n",
      "image 8/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 4 rayons, 232.0ms\n",
      "image 9/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 (no detections), 225.0ms\n",
      "image 10/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 1 rayon, 192.0ms\n",
      "image 11/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 (no detections), 195.9ms\n",
      "image 12/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 4 rayons, 229.3ms\n",
      "image 13/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 (no detections), 241.0ms\n",
      "image 14/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 2 rayons, 237.0ms\n",
      "image 15/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 (no detections), 154.0ms\n",
      "image 16/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 171.0ms\n",
      "image 17/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 5 rayons, 193.0ms\n",
      "image 18/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 1 rayon, 221.0ms\n",
      "image 19/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 (no detections), 224.0ms\n",
      "image 20/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 1 rayon, 163.0ms\n",
      "image 21/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-despus-de-una-ruina-la-necesidad-ser-reparado-esperndola-es-demanda-de-seguro-29745503.jpg: 448x640 (no detections), 231.2ms\n",
      "image 22/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 317.2ms\n",
      "image 23/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 1 rayon, 312.0ms\n",
      "image 24/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 3 rayons, 182.4ms\n",
      "image 25/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 1 rayon, 230.4ms\n",
      "Speed: 3.3ms preprocess, 226.8ms inference, 5.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_scratch_srcv3\u001b[0m\n",
      "13 labels saved to c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_scratch_srcv3\\labels\n",
      "\n",
      "image 1/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 (no detections), 194.0ms\n",
      "image 2/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 2 abolladuras, 228.2ms\n",
      "image 3/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 1 abolladura, 116.0ms\n",
      "image 4/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 (no detections), 213.0ms\n",
      "image 5/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 1 abolladura, 217.0ms\n",
      "image 6/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 1 abolladura, 228.0ms\n",
      "image 7/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 309.6ms\n",
      "image 8/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 1 abolladura, 231.0ms\n",
      "image 9/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 (no detections), 214.0ms\n",
      "image 10/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 (no detections), 192.0ms\n",
      "image 11/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 1 abolladura, 184.0ms\n",
      "image 12/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 (no detections), 217.0ms\n",
      "image 13/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 4 abolladuras, 231.0ms\n",
      "image 14/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 1 abolladura, 232.0ms\n",
      "image 15/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 1 abolladura, 142.0ms\n",
      "image 16/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 157.0ms\n",
      "image 17/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 (no detections), 174.0ms\n",
      "image 18/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 (no detections), 222.3ms\n",
      "image 19/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 (no detections), 216.0ms\n",
      "image 20/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 (no detections), 159.0ms\n",
      "image 21/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-despus-de-una-ruina-la-necesidad-ser-reparado-esperndola-es-demanda-de-seguro-29745503.jpg: 448x640 1 abolladura, 214.9ms\n",
      "image 22/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 300.0ms\n",
      "image 23/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 1 abolladura, 308.0ms\n",
      "image 24/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 abolladura, 174.0ms\n",
      "image 25/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 2 abolladuras, 219.0ms\n",
      "Speed: 2.5ms preprocess, 211.7ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_dent_srcv3\u001b[0m\n",
      "13 labels saved to c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_dent_srcv3\\labels\n",
      "\n",
      "image 1/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 1 car, 3026.9ms\n",
      "image 2/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 (no detections), 3694.6ms\n",
      "image 3/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 1 car, 1749.1ms\n",
      "image 4/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 2 cars, 3434.4ms\n",
      "image 5/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 (no detections), 3422.2ms\n",
      "image 6/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 (no detections), 3679.5ms\n",
      "image 7/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 4921.8ms\n",
      "image 8/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 1 car, 3675.5ms\n",
      "image 9/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 1 car, 3424.3ms\n",
      "image 10/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 (no detections), 2953.6ms\n",
      "image 11/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 1 car, 2965.1ms\n",
      "image 12/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 2 cars, 3480.0ms\n",
      "image 13/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 1 car, 3709.4ms\n",
      "image 14/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 1 car, 3700.5ms\n",
      "image 15/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 4 cars, 2255.8ms\n",
      "image 16/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 2495.7ms\n",
      "image 17/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 (no detections), 2896.9ms\n",
      "image 18/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 1 car, 4031.4ms\n",
      "image 19/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 1 car, 3549.2ms\n",
      "image 20/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 1 car, 2549.0ms\n",
      "image 21/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-despus-de-una-ruina-la-necesidad-ser-reparado-esperndola-es-demanda-de-seguro-29745503.jpg: 448x640 1 car, 3511.3ms\n",
      "image 22/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 5983.5ms\n",
      "image 23/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 (no detections), 5074.7ms\n",
      "image 24/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 car, 2784.3ms\n",
      "image 25/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 1 car, 3512.7ms\n",
      "Speed: 4.2ms preprocess, 3459.3ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_car_srcv3\u001b[0m\n",
      "16 labels saved to c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_car_srcv3\\labels\n"
     ]
    }
   ],
   "source": [
    "#SOURCE= dir_prueba # Establezca el origen de datos que el modelo de detecci贸n utilizar谩 para realizar predicciones. Configure el valor de este hiperpar谩metro seg煤n la tabla proporcionada anteriormente.\n",
    "SOURCE= \"C:/Users/matrix/pruebayolo/proyecto_yolo/src/assets_affectation\"\n",
    "MAX_DET=10 # Toma como valor solo n煤meros enteros. ndica el l铆mite de la cantidad m谩xima de objetos que el modelo intentara predecir en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "IMGSZ=640 # Establezca las dimensiones en p铆xeles de la imagen de entrada durante la predicci贸n en tareas de detecci贸n. Puede ser un n煤mero entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones espec铆ficas de ancho y alto. Se recomienda utilizar los mismos valores utilizados durante el entrenamiento del modelo para mantener la coherencia en la inferencia.\n",
    "CONF=0.3 # Establece el umbral de confianza durante el proceso de predicci贸n en la tarea de detecci贸n. Se recomienda establecer el valor hiperpar谩metro entre 0.5 y 0.10. Un umbral m谩s alto mejora la precisi贸n pero reduce la frecuencia de predicciones, mientras que un umbral m谩s bajo aumenta la frecuencia pero disminuye la precisi贸n en la inferencia.\n",
    "LINE_WIDTH= None # Determina el grosor en p铆xeles de los cuadros delimitadores que rodean los objetos detectados por el modelo. Puede establecer el grosor de la l铆nea como un n煤mero entero en el que, a mayor valor, la l铆nea ser谩 m谩s gruesa, tambi茅n puede utilizar como valor None para que el grosor se ajuste de forma automatizada, proporcionando una l铆nea proporcional al tama帽o de la imagen.\n",
    "VISUALIZE=False # Determina si las caracter铆sticas del modelo de detecci贸n deben mostrarse durante la predicci贸n. Establecer esto en True permite que las caracter铆sticas se muestren como mapas intermedias, lo que hace que el modelo sea m谩s f谩cil de entender. Si se establece en False, no se mostrar谩n las caracter铆sticas del modelo. \n",
    "IOU=0.7 # El umbral predeterminado para la supresi贸n no m谩xima (NMS) en la validaci贸n YOLO es 0,7. Este umbral de IoU (intersecci贸n sobre uni贸n) es fundamental para NMS porque determina el grado m铆nimo de superposici贸n requerido para que dos cuadros delimitadores se consideren la misma detecci贸n. Un umbral de IoU m谩s bajo hace que NMS sea m谩s conservador, mientras que un umbral de IoU m谩s alto permite que un NMS m谩s relajado evite eliminar los verdaderos positivos.\n",
    "DEVICE='cpu' # Especifica el dispositivo de ejecuci贸n para la prueba de predicci贸n en la operaci贸n de detecci贸n. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el par谩metro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el n煤mero representa el identificador de la GPU disponible en el sistema. Tambi茅n es posible utilizar m煤ltiples GPUs mediante device='cuda:0,1,2'.\n",
    "VID_STRIDE=False # Controla la velocidad de los fotogramas durante el proceso de predicci贸n en v铆deos o secuencias de tiempo real. Al establecerlo en True el modelo se adapta a la velocidad de fotogramas especificada por la fuente de v铆deo, procesando cada fotograma individualmente. Para desactivar esta funci贸n indique como valor False.\n",
    "STREAM_BUFFER=False # Controla el almacenamiento en b煤fer de los fotogramas para la detecci贸n. Si es True, se almacenan todos los fotogramas para el procesamiento en tiempo real de v铆deos o transmisiones en directo; si es False, devuelve el fotograma m谩s reciente.\n",
    "SAVE_FRAMES=False # Controla la captura y almacenamiento de los fotogramas predichos por el modelo de detecci贸n. Con True, se guardar谩n todos los fotogramas individuales predichos; con False, no se realizar谩 el almacenamiento de los fotogramas.\n",
    "AUGMENT=False # Aplica transformaciones a las im谩genes de entrada, tales como giros, rotaciones, recortes y cambios de color, para diversificar los datos y mejorar la predicci贸n en la detecci贸n. Establecer en True para activar la funci贸n, False para desactivar.\n",
    "SAVE_CROP=True # Determina si se deben guardar im谩genes recortadas con los resultados durante la predicci贸n en la detecci贸n. Al establecerlo en \"False\", las im谩genes recortadas no se guardar谩n, lo que reduce el tama帽o del archivo. Con el valor \"True\", se guardar谩n las im谩genes recortadas correspondientes a las 谩reas detectadas.\n",
    "SHOW=False # Determina si se deben mostrar las im谩genes o v铆deos detectados durante la predicci贸n. Al establecerlo en \"True\", permite la visualizaci贸n de las predicciones en el mismo entorno, proporcionando una representaci贸n visual de los resultados. Si se establece en \"False\", las predicciones no se mostrar谩n. \n",
    "\n",
    "def train_classes(model_preentrenado, model_original):\n",
    "    try:\n",
    "        selected_model_det=YOLO(model_preentrenado)\n",
    "        \n",
    "        resultado_rayon= selected_model_det.predict(name='predict_scratch_srcv3-seg', source=SOURCE, conf=0.2, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=1,  save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save=True, save_conf=True) \n",
    "        \n",
    "        resultado_abolladura= selected_model_det.predict(name='predict_dent_srcv3-seg', source=SOURCE, conf=0.35, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=0,  save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save=True, save_conf=True)\n",
    "        \n",
    "        if resultado_rayon or resultado_abolladura is not None:\n",
    "            \n",
    "            selected_model_det_car=YOLO(model_original)\n",
    "            resultado_carro= selected_model_det_car.predict(name='predict_car_srcv3-seg', source=SOURCE, conf=CONF, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=2,  save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save=True, save_conf=True) \n",
    "            \n",
    "        return resultado_rayon, resultado_abolladura, resultado_carro\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error en el entrenamiento del modelo: {e}')\n",
    "\n",
    "results_rayon, results_abolladura, results_car= train_classes(model_train, model_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Funci贸n de 谩rea para mascaras segmentadas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Dataframe con las 谩reas totales</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_10319_row0_col0, #T_10319_row0_col1, #T_10319_row0_col2, #T_10319_row0_col3, #T_10319_row0_col4, #T_10319_row1_col0, #T_10319_row1_col1, #T_10319_row1_col2, #T_10319_row1_col3, #T_10319_row1_col4, #T_10319_row2_col0, #T_10319_row2_col1, #T_10319_row2_col2, #T_10319_row2_col3, #T_10319_row2_col4, #T_10319_row3_col0, #T_10319_row3_col1, #T_10319_row3_col2, #T_10319_row3_col3, #T_10319_row3_col4, #T_10319_row4_col0, #T_10319_row4_col1, #T_10319_row4_col2, #T_10319_row4_col3, #T_10319_row4_col4, #T_10319_row5_col0, #T_10319_row5_col1, #T_10319_row5_col2, #T_10319_row5_col3, #T_10319_row5_col4, #T_10319_row6_col0, #T_10319_row6_col1, #T_10319_row6_col2, #T_10319_row6_col3, #T_10319_row6_col4, #T_10319_row7_col0, #T_10319_row7_col1, #T_10319_row7_col2, #T_10319_row7_col3, #T_10319_row7_col4, #T_10319_row8_col0, #T_10319_row8_col1, #T_10319_row8_col2, #T_10319_row8_col3, #T_10319_row8_col4, #T_10319_row9_col0, #T_10319_row9_col1, #T_10319_row9_col2, #T_10319_row9_col3, #T_10319_row9_col4, #T_10319_row10_col0, #T_10319_row10_col1, #T_10319_row10_col2, #T_10319_row10_col3, #T_10319_row10_col4, #T_10319_row11_col0, #T_10319_row11_col1, #T_10319_row11_col2, #T_10319_row11_col3, #T_10319_row11_col4, #T_10319_row12_col0, #T_10319_row12_col1, #T_10319_row12_col2, #T_10319_row12_col3, #T_10319_row12_col4, #T_10319_row13_col0, #T_10319_row13_col1, #T_10319_row13_col2, #T_10319_row13_col3, #T_10319_row13_col4, #T_10319_row14_col0, #T_10319_row14_col1, #T_10319_row14_col2, #T_10319_row14_col3, #T_10319_row14_col4 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_10319\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_10319_level0_col0\" class=\"col_heading level0 col0\" >imagen</th>\n",
       "      <th id=\"T_10319_level0_col1\" class=\"col_heading level0 col1\" >area abolladura</th>\n",
       "      <th id=\"T_10319_level0_col2\" class=\"col_heading level0 col2\" >area rayon</th>\n",
       "      <th id=\"T_10319_level0_col3\" class=\"col_heading level0 col3\" >area carro</th>\n",
       "      <th id=\"T_10319_level0_col4\" class=\"col_heading level0 col4\" >afectacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_10319_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_10319_row0_col1\" class=\"data row0 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row0_col2\" class=\"data row0 col2\" >1575px^2</td>\n",
       "      <td id=\"T_10319_row0_col3\" class=\"data row0 col3\" >1106316px^2</td>\n",
       "      <td id=\"T_10319_row0_col4\" class=\"data row0 col4\" >1104741px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_10319_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_10319_row1_col1\" class=\"data row1 col1\" >38780px^2</td>\n",
       "      <td id=\"T_10319_row1_col2\" class=\"data row1 col2\" >0px^2</td>\n",
       "      <td id=\"T_10319_row1_col3\" class=\"data row1 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row1_col4\" class=\"data row1 col4\" >38780px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_10319_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_10319_row2_col1\" class=\"data row2 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row2_col2\" class=\"data row2 col2\" >0px^2</td>\n",
       "      <td id=\"T_10319_row2_col3\" class=\"data row2 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row2_col4\" class=\"data row2 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_10319_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_10319_row3_col1\" class=\"data row3 col1\" >22862px^2</td>\n",
       "      <td id=\"T_10319_row3_col2\" class=\"data row3 col2\" >1436px^2</td>\n",
       "      <td id=\"T_10319_row3_col3\" class=\"data row3 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row3_col4\" class=\"data row3 col4\" >24298px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_10319_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_10319_row4_col1\" class=\"data row4 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row4_col2\" class=\"data row4 col2\" >452px^2</td>\n",
       "      <td id=\"T_10319_row4_col3\" class=\"data row4 col3\" >112737px^2</td>\n",
       "      <td id=\"T_10319_row4_col4\" class=\"data row4 col4\" >112285px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_10319_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_10319_row5_col1\" class=\"data row5 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row5_col2\" class=\"data row5 col2\" >1794px^2</td>\n",
       "      <td id=\"T_10319_row5_col3\" class=\"data row5 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row5_col4\" class=\"data row5 col4\" >1794px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_10319_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_10319_row6_col1\" class=\"data row6 col1\" >45990px^2</td>\n",
       "      <td id=\"T_10319_row6_col2\" class=\"data row6 col2\" >0px^2</td>\n",
       "      <td id=\"T_10319_row6_col3\" class=\"data row6 col3\" >324852px^2</td>\n",
       "      <td id=\"T_10319_row6_col4\" class=\"data row6 col4\" >278862px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_10319_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_10319_row7_col1\" class=\"data row7 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row7_col2\" class=\"data row7 col2\" >17058px^2</td>\n",
       "      <td id=\"T_10319_row7_col3\" class=\"data row7 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row7_col4\" class=\"data row7 col4\" >17058px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_10319_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_10319_row8_col1\" class=\"data row8 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row8_col2\" class=\"data row8 col2\" >375px^2</td>\n",
       "      <td id=\"T_10319_row8_col3\" class=\"data row8 col3\" >1095628px^2</td>\n",
       "      <td id=\"T_10319_row8_col4\" class=\"data row8 col4\" >1095253px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_10319_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_10319_row9_col1\" class=\"data row9 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row9_col2\" class=\"data row9 col2\" >0px^2</td>\n",
       "      <td id=\"T_10319_row9_col3\" class=\"data row9 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row9_col4\" class=\"data row9 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_10319_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_10319_row10_col1\" class=\"data row10 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row10_col2\" class=\"data row10 col2\" >95px^2</td>\n",
       "      <td id=\"T_10319_row10_col3\" class=\"data row10 col3\" >110962px^2</td>\n",
       "      <td id=\"T_10319_row10_col4\" class=\"data row10 col4\" >110867px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_10319_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_10319_row11_col1\" class=\"data row11 col1\" >45372px^2</td>\n",
       "      <td id=\"T_10319_row11_col2\" class=\"data row11 col2\" >0px^2</td>\n",
       "      <td id=\"T_10319_row11_col3\" class=\"data row11 col3\" >277478px^2</td>\n",
       "      <td id=\"T_10319_row11_col4\" class=\"data row11 col4\" >232106px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_10319_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_10319_row12_col1\" class=\"data row12 col1\" >0px^2</td>\n",
       "      <td id=\"T_10319_row12_col2\" class=\"data row12 col2\" >0px^2</td>\n",
       "      <td id=\"T_10319_row12_col3\" class=\"data row12 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row12_col4\" class=\"data row12 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_10319_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_10319_row13_col1\" class=\"data row13 col1\" >2020px^2</td>\n",
       "      <td id=\"T_10319_row13_col2\" class=\"data row13 col2\" >2444px^2</td>\n",
       "      <td id=\"T_10319_row13_col3\" class=\"data row13 col3\" >367066px^2</td>\n",
       "      <td id=\"T_10319_row13_col4\" class=\"data row13 col4\" >362602px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10319_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_10319_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_10319_row14_col1\" class=\"data row14 col1\" >76005px^2</td>\n",
       "      <td id=\"T_10319_row14_col2\" class=\"data row14 col2\" >72px^2</td>\n",
       "      <td id=\"T_10319_row14_col3\" class=\"data row14 col3\" >0px^2</td>\n",
       "      <td id=\"T_10319_row14_col4\" class=\"data row14 col4\" >76077px^2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f684d99b70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_area(vertices): \n",
    "    total_mask_area = 0 # Se inicializa una variable acumuladora para almacenar la suma total del 谩rea de cada m谩scara en una imagen.\n",
    "    for point in vertices:\n",
    "        x_coordinate = point[:, 0] # Asigna todas filas correspondientes a la primer columna como coordenada X del formato masks que entrega por medio de arrays los vertices (x , y) de los puntos de contorno por medio de una lista para cada regi贸n segmentada.\n",
    "        y_coordinate = point[:, 1] # Asigna todas las filas correspondientes a la segunda columna como coordenada Y.\n",
    "        mask_area = np.round(0.5 * abs(np.dot(x_coordinate, np.roll(y_coordinate, 1)) - np.dot(y_coordinate, np.roll(x_coordinate, 1)))).astype(int) # Almacena el resultado del area x mascara, basandose en la formula Shoelace o lazada de Gauss. Utiliza la suma y la resta de los productos cruzados de las coordenadas de los vertices del poligono; el termino np.roll(y, 1) y np.roll(x, 1) crean versiones desplazadas circularmente, es esencial para que np.dot() calcule el producto punto de los vertices del poligono, la diferencia entre los productos cruzados se multiplicara por 1/2 tomando el valor absoluto.\n",
    "        total_mask_area += mask_area\n",
    "    return total_mask_area \n",
    "\n",
    "def search_for_mask(segmentation_results, image_instance):\n",
    "    for attribute in segmentation_results: # Itera a trav茅s de los atributos en los resultados de segmentaci贸n.\n",
    "        if attribute.path == image_instance: # Comprueba si la ruta de la instancia actual coincide con la imagen en cada clase.\n",
    "            return calculate_area(attribute.masks.xy) if attribute.masks is not None else 0 # Retorna el 谩rea calculada en p铆xeles solo si la m谩scara no est谩 vac铆a.\n",
    "\n",
    "def process_main_detection(dent_class, scratch_class, car_results):\n",
    "    data = {'imagen':[], 'area abolladura':[], 'area rayon':[], 'area carro':[], 'afectacion':[]} # Se define la estructura inicial del dataframe, el orden de las columnas y su informaci贸n en listas que est谩n inicialmente vac铆as.\n",
    "    \n",
    "    for image_id, result in enumerate(dent_class): \n",
    "        control_image = result.path \n",
    "\n",
    "        data['imagen'].append(image_id + 1) \n",
    "        \n",
    "        dent_area = search_for_mask(dent_class, control_image) \n",
    "        data['area abolladura'].append(f'{dent_area}px^2')\n",
    "        \n",
    "        scratch_area = search_for_mask(scratch_class, control_image)\n",
    "        data['area rayon'].append(f'{scratch_area}px^2')\n",
    "\n",
    "        if dent_area > 0 or scratch_area > 0: \n",
    "            car_masks= process_car_detection(car_results, dent_area, scratch_area, control_image) \n",
    "            data['area carro'].append(f'{car_masks[\"car area\"]}px^2')\n",
    "            data['afectacion'].append(f'{car_masks[\"affectation\"]}px^2')\n",
    "        else:\n",
    "            data['area carro'].append('0px^2')\n",
    "            data['afectacion'].append('0px^2')\n",
    "    \n",
    "    df= pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def process_car_detection(car, dent_area, scratch_area, image_instance):\n",
    "    car_area = search_for_mask(car, image_instance)\n",
    "\n",
    "    total_affected_area = abs(car_area - dent_area) if dent_area > 0 else 0\n",
    "    total_affected_area = abs(car_area - scratch_area) if scratch_area > 0 else total_affected_area\n",
    "    if dent_area > 0 and scratch_area > 0:\n",
    "        main_area_sum = dent_area + scratch_area \n",
    "        total_affected_area = abs(main_area_sum - car_area)\n",
    "    return {'car area': car_area, 'affectation': total_affected_area}\n",
    "\n",
    "dataframe=process_main_detection(results_abolladura, results_rayon, results_car)\n",
    "style= dataframe.style.set_properties(**{'text-align': 'right'})\n",
    "style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe con las 谩reas individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>area mascara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_imagen</th>\n",
       "      <th>nombre</th>\n",
       "      <th>afectacion total</th>\n",
       "      <th>id_mascara</th>\n",
       "      <th>Clase mascara</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">20170531_010133.jpg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1104741</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">rayon</th>\n",
       "      <th>1</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>4</th>\n",
       "      <td>1106316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">5-320w-320w.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">15020</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>5</th>\n",
       "      <td>15020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">OIP (1).jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">OIP (1).jpg</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">24298</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>11</th>\n",
       "      <td>22862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">rayon</th>\n",
       "      <th>12</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">OIP.jpeg</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">112285</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">rayon</th>\n",
       "      <th>19</th>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>21</th>\n",
       "      <td>112737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">R.jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1794</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>23</th>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">R.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">278862</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>25</th>\n",
       "      <td>45990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>27</th>\n",
       "      <td>324852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">Webp.net-resizeimage-10-1170x600.jpg</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">17058</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">rayon</th>\n",
       "      <th>29</th>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">abolladura-en-un-coche-632c58a6e2ea5.jpg</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1095253</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>36</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">carro</th>\n",
       "      <th>37</th>\n",
       "      <td>771928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>323700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">big_ray.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">110867</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>43</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>44</th>\n",
       "      <td>110962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">coche-despu茅s-de-una-ruina-la-necesidad-ser-reparado-esper谩ndola-es-demanda-de-seguro-29745503.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">232106</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>45</th>\n",
       "      <td>45372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>47</th>\n",
       "      <td>277478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">13</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">e1b235cf346a92a59d23c353c5ab913c.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">14</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">362602</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>51</th>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">rayon</th>\n",
       "      <th>52</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>55</th>\n",
       "      <td>367066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">20869</th>\n",
       "      <th>0</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>56</th>\n",
       "      <td>20797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>rayon</th>\n",
       "      <th>57</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>carro</th>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           area mascara\n",
       "id_imagen nombre                                             afectacion total id_mascara Clase mascara                 \n",
       "1         20170531_010133.jpg                                1104741          0          abolladura    0              0\n",
       "                                                                              1          rayon         1            281\n",
       "                                                                                                       2            275\n",
       "                                                                                                       3           1019\n",
       "                                                                              2          carro         4        1106316\n",
       "2         5-320w-320w.jpg                                    15020            0          abolladura    5          15020\n",
       "                                                                              1          rayon         6              0\n",
       "                                                                              2          carro         7              0\n",
       "3         OIP (1).jpeg                                       0                0          abolladura    8              0\n",
       "                                                                              1          rayon         9              0\n",
       "                                                                              2          carro         10             0\n",
       "4         OIP (1).jpg                                        24298            0          abolladura    11         22862\n",
       "                                                                              1          rayon         12            98\n",
       "                                                                                                       13           207\n",
       "                                                                                                       14           379\n",
       "                                                                                                       15            83\n",
       "                                                                                                       16           669\n",
       "                                                                              2          carro         17             0\n",
       "5         OIP.jpeg                                           112285           0          abolladura    18             0\n",
       "                                                                              1          rayon         19           329\n",
       "                                                                                                       20           123\n",
       "                                                                              2          carro         21        112737\n",
       "6         R.jpeg                                             1794             0          abolladura    22             0\n",
       "                                                                              1          rayon         23          1794\n",
       "                                                                              2          carro         24             0\n",
       "7         R.jpg                                              278862           0          abolladura    25         45990\n",
       "                                                                              1          rayon         26             0\n",
       "                                                                              2          carro         27        324852\n",
       "8         Webp.net-resizeimage-10-1170x600.jpg               17058            0          abolladura    28             0\n",
       "                                                                              1          rayon         29          2666\n",
       "                                                                                                       30          4065\n",
       "                                                                                                       31           174\n",
       "                                                                                                       32          5690\n",
       "                                                                                                       33          4463\n",
       "                                                                              2          carro         34             0\n",
       "9         abolladura-en-un-coche-632c58a6e2ea5.jpg           1095253          0          abolladura    35             0\n",
       "                                                                              1          rayon         36           375\n",
       "                                                                              2          carro         37        771928\n",
       "                                                                                                       38        323700\n",
       "10        abolladuraautos-fd03b3bae67d7363172c41cc00198c5... 0                0          abolladura    39             0\n",
       "                                                                              1          rayon         40             0\n",
       "                                                                              2          carro         41             0\n",
       "11        big_ray.jpg                                        110867           0          abolladura    42             0\n",
       "                                                                              1          rayon         43            95\n",
       "                                                                              2          carro         44        110962\n",
       "12        coche-despu茅s-de-una-ruina-la-necesidad-ser-rep... 232106           0          abolladura    45         45372\n",
       "                                                                              1          rayon         46             0\n",
       "                                                                              2          carro         47        277478\n",
       "13        e1b235cf346a92a59d23c353c5ab913c.jpg               0                0          abolladura    48             0\n",
       "                                                                              1          rayon         49             0\n",
       "                                                                              2          carro         50             0\n",
       "14        rayonesauto-e68618ca9c3d6859cebc796c300aea97-12... 362602           0          abolladura    51          2020\n",
       "                                                                              1          rayon         52           200\n",
       "                                                                                                       53           113\n",
       "                                                                                                       54          2131\n",
       "                                                                              2          carro         55        367066\n",
       "15        trucos-para-quitar-abolladuras-del-coche.imagen... 20869            0          abolladura    56         20797\n",
       "                                                                              1          rayon         57            72\n",
       "                                                                              2          carro         58             0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_area(segmented_masks): \n",
    "    total_area_of_masks= 0\n",
    "    individual_mask_area= []\n",
    "    if segmented_masks is not None:\n",
    "        for vectors in segmented_masks: \n",
    "            coordinate_x= vectors[:, 0] # \n",
    "            coordinate_y= vectors[:, 1] \n",
    "            area_mask= np.round(0.5 * abs(np.dot(coordinate_x, np.roll(coordinate_y, 1)) - np.dot(coordinate_y, np.roll(coordinate_x, 1)))).astype(int) # Se basa en la formula Shoelace o lazada de Gauss. Utiliza la suma y la resta de los productos cruzados de las coordenadas de los vertices del poligono; el termino np.roll(y, 1) y np.roll(x, 1) crean versiones desplazadas circularmente, es esencial para que np.dot() calcule el producto punto de los vertices del poligono, la diferencia entre los productos cruzados se multiplicara por 1/2 tomando el valor absoluto.\n",
    "            individual_mask_area.append(area_mask) # Permite guardar el area de cada mascara detectada por imagen segun la clase\n",
    "            total_area_of_masks += area_mask # Permite conocer el valor total de las areas \n",
    "    return individual_mask_area, total_area_of_masks\n",
    "\n",
    "def search_mask_by_image(segmentation_results, id_image):\n",
    "    for attributes in segmentation_results:\n",
    "        if attributes.path == id_image: # Confirmar que estamos buscando el resultado en la misma imagen por cada clase, con el atributo path obtenemos la direccion del archivo\n",
    "            return calculate_area(attributes.masks.xy) if attributes.masks is not None else ([], 0) # Envia las coordenadas para el calculo del area si la mascara no esta vacia. De lo contrario, retornara como valor una lista vacia referente a las areas halladas y un equivalente a cero por el area total de la imagen.\n",
    "    return [], None\n",
    "\n",
    "def add_dataframe_rows(main_data, id_image, image_name, class_identification, mask_area_by_class, affectation):\n",
    "    id_class = {'abolladura': 0, 'rayon': 1, 'carro': 2} # Asigna a cada clase un identificador de orden\n",
    "\n",
    "    if isinstance(mask_area_by_class, list):  \n",
    "        for area in mask_area_by_class: \n",
    "            main_data['id_imagen'].append(id_image)\n",
    "            main_data['imagen'].append(image_name)\n",
    "            main_data['Clase mascara'].append(class_identification)\n",
    "            main_data['area mascara'].append(area)\n",
    "            main_data['afectacion total'].append(affectation)\n",
    "            \n",
    "        if mask_area_by_class == []:\n",
    "            main_data['id_imagen'].append(id_image)\n",
    "            main_data['imagen'].append(image_name)\n",
    "            main_data['Clase mascara'].append(class_identification)\n",
    "            main_data['area mascara'].append(0)\n",
    "            main_data['afectacion total'].append(affectation)\n",
    "\n",
    "    main_data['id_mascara'] = [id_class[class_name] for class_name in main_data['Clase mascara']] # Se a帽ade una nueva columna que contendra la asignacion de cada clase \n",
    "\n",
    "def process_segmentation_results(abolladura, rayon, car):\n",
    "    try:\n",
    "        main_data = {'id_imagen': [], 'imagen':[],'Clase mascara': [], 'area mascara': [], 'afectacion total':[]} # Creacion de la estructura inicial para llenar el dataframe, las columnas tienen asignado listas vacias.\n",
    "\n",
    "        for image_number, attributes in enumerate(abolladura): # Recorre los resultados de la segmentacion abolladura, una instancia obtendra el identificador de recorrido.\n",
    "            img_directory = attributes.path # Se obtiene el atributo de directorio en imagen\n",
    "            id_image = image_number + 1 # Incrementa el contador para asignarle una identificaci贸n 煤nica a la imagen\n",
    "            \n",
    "            areas_abolladura, total_abolladura_area = search_mask_by_image(attributes, img_directory)\n",
    "            \n",
    "            areas_rayon, total_rayon_area = search_mask_by_image(rayon, img_directory)\n",
    "            \n",
    "            if total_abolladura_area is not None and total_abolladura_area > 0 or total_rayon_area is not None and total_rayon_area > 0:\n",
    "                areas_car, total_car_area = search_mask_by_image(car, img_directory)\n",
    "                afectacion_imagen= calculating_car_affectation(total_car_area, total_abolladura_area, total_rayon_area)\n",
    "                \n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'abolladura', areas_abolladura, afectacion_imagen)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'rayon', areas_rayon, afectacion_imagen)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'carro', areas_car, afectacion_imagen)\n",
    "            else:\n",
    "                add_dataframe_rows(main_data, id_image, img_directory,'abolladura', areas_abolladura, 0)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory,'rayon', areas_rayon, 0)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'carro', [], 0)\n",
    "\n",
    "        df = pd.DataFrame(main_data) # Convierte la lista de diccionarios a dataframe\n",
    "        df['nombre'] = df['imagen'].apply(lambda ruta: os.path.basename(ruta)) #  Obtener solo el nombre del archivo\n",
    "        grouped_columns=df.groupby(['id_imagen', 'nombre', 'afectacion total','id_mascara','Clase mascara'], group_keys=True, as_index=True)[[ 'area mascara']].apply(lambda x : x) # Se utiliza una agrupacion serial, se agrupa por imagen la afectacion total y los tres tipos de clase, independiente quedan las areas que pertenecen a cada clase.\n",
    "        return grouped_columns\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "def calculating_car_affectation(total_car_area, total_abolladura_area, total_rayon_area): \n",
    "    total_area_affected  = abs(total_car_area - total_abolladura_area) if total_abolladura_area is not None and total_abolladura_area > 0 else abs(total_car_area - total_rayon_area) if total_rayon_area is not None and total_rayon_area > 0 else 0 # verifica si existe un valor valido de abolladura para encontrar el valor de area afectada en el carro, de lo contrario verifica lo mismo para rayon, asigna como valor de afectacion 0 en caso de no ser valido.\n",
    "    \n",
    "    if total_abolladura_area is not None and total_rayon_area is not None and total_abolladura_area > 0 and total_rayon_area > 0:\n",
    "        total_area_affected = abs(total_abolladura_area + total_rayon_area - total_car_area) # Si ambos tipos de afectacion existen en una imagen, se sumaran primero y restaran con el area del carro.\n",
    "    return total_area_affected\n",
    "\n",
    "df = process_segmentation_results(results_abolladura, results_rayon, results_car)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
