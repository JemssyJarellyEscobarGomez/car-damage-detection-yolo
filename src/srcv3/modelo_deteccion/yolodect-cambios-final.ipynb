{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga de librerías</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import sklearn\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación de herramientas de etiquetado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para instalar los paquetes\n",
    "\n",
    "def package_verification(package):\n",
    "    try:\n",
    "        output = os.popen('pip list').read()\n",
    "        return f'{package}' in output\n",
    "    except Exception as e:\n",
    "        print(f'Error en la verificación: {e}')\n",
    "        return False\n",
    "\n",
    "def package_installation(package_name):\n",
    "    if package_verification(package_name):\n",
    "        print(f\"El paquete '{package_name}' ya está instalado.\")\n",
    "    else:\n",
    "        print('Instalando el paquete... ')\n",
    "        try:\n",
    "            os.system(f'pip install {package_name}')\n",
    "            print(f'libreria {package_name} instalada correctamente! ')\n",
    "        except Exception as e:\n",
    "            print(f'Error en la instalación de {package_name}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El paquete 'labelme' ya está instalado.\n"
     ]
    }
   ],
   "source": [
    "package_installation('labelme') # Instalación de la herramienta de etiquetado Labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir la herramienta para el proceso de etiquetado \n",
    "try:\n",
    "    subprocess.check_call([\"labelme\"]) \n",
    "except Exception as e:\n",
    "    print(f'No fue posible abrir labelme: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El paquete 'labelme2yolo' ya está instalado.\n"
     ]
    }
   ],
   "source": [
    "package_installation('labelme2yolo') # Instalación de la herramienta de conversión para el formato JSON de labelme a formato texto requerido por los modelos de detección de objetos YOLO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga rutas</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder= os.getcwd() # Obtener ubicación actual\n",
    "main_folder= os.path.abspath(os.path.join(current_folder, \"../../../\")) # Carpeta main del proyecto\n",
    "main_staticos= os.path.abspath(os.path.join(main_folder))+'\\\\dist' # Carpeta main de los archivos estaticos\n",
    "main_production= os.path.abspath(main_folder) +'\\\\src' # Carpeta main de los archivos listos para producción \n",
    "dir_prueba= os.path.abspath(main_folder) + \"\\\\src\\\\assets\"  # Carpeta de imagenes prueba para el proceso de predecir\n",
    "\n",
    "training_structure=\"lote2_2\" # Indica el nombre de la carpeta que tiene los archivos para el entrenamiento (image, json)\n",
    "dir_train= os.path.abspath(main_staticos) + f'\\\\{training_structure}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuración de rutas de entrenamiento</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos de entrenamiento: 399\n",
      "Cantidad de archivos de validación: 98\n"
     ]
    }
   ],
   "source": [
    "# Función para separar la carpeta global de todos los datos en un 80% entrenamiento y 20% validación. Utilice esta función solo si no ha ordenado los datos en una carpeta para entrenamiento y otra para validación.\n",
    "\n",
    "def file_separation(orig_folder):\n",
    "    file_list = os.listdir(orig_folder)\n",
    "    train, val= train_test_split(file_list, test_size=0.2, random_state=100) # Se divide el set de datos entrenamiento y validación aleatoriamente con una misma semilla\n",
    "    if not os.path.exists(\"train\"):\n",
    "        train_path = os.path.join(orig_folder, \"train\")\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "    move_files(train, orig_folder, train_path)\n",
    "    \n",
    "    if not os.path.exists(\"val\"):\n",
    "        val_path = os.path.join(orig_folder, \"val\")\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "    move_files(val, orig_folder, val_path)\n",
    "\n",
    "def move_files(file_list, orig_folder, dest_folder):\n",
    "    for file in file_list:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            orig_image_path = os.path.join(orig_folder, file)\n",
    "            json_name = os.path.splitext(file)[0] + \".json\"\n",
    "            \n",
    "            orig_json_path = os.path.join(orig_folder, json_name)\n",
    "            dest_image_path = os.path.join(dest_folder, file)\n",
    "            dest_json_path = os.path.join(dest_folder, json_name)\n",
    "            \n",
    "            shutil.copy(orig_image_path, dest_image_path)\n",
    "            shutil.copy(orig_json_path, dest_json_path)\n",
    "\n",
    "file_separation(dir_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Conversión a formato YOLO</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión completada para la carpeta c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\lala\\train\n",
      "Conversión completada para la carpeta c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\lala\\val\n"
     ]
    }
   ],
   "source": [
    "# Función para convertir la carpeta de entrenamiento y validación en formato YOLO\n",
    "# Hacer que permita realizar la conversion si ya se tiene separado\n",
    "def convert_to_yolo_format(training_directory, validation_directory):\n",
    "    try:\n",
    "        subprocess.check_call([\"labelme2yolo\", \"--json_dir\", training_directory])\n",
    "        print(f'Conversión completada para la carpeta {training_directory}')\n",
    "        subprocess.check_call([\"labelme2yolo\", \"--json_dir\", validation_directory])\n",
    "        print(f'Conversión completada para la carpeta {validation_directory}')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar función labelme2yolo: {e}')\n",
    "\n",
    "train_path= os.path.abspath(dir_train) + \"\\\\train\"\n",
    "val_path= os.path.abspath(dir_train) + \"\\\\val\"\n",
    "\n",
    "convert_to_yolo_format(train_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organización de la estructura del repositorio YOLODataset (resultado de la conversión .json a formato YOLO) creado por defecto\n",
    "\n",
    "def reorganization(path):\n",
    "    try:\n",
    "        new_path = os.path.abspath(os.path.join(path, \"YOLODataset\"))\n",
    "        main_folders = os.listdir(new_path)\n",
    "        for folder_instance in main_folders:\n",
    "            secondary_folder_path = os.path.join(new_path, folder_instance)\n",
    "            if os.path.isdir(secondary_folder_path):\n",
    "                secondary_folders = os.listdir(secondary_folder_path)\n",
    "                for secondary_folder in secondary_folders:\n",
    "                    subfolder_secondary_path = os.path.join(secondary_folder_path, secondary_folder)\n",
    "                    try:\n",
    "                        if os.listdir(subfolder_secondary_path) != []:\n",
    "                            for file in os.listdir(subfolder_secondary_path):\n",
    "                                orig_path = os.path.join(subfolder_secondary_path, file)\n",
    "                                dest_path = os.path.abspath(os.path.join(subfolder_secondary_path, \"../\"))\n",
    "                                new_dest_path = os.path.join(dest_path, file)\n",
    "                                shutil.move(orig_path, new_dest_path)\n",
    "                            os.rmdir(subfolder_secondary_path)\n",
    "                        else:\n",
    "                            os.rmdir(subfolder_secondary_path)\n",
    "                    except NotADirectoryError as e:\n",
    "                        print(f'Error: the element is not a folder: {e}')\n",
    "        return new_path\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "yolo_train_data= reorganization(train_path)\n",
    "yolo_val_data= reorganization(val_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mover las carpetas yolo \n",
    "\n",
    "def acomodar_rutas_dataset(main_staticos, dataset_train, dataset_val):\n",
    "    try:\n",
    "        if not os.path.exists(\"data_afectacion\"):\n",
    "            try: \n",
    "                paths_segmentation= os.path.join(main_staticos, \"data_afectacion\")\n",
    "                os.makedirs(paths_segmentation, exist_ok=True)\n",
    "                if os.listdir(paths_segmentation) == []:\n",
    "                    shutil.move(dataset_train, os.path.join(paths_segmentation, \"YOLODataset_train\"))\n",
    "                    shutil.move(dataset_val, os.path.join(paths_segmentation, \"YOLODataset_val\"))\n",
    "                    print(f'Carpetas movidas exitosamente a {paths_segmentation} ')\n",
    "                else:\n",
    "                    print(f'Las carpetas ya se encuentran en {paths_segmentation} ')\n",
    "            except OSError as e:\n",
    "                print(f'Error al intentar crear la carpeta en {paths_segmentation}: {e}')\n",
    "        return paths_segmentation  \n",
    "    except TypeError as e:\n",
    "        print(f'Tipo de dato incorrecto para el argumento: {e}')\n",
    "\n",
    "detect_routes= acomodar_rutas_dataset(main_staticos, yolo_train_data, yolo_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set de funciones para ordenar la estructura de los dataset individuales.\n",
    "\n",
    "def arrange_dataset_paths(train, val):\n",
    "    destination = os.path.abspath(os.path.join(train, \"../../\"))\n",
    "    shutil.move(train, destination)\n",
    "    if \"dataset.yaml\" in os.listdir(os.path.join(val, \"../\")):\n",
    "        os.remove(val)\n",
    "\n",
    "# Función para reescribir el dataset\n",
    "def rewrite_dataset(dir_train_converted, combined_list):\n",
    "    with open(dir_train_converted, 'w') as new_dataset:\n",
    "        new_dataset.write(\n",
    "            f'train: {os.path.abspath(os.path.join(dir_train_converted, \"../\"))}\\n'\n",
    "            f'val: {os.path.abspath(os.path.join(dir_train_converted, \"../../\"))}\\\\YOLODataset_val\\n'\n",
    "            'test: \\n'\n",
    "            f'nc: {len(combined_list)}\\n'\n",
    "            f'names: {combined_list}\\n'\n",
    "        )\n",
    "        \n",
    "# Función para combinar los dos dataset generados\n",
    "def total_labels(list1, list2, update_dataset_train):\n",
    "    set1=set(list1)\n",
    "    set2=set(list2)\n",
    "    union_without_repeating = set1.union(set2)\n",
    "    combined_list = list(union_without_repeating)\n",
    "    rewrite_dataset(update_dataset_train, combined_list)\n",
    "\n",
    "# Función para extraer los nombres de las etiquetas de los dos dataset separados\n",
    "def extract_labels(main_route):\n",
    "    try:\n",
    "        route_dataset_train= os.path.abspath(main_route) + \"\\\\YOLODataset_train\\\\dataset.yaml\"\n",
    "        route_dataset_val= os.path.abspath(main_route) + \"\\\\YOLODataset_val\\\\dataset.yaml\"\n",
    "        \n",
    "        with open(route_dataset_train, 'r') as file_train:\n",
    "            data_train = yaml.safe_load(file_train)\n",
    "            labels_train = data_train['names']\n",
    "        with open(route_dataset_val,'r') as file_val:\n",
    "            data_val= yaml.safe_load(file_val)\n",
    "            labels_val= data_val['names']\n",
    "        total_labels(labels_train, labels_val, route_dataset_train)\n",
    "        \n",
    "        return route_dataset_train, route_dataset_val\n",
    "    except (TypeError, FileNotFoundError) as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "try:\n",
    "    train, val= extract_labels(detect_routes)\n",
    "    arrange_dataset_paths(train, val)\n",
    "except TypeError as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar la carpeta que contiene la configuración completa para el entrenamiento\n",
    "data_train= os.path.abspath(main_staticos) + \"\\\\data_afectacion\\\\dataset.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Selección versión de modelo YOLOv8</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificación de las rutas de las carpetas predeterminadas de ultralytics YOLO\n",
    "\n",
    "def set_config_ultralytics(main):\n",
    "    settings.update({'datasets_dir': f'{main}\\\\dist', 'weights_dir': f'{main}\\\\src', 'runs_dir': f'{main}\\\\src\\\\runs'})\n",
    "set_config_ultralytics(main_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Modelo original</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de variantes en la Segmentación de instancias con YOLOv8\n",
    "\n",
    "| Modelo      | Nombres de archivo                                      | Identificador |\n",
    "|-------------|-----------------------------------------------------|------------|\n",
    "| YOLOv8-seg  | yolov8n-seg.pt yolov8s-seg.pt yolov8m-seg.pt yolov8l-seg.pt yolov8x-seg.pt | n, s, m, l, x |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('gdown') # Librería que le permitira descargar las versiones de YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se está utilizando la versión \"yolov8x.pt\" del modelo. \n"
     ]
    }
   ],
   "source": [
    "def get_model_version():\n",
    "    available_versions= ['n', 's', 'm', 'l', 'x'] # yolov8n.pt , yolov8s.pt , yolov8m.pt , yolov8l.pt , yolov8x.pt\n",
    "    control= True\n",
    "    while control:\n",
    "        version_selection= input(\"Ingrese la versión del modelo que desea utilizar, entre las disponibles están: n, s, m, l, x. Advertencia: Si no desea instalar ninguna ingrese la palabra 'salir'! \") \n",
    "        if version_selection in available_versions:\n",
    "            id_version= f'yolov8{version_selection}.pt' \n",
    "            return id_version\n",
    "        elif version_selection == \"salir\":\n",
    "            control=False\n",
    "            return None\n",
    "        else:\n",
    "            print('Version de modelo inexistente, ingrese nuevamente! ')\n",
    "     \n",
    "def model_installation(url, version_name):\n",
    "    try:\n",
    "        path_save = os.path.abspath(main_folder) + \"\\\\dist\\\\model_version\\\\\" + version_name\n",
    "        if os.path.exists(path_save):\n",
    "            print(f'Se está utilizando la versión \"{version_name}\" del modelo. ')\n",
    "        else:\n",
    "            url_installation = f'{url}/{version_name}'\n",
    "            gdown.download(url_installation, path_save, quiet=False)\n",
    "            print('Versión instalada correctamente!')\n",
    "    except (NameError, UnboundLocalError) as e:\n",
    "        print(f'Error en la instalación de la versión del modelo: {e}')\n",
    "    return path_save\n",
    "\n",
    "model_url= 'https://github.com/ultralytics/assets/releases/download/v0.0.0' \n",
    "model_version= get_model_version()\n",
    "\n",
    "if model_version is not None:\n",
    "    model_orig= model_installation(model_url, model_version) \n",
    "else:\n",
    "    print('Ha salido con exito! ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Modelo entrenado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los pesos del experimento que se van a utilizar son c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv3\\modelo_deteccion\\deteccion\\prueba_entrenamiento\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Función para obtener el último entrenamiento\n",
    "\n",
    "def get_last_training(dir_src):\n",
    "    try:\n",
    "        yolo_model_folders= os.listdir(dir_src)\n",
    "        for folder_name in yolo_model_folders:\n",
    "            if folder_name == \"deteccion\":\n",
    "                base_path = os.path.abspath(os.path.join(dir_src, folder_name))\n",
    "                files= os.listdir(base_path)\n",
    "                last_experiment = sorted(files)[-1]\n",
    "                return os.path.join(base_path, last_experiment, \"weights\", \"best.pt\")\n",
    "        return None\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "version= \"srcv3\"\n",
    "dir_model_version=os.path.abspath(os.path.join(main_production, version)+ \"\\\\modelo_deteccion\")\n",
    "model_train= get_last_training(dir_model_version) \n",
    "\n",
    "if model_train:\n",
    "    print(f'Los pesos del experimento que se van a utilizar son {model_train}')\n",
    "else:\n",
    "    print(f'No existe ningún experimento de entrenamiento en la carpeta {dir_model_version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación de recursos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El paquete 'ultralytics' ya está instalado.\n"
     ]
    }
   ],
   "source": [
    "package_installation('ultralytics') # Instalación de la biblioteca Ultralytics\n",
    "#ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarjeta Grafica: Caption                  \n",
      "\n",
      "AMD Radeon(TM) Graphics.\n",
      " \n",
      "Advertencia: Debe utilizar la CPU para instalación de PyTorch! \n"
     ]
    }
   ],
   "source": [
    "#Función para determinar si tiene GPU Cuda para instalación de PYTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'CUDA: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    try:\n",
    "        command = 'wmic path win32_videocontroller get caption'\n",
    "        device = subprocess.check_output(command, shell=True, universal_newlines=True)\n",
    "        print(f'Tarjeta Grafica: {device.strip()}.\\n \\nAdvertencia: Debe utilizar la CPU para instalación de PyTorch! ')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar el comando: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Dirección para instalar mediante el comando la versión de PyTorch en función de los requerimientos computacionales: </span>[Versión PyTorch](https://pytorch.org/get-started/locally/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_pytorch = 'pip3 install torch torchvision torchaudio' # Comando de instalación según la version personalizada a sus requerimientos computacionales\n",
    "substrings = command_pytorch.split(\" \")\n",
    "try:\n",
    "    subprocess.check_call(substrings)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f'Error al instalar la version de PyTorch: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">ENTRENAMIENTO</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.17 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\model_version\\yolov8n.pt, data=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\dataset.yaml, epochs=30, patience=30, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=1, project=deteccion, name=prueba_entrenamiento, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=deteccion\\prueba_entrenamiento\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA not detected, using default CPU batch-size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_train\\labels.cache... 199 images, 0 backgrounds, 0 corrupt: 100%|██████████| 199/199 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_val\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to deteccion\\prueba_entrenamiento\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mdeteccion\\prueba_entrenamiento\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      2.077       3.57      1.761        100        640: 100%|██████████| 13/13 [01:26<00:00,  6.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0048      0.399     0.0596     0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.938      2.999      1.612         75        640: 100%|██████████| 13/13 [01:17<00:00,  5.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00646       0.55     0.0397     0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.891       2.83      1.569         61        640: 100%|██████████| 13/13 [01:18<00:00,  6.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00794      0.605     0.0363     0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.888      2.743      1.588         94        640: 100%|██████████| 13/13 [01:22<00:00,  6.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.112     0.0896     0.0529     0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G       1.87      2.638      1.578         93        640: 100%|██████████| 13/13 [01:23<00:00,  6.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235       0.54     0.0543     0.0337     0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G      1.923      2.599      1.596        123        640: 100%|██████████| 13/13 [01:23<00:00,  6.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.551      0.109     0.0477      0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.915      2.595        1.6         76        640: 100%|██████████| 13/13 [01:22<00:00,  6.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0948      0.159     0.0432     0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G      1.985      2.546      1.584        127        640: 100%|██████████| 13/13 [01:24<00:00,  6.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0878       0.17     0.0469     0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.945      2.548      1.583        105        640: 100%|██████████| 13/13 [01:18<00:00,  6.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.112      0.243     0.0714     0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G      1.894      2.473      1.582        106        640: 100%|██████████| 13/13 [01:19<00:00,  6.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.145      0.137     0.0638      0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G      1.926      2.499      1.583         61        640: 100%|██████████| 13/13 [01:17<00:00,  5.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0834       0.24     0.0555     0.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G      1.959       2.44      1.609        142        640: 100%|██████████| 13/13 [01:19<00:00,  6.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.102      0.204     0.0542     0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G      1.909       2.43       1.59         75        640: 100%|██████████| 13/13 [01:19<00:00,  6.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.077      0.175     0.0381     0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.869      2.302      1.524        140        640: 100%|██████████| 13/13 [01:22<00:00,  6.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.128      0.197     0.0871     0.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.828      2.226      1.497        121        640: 100%|██████████| 13/13 [01:24<00:00,  6.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.149       0.17     0.0572     0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.826      2.269      1.512         93        640: 100%|██████████| 13/13 [01:22<00:00,  6.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.161      0.135      0.072     0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.814      2.157      1.467         65        640: 100%|██████████| 13/13 [01:24<00:00,  6.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.165      0.182      0.083     0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.778      2.128      1.449        137        640: 100%|██████████| 13/13 [01:20<00:00,  6.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.221      0.188      0.117     0.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.737      2.112      1.439         78        640: 100%|██████████| 13/13 [01:17<00:00,  5.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.215      0.191      0.129     0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.741      2.078      1.425         53        640: 100%|██████████| 13/13 [01:21<00:00,  6.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.211      0.213      0.126     0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G      1.848      2.376      1.552         34        640: 100%|██████████| 13/13 [01:20<00:00,  6.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.176      0.215      0.122     0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.725      2.181      1.429         59        640: 100%|██████████| 13/13 [01:20<00:00,  6.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.206      0.167      0.125     0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G       1.73      2.167      1.446         28        640: 100%|██████████| 13/13 [01:18<00:00,  6.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.283      0.182      0.144     0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.719      2.145      1.447         28        640: 100%|██████████| 13/13 [01:16<00:00,  5.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.321      0.189      0.153     0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.705      2.098      1.431         55        640: 100%|██████████| 13/13 [01:15<00:00,  5.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.202      0.259      0.163     0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G       1.65      2.002        1.4         52        640: 100%|██████████| 13/13 [01:14<00:00,  5.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.248      0.269      0.155     0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G      1.641      1.965      1.393         53        640: 100%|██████████| 13/13 [01:15<00:00,  5.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.352      0.247      0.174     0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G      1.632      1.934      1.391         82        640: 100%|██████████| 13/13 [01:14<00:00,  5.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.307      0.291      0.186     0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G      1.571       1.89      1.375         32        640: 100%|██████████| 13/13 [01:14<00:00,  5.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.241      0.291      0.191     0.0776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G       1.56      1.796      1.338         35        640: 100%|██████████| 13/13 [01:14<00:00,  5.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.256      0.274      0.182     0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 0.720 hours.\n",
      "Optimizer stripped from deteccion\\prueba_entrenamiento\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from deteccion\\prueba_entrenamiento\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating deteccion\\prueba_entrenamiento\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.305      0.288      0.187     0.0793\n",
      "            abolladura         49         46      0.276       0.37      0.217      0.092\n",
      "                 rayon         49        189      0.334      0.206      0.158     0.0666\n",
      "Speed: 2.7ms preprocess, 83.4ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Results saved to \u001b[1mdeteccion\\prueba_entrenamiento\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --Inicio Menú\n",
    "while True:\n",
    "    try:\n",
    "        model_type = input('Qué tipo de modelo desea utilizar, indique \"original\" o \"entrenado\": ')\n",
    "        if model_type == \"original\":\n",
    "            model_detection= YOLO(model_orig)\n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        elif model_type == \"entrenado\":\n",
    "            model_detection= YOLO(model_orig) \n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        else:\n",
    "            print('Caracter no valido! Intente nuevamente.')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "# --Finalización Menú\n",
    "\n",
    "PROJECT='deteccion' # Le permite asignar un nombre al directorio de inicio que contendrá los experimentos de detección de objetos, y debe estar entre comillas; se recomienda no utilizar espacios en el nombre.\n",
    "NAME='prueba_entrenamiento' # El nombre del experimento entrenamiento para deteccion de objetos debe ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "TASK='detect' # Define la tarea principal que desea realizar con el modelo YOLO v8; para este caso, la deteccion de objetos implica identificar la ubicación y la clase de objetos en una imagen o un flujo de video.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada. Puede especificarlo como un número entero, como imgsz a 640 para obtener un cuadrado perfecto, o como una tupla, como imgsz=(640,480) para establecer dimensiones específicas de ancho y alto. Se recomienda ajustar este valor según el tamaño del objeto que desea detectar. Para la detencción de objetos pequeños, se recomienda aumentar el valor a más de 640 píxeles para obtener una resolución más alta.\n",
    "DATA=data_train  #  Le permite indicar la ruta al archivo que contiene los metadatos que utilizara el modelo detección de objetos y su configuración en formato YAML. Si especifica el valor data=None, el conjunto de datos coco128-seg.yaml se utiliza de forma predeterminada; de lo contrario, escriba la ruta al archivo YAML entre comillas utilizando barras diagonales (/) en lugar de barras invertidas (\\).\n",
    "EPOCHS=30 # Establezca el número de épocas del modelo YOLO v8 en la tarea de deteccion. Este valor representa el número total de iteraciones en todo el conjunto de datos de entrenamiento. Se recomienda experimentar con este parámetro dependiendo de la cantidad de imágenes disponibles. Si tiene un conjunto de datos grande, considere aumentar este valor por encima de 30 para obtener mejores resultados. Por otro lado, establecer epochs=None hará que el modelo continúe entrenándose hasta que la pérdida de validación deje de mejorar.\n",
    "BATCH=-1 # Define la cantidad de imágenes procesadas simultáneamente en una iteración del modelo YOLO v8 en la deteccion. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta automáticamente el tamaño del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del parámetro como un número entero.\n",
    "OPTIMIZER='auto' # Define el algoritmo de optimización para el modelo de deteccion YOLO. Su elección ajusta los pesos del modelo durante el entrenamiento y es crucial para la velocidad y rendimiento. Puede tomar valores como 'SGD', 'Adam', 'Adamax', 'AdamW', 'NAdam', 'RAdam', 'RMSProp' y 'auto', este último selecciona automáticamente el optimizador más adecuado a la tarea segmentación de objetos.\n",
    "WORKERS=1 # Especifica el número de hilos de trabajo para la carga de datos en el modelo deteccion YOLO. Es recomendable utilizar un número de subprocesos que se ajusten al número de núcleos del CPU disponibles en el sistema.\n",
    "DEVICE= 'cpu' # Especifica el dispositivo de ejecución para la versión del modelo yolov8 en la operación de deteccion. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generación de gráficos que permite visualizar y monitorear la pérdida y la precisión durante el entrenamiento de deteccion de objetos. Establecer plots=True activara la función; si desea desactivarla, establezca el valor del hiperparámetro en False.\n",
    "SAVE=True # Cuando se establece en True, el modelo guarda puntos de control periódicamente durante el entrenamiento de deteccion. Se recomienda tener cuidado al establecer este valor en Verdadero, ya que está relacionado con el hiperparámetro SAVE_PERIOD; si establece el valor del hiperparametro a False, la función Save_Period se desactivará.\n",
    "SAVE_PERIOD=-1 # Se utiliza para especificar con qué frecuencia se guardan los puntos de control durante el entrenamiento de deteccion. Si se establece en un valor mayor que 0, el modelo guardará puntos de control cada número especificado de épocas. Sin embargo, si save_period se establece en -1, significa que la función esta deshabilitada.\n",
    "PATIENCE=30 # Representa el número esperado de épocas durante el entrenamiento de deteccion. Si no se observa mejora en el conjunto de validación dentro de un período específico, se detiene el proceso. Esta técnica de parada temprana se utiliza para evitar el sobreajuste del modelo. Se recomienda ajustar este hiperparámetro en función de la duración esperada del entrenamiento.\n",
    "VERBOSE=True # Se utiliza para controlar el número de impresiones durante la ejecución del entrenamiento de deteccion. Para suprimir la salida de información básica únicamente, debe establecer el valor del hiperparámetro en False, pero si desea una salida de progreso más detallada, establezca el valor en True.\n",
    "RECT= False # Habilita la formación rectangular en cada lote, redimensionando las imágenes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de entrenamiento en la deteccion de objetos. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente lote.\n",
    "COS_LR=False # Reemplaza el decaimiento escalonado predeterminado de YOLOv8, que reduce la tasa de aprendizaje en ciertas épocas, con el decaimiento escalonado cos_lr. Este ajusta la tasa de aprendizaje según las épocas restantes y la tasa de aprendizaje inicial, proporcionando una disminución más suave. Establezca este hiperparámetro en True para una reducción gradual de la tasa de aprendizaje, de lo contrario establezca en False.\n",
    "FRACTION= 1.0 # Controla la fracción del conjunto de datos que se utilizara para el entrenamiento de deteccion. Debes establecer este parámetro entre 0.0 y 1.0. Por defecto, cuando es 1.0, se emplea el 100% de las imágenes disponibles en el conjunto de datos.\n",
    "EXIST_OK=False # Controla la sobreescritura de un experimento de deteccion existente. Cuando se establece en False, el sistema no sobrescribirá, en su lugar devolverá una ruta incrementada. Esto es útil para prevenir la sobreescritura accidental de experimentos anteriores. Para activar la función, asigna el valor True.\n",
    "try:\n",
    "    model_detection.train(project=PROJECT,name=NAME, task=TASK, data=DATA, imgsz=IMGSZ, epochs=EPOCHS, batch=BATCH, workers=WORKERS, device=DEVICE, plots=PLOTS, verbose=VERBOSE, rect=RECT, cos_lr=COS_LR, optimizer=OPTIMIZER, fraction=FRACTION, patience=PATIENCE, exist_ok=EXIST_OK)\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train= get_last_training(dir_model_version) # Llamado a la función que selecciona el último modelo entrenado por si acaso no se proporciona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">Configuración para la exportación</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra una tabla de referencia para exportar un modelo YOLOv8 entrenado en la tarea deteccion de objetos. Tenga en cuenta que configurar el parámetro de `format` es fundamental para el proceso de exportación. Antes de continuar, asegúrese de verificar y ajustar estos valores a sus requisitos específicos: \n",
    "| Formatos                                                             | Asignación | Extensión                     | Hyperparámetros                                            | Descripción                                        |\n",
    "|--------------------------------------------------------------------|-------------------|---------------------------|-----------------------------------------------------|----------------------------------------------------|\n",
    "| [PyTorch](https://pytorch.org/)                                    | -                 | `yolov8n.pt`              | -                                                   | Modelo en formato PyTorch                           |\n",
    "| [TorchScript](https://pytorch.org/docs/stable/jit.html)            | \"torchscript\"     | `yolov8n.torchscript`     | `imgsz`, `optimize`                                 | Simplifica la implementación de modelos PyTorch en entornos de producción y aplicaciones eficientes, mejorando la portabilidad y el rendimiento al permitir ejecutar una representación intermedia en entornos sin Python.                       |\n",
    "| [ONNX](https://onnx.ai/)                                           | \"onnx\"            | `yolov8n.onnx`            | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     | Desarrollado para promover la interoperabilidad, la optimización del hardware y la colaboración entre comunidades, al tiempo que responde a la necesidad de portabilidad de los modelos entre distintos marcos y herramientas de aprendizaje automático.                              |\n",
    "| [OpenVINO](https://docs.openvino.ai/latest/index.html)             | \"openvino\"        | `yolov8n_openvino_model/` | `imgsz`, `half`, `int8`                             | Elaborado para promover la interoperabilidad, la optimización del hardware y el despliegue eficiente de modelos a través de diferentes marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware Intel.                     |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt)                  | \"engine\"          | `yolov8n.engine`          | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` | Permite promover la interoperabilidad, la optimización del hardware y la implantación eficiente de modelos en distintos marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware de NVIDIA.                     |\n",
    "| [CoreML](https://github.com/apple/coremltools)                     | \"coreml\"          | `yolov8n.mlpackage`       | `imgsz`, `half`, `int8`, `nms`                      | Posibilita promover la interoperabilidad, la optimización del hardware y el despliegue eficiente de modelos a través de diferentes marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware de Apple.                            |\n",
    "| [TF SavedModel](https://www.tensorflow.org/guide/saved_model)      | \"saved_model\"     | `yolov8n_saved_model/`    | `imgsz`, `keras`, `int8`                            | Empleado para guardar, compartir y desplegar modelos entrenados con TensorFlow. Versátil y facilita el despliegue en diversas plataformas como servidores, dispositivos móviles, embebidos y navegadores.                     |\n",
    "| [TF Lite](https://www.tensorflow.org/lite)                         | \"tflite\"          | `yolov8n.tflite`          | `imgsz`, `half`, `int8`                             | Diseñado para el aprendizaje automático en dispositivos, TF Lite aborda restricciones clave como latencia, privacidad, conectividad, tamaño y consumo de energía. Es esencial para desplegar modelos en dispositivos móviles e integrados, ofreciendo una solución ligera y eficiente.                           |\n",
    "| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | \"edgetpu\"         | `yolov8n_edgetpu.tflite`  | `imgsz`                                             | Utilizado para desplegar modelos de aprendizaje automático en el Edge TPU de TensorFlow. El Edge TPU es un pequeño ASIC (Circuito Integrado Específico de Aplicación) diseñado por Google para ofrecer inferencias de aprendizaje automático de alto rendimiento en dispositivos de bajo consumo.                       |\n",
    "| [TF.js](https://www.tensorflow.org/js)                             | \"tfjs\"            | `yolov8n_web_model/`      | `imgsz`                                             | Facilita el despliegue de modelos de aprendizaje automático en navegadores web y Node.js, destacando la portabilidad y la facilidad de uso.                    |\n",
    "| [PaddlePaddle](https://github.com/PaddlePaddle)                    | \"paddle\"          | `yolov8n_paddle_model/`   | `imgsz`                                             | Utilizado para desplegar modelos en PaddlePaddle, una plataforma de aprendizaje profundo de código abierto, paralela y distribuida que tiene su origen en la práctica industrial.                      |\n",
    "| [ncnn](https://github.com/Tencent/ncnn)                            | \"ncnn\"            | `yolov8n_ncnn_model/`     | `imgsz`, `half`                                     | Formato optimizado para plataformas móviles, ofreciendo alto rendimiento. Puede incluir una estructura de archivo de modelo con información sobre capas, blobs de entrada y salida, y otros parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">EXPORTACIÓN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model_det=YOLO(model_train)\n",
    "\n",
    "FORMAT='onnx' # Seleccione el formato de exportación del modelo deteccion, empleando la tabla previamente proporcionada; en la columna \"Asignación\" se proporcionan las opciones para ajustar este valor.\n",
    "INT8=True # Establezca este parámetro en True al utilizar la CPU y en False en caso contrario. La cuantificación a INT8 mejora la eficiencia del modelo deteccion en cuanto a memoria y velocidad de inferencia, especialmente en hardware que admite esta precisión.\n",
    "HALF=False # Configúrelo en True cuando use la GPU; en caso contrario, False. La cuantificación a FP16 mejora la eficiencia de la memoria del modelo deteccion y la velocidad de inferencia, especialmente en hardware que admite precisión de punto flotante de 16 bits.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada para la exportación del modelo de deteccion. Puede especificarlo como un número entero, por ejemplo, 640 para un cuadrado perfecto, o como una tupla, por ejemplo, (640, 480) para dimensiones específicas de ancho y alto. Las imágenes que ingreses al modelo después de la exportación deben tener las mismas dimensiones específicas que has configurado para adaptarse a los requisitos del escenario de despliegue.\n",
    "OPTIMIZE=False # Controla la optimización en modelos de detección a TorchScript para su implementación móvil. Es importante destacar que esta función puede resultar en un aumento significativo en el tamaño del modelo exportado, lo cual puede no ser ideal para aplicaciones móviles. Se configura con True para activar y False para desactivar.\n",
    "DYNAMIC=False # Controla la habilitación de ejes dinámicos en modelos de deteccion, lo cual es particularmente útil para gestionar tamaños de lote variables. Esta característica funciona bien en escenarios donde el tamaño del lote puede cambiar durante la inferencia, como aplicaciones en tiempo real o de transmisión por secuencias. Los valores aceptados son Verdadero para habilitar la función y Falso para deshabilitarla.\n",
    "SIMPLIFY=False # En la exportación de modelos de deteccion a ONNX|TensorRT, este hiperparámetro personaliza la complejidad del modelo controlando la optimización, eliminando capas redundantes y reduciendo la precisión de los parámetros. Se activa con True y se desactiva con False.\n",
    "OPSET=False # Especifica la versión del conjunto de operadores en ONNX al exportar el modelo deteccion desde marcos como PyTorch o TensorFlow. Si se deja en \"None\", ONNX utilizará automáticamente la versión más reciente disponible; para una versión específica, asigne el número entre comillas, por ejemplo, \"11\".\n",
    "WORKSPACE=4 # En la exportación de modelos de deteccion a TensorRT, establece el tamaño del espacio de trabajo en GB asignado para optimizar y preparar el modelo de red neuronal. Este espacio se utiliza durante la construcción del motor para lograr una ejecución eficiente en hardware GPU mediante la biblioteca TensorRT.\n",
    "NMS=False # En la exportación de modelos de deteccion a CoreML, controla la inclusión de la Supresión No Máxima (NMS) en el modelo para eliminar cuadros delimitadores redundantes en la segmentación de instancias y mejorar la precisión de las predicciones. Establecer 'NMS' en 'False' ignora NMS en los modelos CoreML exportados.  Este ajuste, configurable durante la exportación del modelo YOLO, lo que permite a los usuarios optimizar la implementación del modelo en una variedad de plataformas y dispositivos.\n",
    "KERAS= False # En la exportación de modelos de deteccion a TF SavedModel y TF Lite, permite optimizar el despliegue en diversas plataformas y dispositivos. Incluye también el formato del archivo, el dispositivo de ejecución y la posibilidad de manejar múltiples etiquetas por caja. Establezca el valor del hiperparámetro en True si está familiarizado con Keras; de lo contrario, en False para excluir su uso en la exportación.\n",
    "\n",
    "selected_model_det.export(format=FORMAT, imgsz=640, dynamic=False, simplify=False, opset=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">VALIDACIÓN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\YOLODataset_val\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:06<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235          1      0.865       0.93       0.93\n",
      "            abolladura         49        189          1       0.73      0.865      0.865\n",
      "                 rayon         49         46          1          1      0.995      0.995\n",
      "Speed: 3.2ms preprocess, 114.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\Prueba_validación_det\\predictions.json...\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\Prueba_validación_det\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --Inicio Menú\n",
    "while True:\n",
    "    try:\n",
    "        model_type = input('Qué tipo de modelo desea utilizar, indique \"original\" o \"entrenado\": ')\n",
    "        if model_type == \"original\":\n",
    "            selected_model_det=YOLO(model_orig)\n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        elif model_type == \"entrenado\":\n",
    "            selected_model_det=YOLO(model_train)\n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        else:\n",
    "            print('Caracter no valido! Intente nuevamente.')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "# --Finalización Menú\n",
    "\n",
    "NAME='Prueba_validación_det' # El nombre del experimento de validación para deteccion de objetos deben ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "DATA= data_train #Permite indicar la ruta al archivo que contiene los metadatos necesarios para el proceso de validación, la ruta debe ser proporcionada entre comillas.\n",
    "IMGSZ=640 # Establece las dimensiones en píxeles de la imagen de entrada para la validación del modelo de deteccion. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda usar el mismo valor que utilizo durante el entrenamiento del modelo.\n",
    "BATCH=16 # Define la cantidad de imágenes procesadas simultáneamente en una iteración para la validación en detecciones de objetos. El valor predeterminado es 16; se recomienda establecerlo en -1 para utilizar AutoBatch, que ajusta automáticamente el tamaño del lote para optimizar el rendimiento y la eficiencia del entrenamiento, evitando problemas de memoria. Si desea personalizarlo, establezca el valor como un número entero.\n",
    "SAVE_HYBRID=True # Activa la función con True para guardar una versión híbrida de la etiqueta, incluyendo la original y predicciones adicionales. Útil para el análisis detallado del rendimiento del modelo deteccion durante la validación; establezca en False para mostrar solo las predicciones.\n",
    "CONF=0.5 # Establece el umbral de confianza para la validación de clases en la tarea de deteccion. Se recomienda un valor entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión. \n",
    "MAX_DET=10 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara detectar en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "DEVICE='CPU' # Especifica el dispositivo de ejecución para la prueba de validación en la operación de deteccion. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generación de gráficos que permite visualizar y monitorear la pérdida y la precisión durante la validación en la deteccion de objetos. Establecer plots=True activara la función; si desea desactivarla, establezca el valor del hiperparámetro en False.\n",
    "RECT=False # Habilita la formación rectangular en cada lote, redimensionando las imágenes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de validación en la deteccion de objetos. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente.\n",
    "IOU=0.6 # El umbral predeterminado para la supresión no máxima (NMS) en la validación YOLO es 0,6. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren el mismo objeto. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "\n",
    "try:\n",
    "    selected_model_det.val(name=NAME, data=DATA, imgsz=IMGSZ, batch=BATCH, save_hybrid=SAVE_HYBRID, conf=CONF, max_det=MAX_DET, device=DEVICE, plots=PLOTS, rect=RECT, iou=IOU, save_json=True)\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuración de fuentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar múltiples fuentes de datos al realizar predicciones con el modelo, se requiere que se ajuste el parámetro'source' a sus necesidades, tal como se indica en la siguiente tabla:\n",
    "| Fuentes          | Asignación                             | Tipo             | Notas                                                           |\n",
    "| --------------- | ------------------------------------ | ----------------- | --------------------------------------------------------------- |\n",
    "| `image`           | 'image.jpg'                          | str or Path       | Archivo que contiene una única imagen.                                              |\n",
    "| `URL`             | 'https://ultralytics.com/images/bus.jpg' | str               | Dirección que especifica la ubicación de una imagen en la web.                                                 |\n",
    "| `screenshot`      | 'screen'                             | str               | El sistema captura la imagen actualmente visible en la pantalla y la utiliza como entrada para el modelo.                                           |\n",
    "| `PIL`             | Image.open('im.jpg')                 | PIL.Image         | Utilizado para cargar imágenes en formato HWC (altura, ancho, canales) con canales RGB (rojo, verde y azul) mediante la biblioteca Python Imaging Library (PIL).                                   |\n",
    "| `OpenCV`          | cv2.imread('im.jpg')                 | np.ndarray        | Permite la lectura de una imagen desde un archivo en formato HWC con canales BGR (azul, verde, rojo) utilizando la biblioteca OpenCV, almacenando la imagen como un array de NumPy.                    |\n",
    "| `numpy`           | np.zeros((640,1280,3))               | np.ndarray        | Genera un array de ceros con las dimensiones especificadas para un formato HWC con canales BGR, utilizando la biblioteca NumPy.                    |\n",
    "| `torch`           | torch.zeros(16,3,320,640)            | torch.Tensor      | Crea un tensor de ceros con las dimensiones especificadas para un formato HWC con canales RGB, empleando el framework PyTorch.               |\n",
    "| `CSV`             | 'sources.csv'                        | str or Path       | Archivo de texto que almacena las rutas a las imágenes que se procesarán.   |\n",
    "| `video`          | 'video.mp4'                          | str or Path       | Proporciona acceso a un archivo de video único.                       |\n",
    "| `directory`      | 'path/'                              | str or Path       | Directorio que contiene múltiples archivos de imagen.               |\n",
    "| `glob`           | 'path/*.jpg'                         | str               | Permite acceder a varias imágenes en un directorio usando expresiones de coincidencia de patrones. |\n",
    "| `YouTube`        | 'https://youtu.be/LNwODJXcvt4'       | str               | Facilita el acceso a videos desde la plataforma YouTube.                                         |\n",
    "| `stream`         | 'rtsp://example.com/media.mp4'      | str               | Permite la conexión a flujos de video o audio en tiempo real mediante protocolos como RTSP, RTMP, TCP o IP, ya sea a través de internet o una red local. |\n",
    "| `multi-stream`   | 'list.streams'                       | str or Path       | Se utiliza para transmitir varios flujos de medios simultáneamente, permitiendo el procesamiento y análisis paralelo de múltiples flujos de medios. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatos para las imágenes: \n",
    "\n",
    "| Image Suffixes | Reference                           |\n",
    "| --------------- | ----------------------------------- |\n",
    "| .bmp            | [Microsoft BMP File Format](https://docs.fileformat.com/es/image/bmp/)           |\n",
    "| .dng            | [Adobe DNG](https://docs.fileformat.com/es/image/dng/)                           |\n",
    "| .jpeg           | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .jpg            | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .mpo            | [Multi Picture Object](https://docs.fileformat.com/es/image/mpo/)                |\n",
    "| .png            | [Portable Network Graphics](https://docs.fileformat.com/es/image/png/)           |\n",
    "| .tif            | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .tiff           | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .webp           | [WebP](https://docs.fileformat.com/es/image/webp/)                                |\n",
    "| .pfm            | [Portable FloatMap](https://docs.fileformat.com/font/pfm/)                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatos para los videos: \n",
    "\n",
    "| Video Suffixes | Reference                           |\n",
    "| -------------- | ----------------------------------- |\n",
    "| .asf           | [Advanced Systems Format](https://docs.fileformat.com/es/video/asf/)             |\n",
    "| .avi           | [Audio Video Interleave](https://docs.fileformat.com/es/video/avi/)              |\n",
    "| .gif           | [Graphics Interchange Format]()          |\n",
    "| .m4v           | [MPEG-4 Part 14](https://docs.fileformat.com/es/video/m4v/)                      |\n",
    "| .mkv           | [Matroska](https://docs.fileformat.com/es/video/mkv/)                            |\n",
    "| .mov           | [QuickTime File Format](https://docs.fileformat.com/es/video/mov/)               |\n",
    "| .mp4           | [MPEG-4](https://docs.fileformat.com/es/video/mp4/)          |\n",
    "| .mpeg          | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .mpg           | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .ts            | [MPEG Transport Stream](https://docs.fileformat.com/es/video/ts/)               |\n",
    "| .wmv           | [Windows Media Video](https://docs.fileformat.com/es/video/wmv/)                 |\n",
    "| .webm          | [WebM Project](https://docs.fileformat.com/es/video/webm/)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">PREDICCIÓN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 2 rayons, 144.3ms\n",
      "image 2/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 (no detections), 100.0ms\n",
      "image 3/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 (no detections), 52.0ms\n",
      "image 4/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 3 rayons, 88.0ms\n",
      "image 5/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 (no detections), 78.0ms\n",
      "image 6/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 2 rayons, 114.0ms\n",
      "image 7/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 181.0ms\n",
      "image 8/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 1 rayon, 71.0ms\n",
      "image 9/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 (no detections), 86.0ms\n",
      "image 10/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 (no detections), 66.0ms\n",
      "image 11/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 (no detections), 68.0ms\n",
      "image 12/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 (no detections), 111.0ms\n",
      "image 13/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 (no detections), 83.0ms\n",
      "image 14/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 1 rayon, 85.0ms\n",
      "image 15/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 (no detections), 76.0ms\n",
      "image 16/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 72.0ms\n",
      "image 17/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 1 rayon, 66.0ms\n",
      "image 18/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 1 rayon, 65.0ms\n",
      "image 19/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 (no detections), 77.0ms\n",
      "image 20/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 (no detections), 55.0ms\n",
      "image 21/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg: 448x640 (no detections), 67.0ms\n",
      "image 22/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 93.0ms\n",
      "image 23/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 (no detections), 172.0ms\n",
      "image 24/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 2 rayons, 59.0ms\n",
      "image 25/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 (no detections), 103.0ms\n",
      "Speed: 2.0ms preprocess, 89.3ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\PruebaPrediccion_abolladura\u001b[0m\n",
      "8 labels saved to c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\PruebaPrediccion_abolladura\\labels\n",
      "\n",
      "image 1/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 (no detections), 103.0ms\n",
      "image 2/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 2 abolladuras, 177.0ms\n",
      "image 3/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 3 abolladuras, 66.0ms\n",
      "image 4/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 1 abolladura, 71.0ms\n",
      "image 5/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 5 abolladuras, 114.0ms\n",
      "image 6/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 (no detections), 81.0ms\n",
      "image 7/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 1 abolladura, 118.0ms\n",
      "image 8/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 (no detections), 100.0ms\n",
      "image 9/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 1 abolladura, 103.0ms\n",
      "image 10/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 2 abolladuras, 76.0ms\n",
      "image 11/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 2 abolladuras, 63.0ms\n",
      "image 12/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 1 abolladura, 70.0ms\n",
      "image 13/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 4 abolladuras, 81.0ms\n",
      "image 14/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 2 abolladuras, 75.0ms\n",
      "image 15/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 2 abolladuras, 51.0ms\n",
      "image 16/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 52.0ms\n",
      "image 17/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 (no detections), 60.0ms\n",
      "image 18/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 (no detections), 62.0ms\n",
      "image 19/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 1 abolladura, 72.0ms\n",
      "image 20/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 2 abolladuras, 70.0ms\n",
      "image 21/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg: 448x640 3 abolladuras, 80.0ms\n",
      "image 22/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 2 abolladuras, 87.0ms\n",
      "image 23/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 2 abolladuras, 94.0ms\n",
      "image 24/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 abolladura, 56.0ms\n",
      "image 25/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 5 abolladuras, 75.0ms\n",
      "Speed: 2.1ms preprocess, 82.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\PruebaPrediccion_rayon\u001b[0m\n",
      "18 labels saved to c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\PruebaPrediccion_rayon\\labels\n",
      "\n",
      "image 1/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 1 car, 657.5ms\n",
      "image 2/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 1 car, 881.6ms\n",
      "image 3/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 1 car, 389.2ms\n",
      "image 4/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 1 car, 688.8ms\n",
      "image 5/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 1 car, 787.8ms\n",
      "image 6/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 (no detections), 910.8ms\n",
      "image 7/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 981.5ms\n",
      "image 8/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 1 car, 878.0ms\n",
      "image 9/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 1 car, 768.6ms\n",
      "image 10/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 (no detections), 638.0ms\n",
      "image 11/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 1 car, 839.0ms\n",
      "image 12/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 2 cars, 973.2ms\n",
      "image 13/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 1 car, 872.0ms\n",
      "image 14/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 1 car, 741.0ms\n",
      "image 15/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 4 cars, 485.0ms\n",
      "image 16/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 545.0ms\n",
      "image 17/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 (no detections), 604.2ms\n",
      "image 18/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 1 car, 783.4ms\n",
      "image 19/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 1 car, 682.5ms\n",
      "image 20/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 1 car, 786.0ms\n",
      "image 21/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg: 448x640 1 car, 751.4ms\n",
      "image 22/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 1117.1ms\n",
      "image 23/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 (no detections), 1115.5ms\n",
      "image 24/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 car, 620.1ms\n",
      "image 25/25 C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 (no detections), 970.3ms\n",
      "Speed: 2.2ms preprocess, 778.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\PruebaPrediccion_carro\u001b[0m\n",
      "17 labels saved to c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\detect\\PruebaPrediccion_carro\\labels\n"
     ]
    }
   ],
   "source": [
    "#SOURCE= dir_prueba # Establezca el origen de datos que el modelo de detección utilizará para realizar predicciones. Configure el valor de este hiperparámetro según la tabla proporcionada anteriormente.\n",
    "SOURCE= \"C:/Users/matrix/pruebayolo/proyecto_yolo/src/assets_affectation\"\n",
    "MAX_DET=10 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara predecir en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada durante la predicción en tareas de detección. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda utilizar los mismos valores utilizados durante el entrenamiento del modelo para mantener la coherencia en la inferencia.\n",
    "CONF=0.5 # Establece el umbral de confianza durante el proceso de predicción en la tarea de detección. Se recomienda establecer el valor hiperparámetro entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión en la inferencia.\n",
    "LINE_WIDTH= None # Determina el grosor en píxeles de los cuadros delimitadores que rodean los objetos detectados por el modelo. Puede establecer el grosor de la línea como un número entero en el que, a mayor valor, la línea será más gruesa, también puede utilizar como valor None para que el grosor se ajuste de forma automatizada, proporcionando una línea proporcional al tamaño de la imagen.\n",
    "VISUALIZE=False # Determina si las características del modelo de detección deben mostrarse durante la predicción. Establecer esto en True permite que las características se muestren como mapas intermedias, lo que hace que el modelo sea más fácil de entender. Si se establece en False, no se mostrarán las características del modelo. \n",
    "IOU=0.7 # El umbral predeterminado para la supresión no máxima (NMS) en la validación YOLO es 0,7. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren la misma detección. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "DEVICE='cpu' # Especifica el dispositivo de ejecución para la prueba de predicción en la operación de detección. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "VID_STRIDE=False # Controla la velocidad de los fotogramas durante el proceso de predicción en vídeos o secuencias de tiempo real. Al establecerlo en True el modelo se adapta a la velocidad de fotogramas especificada por la fuente de vídeo, procesando cada fotograma individualmente. Para desactivar esta función indique como valor False.\n",
    "STREAM_BUFFER=False # Controla el almacenamiento en búfer de los fotogramas para la detección. Si es True, se almacenan todos los fotogramas para el procesamiento en tiempo real de vídeos o transmisiones en directo; si es False, devuelve el fotograma más reciente.\n",
    "SAVE_FRAMES=False # Controla la captura y almacenamiento de los fotogramas predichos por el modelo de detección. Con True, se guardarán todos los fotogramas individuales predichos; con False, no se realizará el almacenamiento de los fotogramas.\n",
    "AUGMENT=False # Aplica transformaciones a las imágenes de entrada, tales como giros, rotaciones, recortes y cambios de color, para diversificar los datos y mejorar la predicción en la detección. Establecer en True para activar la función, False para desactivar.\n",
    "SAVE_CROP=True # Determina si se deben guardar imágenes recortadas con los resultados durante la predicción en la detección. Al establecerlo en \"False\", las imágenes recortadas no se guardarán, lo que reduce el tamaño del archivo. Con el valor \"True\", se guardarán las imágenes recortadas correspondientes a las áreas detectadas.\n",
    "SHOW=False # Determina si se deben mostrar las imágenes o vídeos detectados durante la predicción. Al establecerlo en \"True\", permite la visualización de las predicciones en el mismo entorno, proporcionando una representación visual de los resultados. Si se establece en \"False\", las predicciones no se mostrarán. \n",
    "\n",
    "def train_classes(model_preentrenado, model_original):\n",
    "    try:\n",
    "        selected_model_det=YOLO(model_preentrenado)\n",
    "        \n",
    "        resultado_rayon= selected_model_det.predict(name='PruebaPrediccion_abolladura', source=SOURCE,conf=0.4, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=1,  save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save=True, save_conf=True) \n",
    "        \n",
    "        resultado_abolladura= selected_model_det.predict(name='PruebaPrediccion_rayon', source=SOURCE,conf=0.2, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=0,  save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save=True, save_conf=True)\n",
    "        \n",
    "        if resultado_rayon or resultado_abolladura is not None:\n",
    "            \n",
    "            selected_model_det_car=YOLO(model_original)\n",
    "            resultado_carro= selected_model_det_car.predict(name='PruebaPrediccion_carro', source=SOURCE,conf=CONF, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=2,  save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save=True, save_conf=True) \n",
    "            \n",
    "        return resultado_rayon, resultado_abolladura, resultado_carro\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error en el entrenamiento del modelo: {e}')\n",
    "\n",
    "results_rayon, results_abolladura, results_car= train_classes(model_train, model_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Función de área para cajas detectadas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Dataframe con las áreas totales</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7b6a8_row0_col0, #T_7b6a8_row0_col1, #T_7b6a8_row0_col2, #T_7b6a8_row0_col3, #T_7b6a8_row0_col4, #T_7b6a8_row1_col0, #T_7b6a8_row1_col1, #T_7b6a8_row1_col2, #T_7b6a8_row1_col3, #T_7b6a8_row1_col4, #T_7b6a8_row2_col0, #T_7b6a8_row2_col1, #T_7b6a8_row2_col2, #T_7b6a8_row2_col3, #T_7b6a8_row2_col4, #T_7b6a8_row3_col0, #T_7b6a8_row3_col1, #T_7b6a8_row3_col2, #T_7b6a8_row3_col3, #T_7b6a8_row3_col4, #T_7b6a8_row4_col0, #T_7b6a8_row4_col1, #T_7b6a8_row4_col2, #T_7b6a8_row4_col3, #T_7b6a8_row4_col4, #T_7b6a8_row5_col0, #T_7b6a8_row5_col1, #T_7b6a8_row5_col2, #T_7b6a8_row5_col3, #T_7b6a8_row5_col4, #T_7b6a8_row6_col0, #T_7b6a8_row6_col1, #T_7b6a8_row6_col2, #T_7b6a8_row6_col3, #T_7b6a8_row6_col4, #T_7b6a8_row7_col0, #T_7b6a8_row7_col1, #T_7b6a8_row7_col2, #T_7b6a8_row7_col3, #T_7b6a8_row7_col4, #T_7b6a8_row8_col0, #T_7b6a8_row8_col1, #T_7b6a8_row8_col2, #T_7b6a8_row8_col3, #T_7b6a8_row8_col4, #T_7b6a8_row9_col0, #T_7b6a8_row9_col1, #T_7b6a8_row9_col2, #T_7b6a8_row9_col3, #T_7b6a8_row9_col4, #T_7b6a8_row10_col0, #T_7b6a8_row10_col1, #T_7b6a8_row10_col2, #T_7b6a8_row10_col3, #T_7b6a8_row10_col4, #T_7b6a8_row11_col0, #T_7b6a8_row11_col1, #T_7b6a8_row11_col2, #T_7b6a8_row11_col3, #T_7b6a8_row11_col4, #T_7b6a8_row12_col0, #T_7b6a8_row12_col1, #T_7b6a8_row12_col2, #T_7b6a8_row12_col3, #T_7b6a8_row12_col4, #T_7b6a8_row13_col0, #T_7b6a8_row13_col1, #T_7b6a8_row13_col2, #T_7b6a8_row13_col3, #T_7b6a8_row13_col4, #T_7b6a8_row14_col0, #T_7b6a8_row14_col1, #T_7b6a8_row14_col2, #T_7b6a8_row14_col3, #T_7b6a8_row14_col4, #T_7b6a8_row15_col0, #T_7b6a8_row15_col1, #T_7b6a8_row15_col2, #T_7b6a8_row15_col3, #T_7b6a8_row15_col4, #T_7b6a8_row16_col0, #T_7b6a8_row16_col1, #T_7b6a8_row16_col2, #T_7b6a8_row16_col3, #T_7b6a8_row16_col4, #T_7b6a8_row17_col0, #T_7b6a8_row17_col1, #T_7b6a8_row17_col2, #T_7b6a8_row17_col3, #T_7b6a8_row17_col4 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7b6a8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7b6a8_level0_col0\" class=\"col_heading level0 col0\" >imagen</th>\n",
       "      <th id=\"T_7b6a8_level0_col1\" class=\"col_heading level0 col1\" >area abolladura</th>\n",
       "      <th id=\"T_7b6a8_level0_col2\" class=\"col_heading level0 col2\" >area rayon</th>\n",
       "      <th id=\"T_7b6a8_level0_col3\" class=\"col_heading level0 col3\" >area carro</th>\n",
       "      <th id=\"T_7b6a8_level0_col4\" class=\"col_heading level0 col4\" >afectacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7b6a8_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_7b6a8_row0_col1\" class=\"data row0 col1\" >51995px^2</td>\n",
       "      <td id=\"T_7b6a8_row0_col2\" class=\"data row0 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row0_col3\" class=\"data row0 col3\" >1234924px^2</td>\n",
       "      <td id=\"T_7b6a8_row0_col4\" class=\"data row0 col4\" >1182929px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7b6a8_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_7b6a8_row1_col1\" class=\"data row1 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row1_col2\" class=\"data row1 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row1_col3\" class=\"data row1 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row1_col4\" class=\"data row1 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7b6a8_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_7b6a8_row2_col1\" class=\"data row2 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row2_col2\" class=\"data row2 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row2_col3\" class=\"data row2 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row2_col4\" class=\"data row2 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7b6a8_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_7b6a8_row3_col1\" class=\"data row3 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row3_col2\" class=\"data row3 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row3_col3\" class=\"data row3 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row3_col4\" class=\"data row3 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7b6a8_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_7b6a8_row4_col1\" class=\"data row4 col1\" >27293px^2</td>\n",
       "      <td id=\"T_7b6a8_row4_col2\" class=\"data row4 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row4_col3\" class=\"data row4 col3\" >463279px^2</td>\n",
       "      <td id=\"T_7b6a8_row4_col4\" class=\"data row4 col4\" >435986px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7b6a8_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_7b6a8_row5_col1\" class=\"data row5 col1\" >242px^2</td>\n",
       "      <td id=\"T_7b6a8_row5_col2\" class=\"data row5 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row5_col3\" class=\"data row5 col3\" >32196px^2</td>\n",
       "      <td id=\"T_7b6a8_row5_col4\" class=\"data row5 col4\" >31954px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7b6a8_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_7b6a8_row6_col1\" class=\"data row6 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row6_col2\" class=\"data row6 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row6_col3\" class=\"data row6 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row6_col4\" class=\"data row6 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7b6a8_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_7b6a8_row7_col1\" class=\"data row7 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row7_col2\" class=\"data row7 col2\" >4338px^2</td>\n",
       "      <td id=\"T_7b6a8_row7_col3\" class=\"data row7 col3\" >555670px^2</td>\n",
       "      <td id=\"T_7b6a8_row7_col4\" class=\"data row7 col4\" >551332px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7b6a8_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_7b6a8_row8_col1\" class=\"data row8 col1\" >28523px^2</td>\n",
       "      <td id=\"T_7b6a8_row8_col2\" class=\"data row8 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row8_col3\" class=\"data row8 col3\" >38380px^2</td>\n",
       "      <td id=\"T_7b6a8_row8_col4\" class=\"data row8 col4\" >9857px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7b6a8_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_7b6a8_row9_col1\" class=\"data row9 col1\" >20629px^2</td>\n",
       "      <td id=\"T_7b6a8_row9_col2\" class=\"data row9 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row9_col3\" class=\"data row9 col3\" >565073px^2</td>\n",
       "      <td id=\"T_7b6a8_row9_col4\" class=\"data row9 col4\" >544444px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_7b6a8_row10_col0\" class=\"data row10 col0\" >11</td>\n",
       "      <td id=\"T_7b6a8_row10_col1\" class=\"data row10 col1\" >9101px^2</td>\n",
       "      <td id=\"T_7b6a8_row10_col2\" class=\"data row10 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row10_col3\" class=\"data row10 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row10_col4\" class=\"data row10 col4\" >9101px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_7b6a8_row11_col0\" class=\"data row11 col0\" >12</td>\n",
       "      <td id=\"T_7b6a8_row11_col1\" class=\"data row11 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row11_col2\" class=\"data row11 col2\" >154551px^2</td>\n",
       "      <td id=\"T_7b6a8_row11_col3\" class=\"data row11 col3\" >387448px^2</td>\n",
       "      <td id=\"T_7b6a8_row11_col4\" class=\"data row11 col4\" >232897px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_7b6a8_row12_col0\" class=\"data row12 col0\" >13</td>\n",
       "      <td id=\"T_7b6a8_row12_col1\" class=\"data row12 col1\" >28928px^2</td>\n",
       "      <td id=\"T_7b6a8_row12_col2\" class=\"data row12 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row12_col3\" class=\"data row12 col3\" >934750px^2</td>\n",
       "      <td id=\"T_7b6a8_row12_col4\" class=\"data row12 col4\" >905822px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_7b6a8_row13_col0\" class=\"data row13 col0\" >14</td>\n",
       "      <td id=\"T_7b6a8_row13_col1\" class=\"data row13 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row13_col2\" class=\"data row13 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row13_col3\" class=\"data row13 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row13_col4\" class=\"data row13 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_7b6a8_row14_col0\" class=\"data row14 col0\" >15</td>\n",
       "      <td id=\"T_7b6a8_row14_col1\" class=\"data row14 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row14_col2\" class=\"data row14 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row14_col3\" class=\"data row14 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row14_col4\" class=\"data row14 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_7b6a8_row15_col0\" class=\"data row15 col0\" >16</td>\n",
       "      <td id=\"T_7b6a8_row15_col1\" class=\"data row15 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row15_col2\" class=\"data row15 col2\" >148724px^2</td>\n",
       "      <td id=\"T_7b6a8_row15_col3\" class=\"data row15 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row15_col4\" class=\"data row15 col4\" >148724px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_7b6a8_row16_col0\" class=\"data row16 col0\" >17</td>\n",
       "      <td id=\"T_7b6a8_row16_col1\" class=\"data row16 col1\" >5189px^2</td>\n",
       "      <td id=\"T_7b6a8_row16_col2\" class=\"data row16 col2\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row16_col3\" class=\"data row16 col3\" >374694px^2</td>\n",
       "      <td id=\"T_7b6a8_row16_col4\" class=\"data row16 col4\" >369505px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b6a8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_7b6a8_row17_col0\" class=\"data row17 col0\" >18</td>\n",
       "      <td id=\"T_7b6a8_row17_col1\" class=\"data row17 col1\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row17_col2\" class=\"data row17 col2\" >91088px^2</td>\n",
       "      <td id=\"T_7b6a8_row17_col3\" class=\"data row17 col3\" >0px^2</td>\n",
       "      <td id=\"T_7b6a8_row17_col4\" class=\"data row17 col4\" >91088px^2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19ce230bbb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_area(mask):\n",
    "    sum_area = 0\n",
    "    if mask is not None:\n",
    "        for e in mask:\n",
    "            area = torch.round(e[2] * e[3]).int()\n",
    "            sum_area += area.sum().item()\n",
    "        return sum_area\n",
    "    \n",
    "def search_area_by_instance(results, image_instance):\n",
    "    for i in results:\n",
    "        if i.path == image_instance:\n",
    "            return calculate_area(i.boxes.xywh) if i.boxes is not None and len(i.boxes) > 0 else 0\n",
    "\n",
    "def process_main_detection(dent, scratch, car_results):\n",
    "    data = {'imagen':[], 'area abolladura':[], 'area rayon':[], 'area carro':[], 'afectacion':[]}\n",
    "    \n",
    "    for image_id, e_dent in enumerate(dent):\n",
    "        image_instance = e_dent.path\n",
    "        dent_area = search_area_by_instance(dent, image_instance)\n",
    "        scratch_area = search_area_by_instance(scratch, image_instance)\n",
    "        \n",
    "        data['imagen'].append(f'{image_id + 1}')\n",
    "        data['area abolladura'].append(f'{dent_area}px^2')\n",
    "        data['area rayon'].append(f'{scratch_area}px^2')\n",
    "        \n",
    "        if dent_area > 0 or scratch_area > 0:\n",
    "            car_result= process_secondary_detection(car_results, dent_area, scratch_area, image_instance)\n",
    "            data['area carro'].append(f'{car_result[\"car_area\"]}px^2')\n",
    "            data['afectacion'].append(f'{car_result[\"affected_area\"]}px^2')\n",
    "        else:\n",
    "            data['area carro'].append('0px^2')\n",
    "            data['afectacion'].append('0px^2')\n",
    "\n",
    "    df=pd.DataFrame(data) \n",
    "    return df  \n",
    "    \n",
    "def process_secondary_detection(car, dent_area, scratch_area, image_instance):\n",
    "    car_area = search_area_by_instance(car, image_instance)\n",
    "    \n",
    "    total_affected_area = abs(car_area - dent_area) if dent_area > 0 else 0\n",
    "    total_affected_area = abs(car_area - scratch_area) if scratch_area > 0 else total_affected_area\n",
    "    if dent_area > 0 and scratch_area > 0:\n",
    "        main_area_sum = dent_area + scratch_area \n",
    "        total_affected_area = main_area_sum - car_area\n",
    "    return {'car_area': car_area, 'affected_area': total_affected_area}\n",
    "\n",
    "df_result = process_main_detection(results_abolladura, results_rayon, results_car)\n",
    "\n",
    "styled_df = df_result.style.set_properties(**{'text-align': 'right'})\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe con las áreas individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                             area x mascara\n",
      "id_imagen nombre                                             afectacion x imagen id_mascara ClaseMascara                   \n",
      "1         20170531_010133.jpg                                1185374             0          abolladura   0            49550\n",
      "                                                                                 1          rayon        1                0\n",
      "                                                                                 2          carro        2          1234924\n",
      "2         D_NQ_NP_2X_635253-MCO74651611787_022024-F.jpg      0                   0          abolladura   3                0\n",
      "                                                                                 1          rayon        4                0\n",
      "                                                                                 2          carro        5                0\n",
      "3         D_NQ_NP_2X_651757-MCO74531359442_022024-F.jpg      0                   0          abolladura   6                0\n",
      "                                                                                 1          rayon        7                0\n",
      "                                                                                 2          carro        8                0\n",
      "4         D_NQ_NP_2X_667580-MCO74631059717_022024-F.jpg      0                   0          abolladura   9                0\n",
      "                                                                                 1          rayon        10               0\n",
      "                                                                                 2          carro        11               0\n",
      "5         D_NQ_NP_2X_693113-MCO74586483359_022024-F.jpg      436143              0          abolladura   12           27136\n",
      "                                                                                 1          rayon        13               0\n",
      "                                                                                 2          carro        14          450278\n",
      "                                                                                                         15           10034\n",
      "                                                                                                         16            2967\n",
      "6         D_NQ_NP_2X_711885-MCO74610835935_022024-F.jpg      31954               0          abolladura   17             242\n",
      "                                                                                 1          rayon        18               0\n",
      "                                                                                 2          carro        19           16590\n",
      "                                                                                                         20           15606\n",
      "7         D_NQ_NP_2X_780482-MCO74527319422_022024-F.jpg      0                   0          abolladura   21               0\n",
      "                                                                                 1          rayon        22               0\n",
      "                                                                                 2          carro        23               0\n",
      "8         D_NQ_NP_2X_783486-MCO74451928474_022024-F.jpg      551332              0          abolladura   24               0\n",
      "                                                                                 1          rayon        25            4338\n",
      "                                                                                 2          carro        26          555670\n",
      "9         D_NQ_NP_2X_802796-MCO74603467307_022024-F.jpg      20031               0          abolladura   27           18349\n",
      "                                                                                 1          rayon        28               0\n",
      "                                                                                 2          carro        29           12698\n",
      "                                                                                                         30            5320\n",
      "                                                                                                         31           13735\n",
      "                                                                                                         32            6627\n",
      "10        D_NQ_NP_2X_847030-MCO74507003468_022024-F.jpg      560827              0          abolladura   33            4246\n",
      "                                                                                 1          rayon        34               0\n",
      "                                                                                 2          carro        35          565073\n",
      "11        OIP (1).jpg                                        4411                0          abolladura   36            4411\n",
      "                                                                                 1          rayon        37               0\n",
      "                                                                                 2          carro        38               0\n",
      "12        R.jpg                                              232897              0          abolladura   39               0\n",
      "                                                                                 1          rayon        40          154551\n",
      "                                                                                 2          carro        41          387448\n",
      "13        abolladura-en-un-coche-632c58a6e2ea5.jpg           905822              0          abolladura   42           28928\n",
      "                                                                                 1          rayon        43               0\n",
      "                                                                                 2          carro        44          934750\n",
      "14        abolladuraautos-fd03b3bae67d7363172c41cc00198c5... 0                   0          abolladura   45               0\n",
      "                                                                                 1          rayon        46               0\n",
      "                                                                                 2          carro        47               0\n",
      "15        big_ray.jpg                                        0                   0          abolladura   48               0\n",
      "                                                                                 1          rayon        49               0\n",
      "                                                                                 2          carro        50               0\n",
      "16        coche-después-de-una-ruina-la-necesidad-ser-rep... 148724              0          abolladura   51               0\n",
      "                                                                                 1          rayon        52          148724\n",
      "                                                                                 2          carro        53               0\n",
      "17        rayonesauto-e68618ca9c3d6859cebc796c300aea97-12... 369894              0          abolladura   54            4800\n",
      "                                                                                 1          rayon        55               0\n",
      "                                                                                 2          carro        56          374694\n",
      "18        trucos-para-quitar-abolladuras-del-coche.imagen... 91088               0          abolladura   57               0\n",
      "                                                                                 1          rayon        58           91088\n",
      "                                                                                 2          carro        59               0\n"
     ]
    }
   ],
   "source": [
    "def calculate_area(segmented_masks): \n",
    "    sum_area = 0\n",
    "    area_individual= []\n",
    "    if segmented_masks is not None:\n",
    "        for e in segmented_masks:\n",
    "            area = torch.round(e[2] * e[3]).int()\n",
    "            area_individual.append(area.item())\n",
    "            sum_area += area.sum().item()\n",
    "    return area_individual, sum_area\n",
    "\n",
    "def search_mask_by_image(segmentation_results, id_image):\n",
    "    for attributes in segmentation_results:\n",
    "        if attributes.path == id_image: # Confirmar que estamos buscando el resultado en la misma imagen por cada clase, con el atributo path obtenemos la direccion del archivo\n",
    "            return calculate_area(attributes.boxes.xywh) if attributes.boxes is not None else ([], 0) # Envia las coordenadas para el calculo del area si la mascara no esta vacia. De lo contrario, retornara como valor una lista vacia referente a las areas halladas y un equivalente a cero por el area total de la imagen.\n",
    "    return [], None\n",
    "\n",
    "def add_dataframe_rows(main_data, id_image, image_name, class_identification, mask_area_by_class, affectation):\n",
    "    id_class = {'abolladura': 0, 'rayon': 1, 'carro': 2} # Asigna a cada clase un identificador de orden\n",
    "        \n",
    "    if isinstance(mask_area_by_class, list): #Verifica si las areas de cada mascara segmentada esta en una lista\n",
    "        for area in mask_area_by_class: # recorre cada area de la lista de areas, permite asignar por cada area una fila en el dataframe.\n",
    "            main_data['id_imagen'].append(id_image)\n",
    "            main_data['imagen'].append(image_name)\n",
    "            main_data['ClaseMascara'].append(class_identification)\n",
    "            main_data['area x mascara'].append(area)\n",
    "            main_data['afectacion x imagen'].append(affectation)\n",
    "            \n",
    "        if mask_area_by_class == []:\n",
    "            main_data['id_imagen'].append(id_image)\n",
    "            main_data['imagen'].append(image_name)\n",
    "            main_data['ClaseMascara'].append(class_identification)\n",
    "            main_data['area x mascara'].append(0)\n",
    "            main_data['afectacion x imagen'].append(affectation)\n",
    "    main_data['id_mascara'] = [id_class[class_name] for class_name in main_data['ClaseMascara']] # Se añade una nueva columna que contendra la asignacion de cada clase \n",
    "\n",
    "def process_segmentation_results(abolladura, rayon, car):\n",
    "    try:\n",
    "        main_data = {'id_imagen': [], 'imagen':[],'ClaseMascara': [], 'area x mascara': [], 'afectacion x imagen':[]} # Creacion de la estructura inicial para llenar el dataframe, las columnas tienen asignado listas vacias.\n",
    "\n",
    "        for image_number, attributes in enumerate(abolladura): # Recorre los resultados de la segmentacion abolladura, una instancia obtendra el identificador de recorrido.\n",
    "            img_directory = attributes.path # Se obtiene el atributo de directorio en imagen\n",
    "            id_image = image_number + 1 # Incrementa el contador para asignarle una identificación única a la imagen\n",
    "            \n",
    "            areas_abolladura, total_abolladura_area = search_mask_by_image(attributes, img_directory) \n",
    "            \n",
    "            areas_rayon, total_rayon_area = search_mask_by_image(rayon, img_directory)\n",
    "            \n",
    "            if total_abolladura_area is not None and total_abolladura_area > 0 or total_rayon_area is not None and total_rayon_area > 0:\n",
    "                areas_car, total_car_area = search_mask_by_image(car, img_directory)\n",
    "                afectacion_imagen= calculating_car_affectation(total_car_area, total_abolladura_area, total_rayon_area)\n",
    "                \n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'abolladura', areas_abolladura, afectacion_imagen)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'rayon', areas_rayon, afectacion_imagen)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'carro', areas_car, afectacion_imagen)\n",
    "            else:\n",
    "                add_dataframe_rows(main_data, id_image, img_directory,'abolladura', areas_abolladura, 0)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory,'rayon', areas_rayon, 0)\n",
    "                add_dataframe_rows(main_data, id_image, img_directory, 'carro', [], 0)\n",
    "\n",
    "        df = pd.DataFrame(main_data) # Convierte la lista de diccionarios a dataframe\n",
    "        df['nombre'] = df['imagen'].apply(lambda ruta: os.path.basename(ruta)) #  Obtener solo el nombre del archivo\n",
    "        df['area x mascara'] = df['area x mascara'].apply(lambda x: x if x is not None else None)\n",
    "        grouped_columns=df.groupby(['id_imagen', 'nombre', 'afectacion x imagen', \"id_mascara\", 'ClaseMascara'], group_keys=True, as_index=True)[[ 'area x mascara']].apply(lambda x : x) # Se utiliza una agrupacion serial, se agrupa por imagen la afectacion total y los tres tipos de clase, independiente quedan las areas que pertenecen a cada clase.\n",
    "        return grouped_columns\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "def calculating_car_affectation(total_car_area, total_abolladura_area, total_rayon_area): \n",
    "    total_area_affected  = abs(total_car_area - total_abolladura_area) if total_abolladura_area is not None and total_abolladura_area > 0 else abs(total_car_area - total_rayon_area) if total_rayon_area is not None and total_rayon_area > 0 else 0 # verifica si existe un valor valido de abolladura para encontrar el valor de area afectada en el carro, de lo contrario verifica lo mismo para rayon, asigna como valor de afectacion 0 en caso de no ser valido.\n",
    "    \n",
    "    if total_abolladura_area is not None and total_rayon_area is not None and total_abolladura_area > 0 and total_rayon_area > 0:\n",
    "        total_area_affected = total_abolladura_area + total_rayon_area - total_car_area # Si ambos tipos de afectacion existen en una imagen, se sumaran primero y restaran con el area del carro.\n",
    "    return total_area_affected\n",
    "\n",
    "dataframe = process_segmentation_results(results_abolladura, results_rayon, results_car)\n",
    "print(dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
