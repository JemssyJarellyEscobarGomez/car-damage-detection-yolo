{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga librerías</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "import sklearn\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from PIL import Image\n",
    "import re\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga rutas</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder= os.getcwd() # Obtener ubicación actual\n",
    "main_folder= os.path.abspath(os.path.join(current_folder, \"../../../\")) # Carpeta main del proyecto\n",
    "main_staticos= os.path.abspath(os.path.join(main_folder))+'\\\\dist' # Carpeta main de los archivos estaticos\n",
    "main_production= os.path.abspath(main_folder) +'\\\\src' # Carpeta main de los archivos listos para producción \n",
    "dir_prueba= os.path.abspath(main_folder) + \"\\\\src\\\\assets_affectation\"  # Carpeta de imagenes prueba para la tarea de predicción\n",
    "\n",
    "training_structure=\"lote2_2\" # Indica el nombre de la carpeta que tiene los archivos para el entrenamiento (image, json)\n",
    "dir_train= os.path.abspath(main_staticos) + f'\\\\{training_structure}' # Establece la ruta completa del data para entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Función para instalar paquetes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para la implementación de paquetes\n",
    "def package_verification(package):\n",
    "    try:\n",
    "        output = os.popen('pip list').read()\n",
    "        return f'{package}' in output\n",
    "    except Exception as e:\n",
    "        print(f'Error en la verificación: {e}')\n",
    "        return False\n",
    "\n",
    "def package_installation(package_name):\n",
    "    if package_verification(package_name):\n",
    "        print(f\"El paquete '{package_name}' ya está instalado. \")\n",
    "    else:\n",
    "        print('Instalando el paquete... ')\n",
    "        try:\n",
    "            os.system(f'pip install {package_name}')\n",
    "            print(f'libreria {package_name} instalada correctamente! ')\n",
    "        except Exception as e:\n",
    "            print(f'Error en la instalación de {package_name}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación de recursos para YOLO</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librería Ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('ultralytics') # Instalación de la biblioteca Ultralytics\n",
    "#ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para determinar si tiene GPU Cuda para instalación de PYTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'CUDA: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    try:\n",
    "        command = 'wmic path win32_videocontroller get caption'\n",
    "        device = subprocess.check_output(command, shell=True, universal_newlines=True)\n",
    "        print(f'Tarjeta Grafica: {device.strip()}.\\n \\nAdvertencia: Debe utilizar la CPU para instalación de PyTorch! ')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar el comando: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Dirección para instalar mediante el comando la versión de PyTorch en función de los requerimientos computacionales: </span>[Versión PyTorch](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_pytorch = 'pip3 install torch torchvision torchaudio' # Comando de instalación según la version personalizada a sus requerimientos computacionales # idear solucion mas amena al cliente\n",
    "substrings = command_pytorch.split(\" \")\n",
    "try:\n",
    "    subprocess.check_call(substrings)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f'Error al instalar la version de PyTorch: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación de herramientas de etiquetado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La función destinada a la instalación de dependencias no está activa. Por favor, ejecute primero la celda correspondiente. \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    package_installation('labelme') # Instalación de la herramienta de etiquetado LabelMe\n",
    "except NameError:\n",
    "    print('La función destinada a la instalación de dependencias no está activa. Por favor, ejecute primero la celda correspondiente. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No fue posible abrir labelme: name 'subprocess' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    subprocess.check_call([\"labelme\"]) # Permite abrir la herramienta LabelMe\n",
    "except Exception as e:\n",
    "    print(f'No fue posible abrir labelme: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La función destinada a la instalación de dependencias no está activa. Por favor, ejecute primero la celda correspondiente. \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    package_installation('labelme2yolo') # Instalación del convertidor para transformar el formato JSON de LabelMe al formato de texto exigido por los modelos YOLO de detección de objetos.\n",
    "except NameError: \n",
    "    print('La función destinada a la instalación de dependencias no está activa. Por favor, ejecute primero la celda correspondiente. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuración de rutas de entrenamiento | Movimiento de datos globales etiquetados</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos de entrenamiento: 399\n",
      "Cantidad de archivos de validación: 98\n"
     ]
    }
   ],
   "source": [
    "# Función para separar la carpeta global de todos los datos en un 80% entrenamiento y 20% validación. Utilice esta función solo si no ha ordenado los datos en una carpeta para entrenamiento y otra para validación.\n",
    "\n",
    "def file_separation(orig_folder):\n",
    "    file_list = os.listdir(orig_folder)\n",
    "    train, val = train_test_split(file_list, test_size=0.2, random_state=100)\n",
    "    if not os.path.exists(\"train\"):\n",
    "        train_path = os.path.join(orig_folder, \"train\")\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "    move_files(train, orig_folder, train_path)\n",
    "    \n",
    "    if not os.path.exists(\"val\"):\n",
    "        val_path = os.path.join(orig_folder, \"val\")\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "    move_files(val, orig_folder, val_path)\n",
    "\n",
    "def move_files(file_list, orig_folder, dest_folder):\n",
    "    for file in file_list:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            orig_image_path = os.path.join(orig_folder, file)\n",
    "            json_name = os.path.splitext(file)[0] + \".json\"\n",
    "            \n",
    "            orig_json_path = os.path.join(orig_folder, json_name)\n",
    "            dest_image_path = os.path.join(dest_folder, file)\n",
    "            dest_json_path = os.path.join(dest_folder, json_name)\n",
    "            \n",
    "            shutil.copy(orig_image_path, dest_image_path)\n",
    "            shutil.copy(orig_json_path, dest_json_path)\n",
    "\n",
    "file_separation(dir_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Conversión a formato YOLO</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión completada para la carpeta c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\lote2_2\\train\n",
      "Conversión completada para la carpeta c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\lote2_2\\val\n"
     ]
    }
   ],
   "source": [
    "# Función para convertir la carpeta de entrenamiento y validación en formato YOLO\n",
    "\n",
    "def convert_to_yolo_format(training_directory, validation_directory):\n",
    "    try:\n",
    "        subprocess.check_call([\"labelme2yolo\", \"--json_dir\", training_directory])\n",
    "        print(f'Conversión completada para la carpeta {training_directory}')\n",
    "        subprocess.check_call([\"labelme2yolo\", \"--json_dir\", validation_directory])\n",
    "        print(f'Conversión completada para la carpeta {validation_directory}')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar función labelme2yolo: {e}')\n",
    "\n",
    "train_path= os.path.abspath(dir_train) + \"\\\\train\"\n",
    "val_path= os.path.abspath(dir_train) + \"\\\\val\"\n",
    "\n",
    "convert_to_yolo_format(train_path, val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Conversión a formato YOLO | Configuración del dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organización de la estructura del repositorio YOLODataset (resultado de la conversión .json a formato YOLO) creado por defecto\n",
    "\n",
    "def reorganization(path):\n",
    "    try:\n",
    "        new_path = os.path.abspath(os.path.join(path, \"YOLODataset\"))\n",
    "        main_folders = os.listdir(new_path)\n",
    "        for folder_instance in main_folders:\n",
    "            secondary_folder_path = os.path.join(new_path, folder_instance)\n",
    "            if os.path.isdir(secondary_folder_path):\n",
    "                secondary_folders = os.listdir(secondary_folder_path)\n",
    "                for secondary_folder in secondary_folders:\n",
    "                    subfolder_secondary_path = os.path.join(secondary_folder_path, secondary_folder)\n",
    "                    try:\n",
    "                        if os.listdir(subfolder_secondary_path) != []:\n",
    "                            for file in os.listdir(subfolder_secondary_path):\n",
    "                                orig_path = os.path.join(subfolder_secondary_path, file)\n",
    "                                dest_path = os.path.abspath(os.path.join(subfolder_secondary_path, \"../\"))\n",
    "                                new_dest_path = os.path.join(dest_path, file)\n",
    "                                shutil.move(orig_path, new_dest_path)\n",
    "                            os.rmdir(subfolder_secondary_path)\n",
    "                        else:\n",
    "                            os.rmdir(subfolder_secondary_path)\n",
    "                    except NotADirectoryError as e:\n",
    "                        print(f'Error: the element is not a folder: {e}')\n",
    "        return new_path\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "yolo_train_data= reorganization(train_path)\n",
    "yolo_val_data= reorganization(val_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpetas movidas exitosamente a c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion \n"
     ]
    }
   ],
   "source": [
    "# Función para mover las carpetas yolo \n",
    "\n",
    "def acomodar_rutas_dataset(main_staticos, dataset_train, dataset_val):\n",
    "    try:\n",
    "        if not os.path.exists(\"data_affectation\"):\n",
    "            try: \n",
    "                paths_segmentation= os.path.join(main_staticos, \"data_affectation\")\n",
    "                os.makedirs(paths_segmentation, exist_ok=True)\n",
    "                if os.listdir(paths_segmentation) == []:\n",
    "                    shutil.move(dataset_train, os.path.join(paths_segmentation, \"YOLODataset_train\"))\n",
    "                    shutil.move(dataset_val, os.path.join(paths_segmentation, \"YOLODataset_val\"))\n",
    "                    print(f'Carpetas movidas exitosamente a {paths_segmentation} ')\n",
    "                else:\n",
    "                    print(f'Las carpetas ya se encuentran en {paths_segmentation} ')\n",
    "            except OSError as e:\n",
    "                print(f'Error al intentar crear la carpeta en {paths_segmentation}: {e}')\n",
    "        return paths_segmentation  \n",
    "    except TypeError as e:\n",
    "        print(f'Tipo de dato incorrecto para el argumento: {e}')\n",
    "\n",
    "segmentation_routes= acomodar_rutas_dataset(main_staticos, yolo_train_data, yolo_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set de funciones para ordenar la estructura de los dataset individuales.\n",
    "\n",
    "def arrange_dataset_paths(train, val):\n",
    "    destination = os.path.abspath(os.path.join(train, \"../../\"))\n",
    "    shutil.move(train, destination)\n",
    "    if \"dataset.yaml\" in os.listdir(os.path.join(val, \"../\")):\n",
    "        os.remove(val)\n",
    "\n",
    "# Función para reescribir el dataset\n",
    "def rewrite_dataset(dir_train_converted, combined_list):\n",
    "    with open(dir_train_converted, 'w') as new_dataset:\n",
    "        new_dataset.write(\n",
    "            f'train: {os.path.abspath(os.path.join(dir_train_converted, \"../\"))}\\n'\n",
    "            f'val: {os.path.abspath(os.path.join(dir_train_converted, \"../../\"))}\\\\YOLODataset_val\\n'\n",
    "            'test: \\n'\n",
    "            f'nc: {len(combined_list)}\\n'\n",
    "            f'names: {combined_list}\\n'\n",
    "        )\n",
    "        \n",
    "# Función para combinar los dos dataset generados\n",
    "def total_labels(list1, list2, update_dataset_train):\n",
    "    set1=set(list1)\n",
    "    set2=set(list2)\n",
    "    union_without_repeating = set1.union(set2)\n",
    "    combined_list = list(union_without_repeating)\n",
    "    rewrite_dataset(update_dataset_train, combined_list)\n",
    "\n",
    "# Función para extraer los nombres de las etiquetas de los dos dataset separados\n",
    "def extract_labels(main_route):\n",
    "    try:\n",
    "        route_dataset_train= os.path.abspath(main_route) + \"\\\\YOLODataset_train\\\\dataset.yaml\"\n",
    "        route_dataset_val= os.path.abspath(main_route) + \"\\\\YOLODataset_val\\\\dataset.yaml\"\n",
    "        \n",
    "        with open(route_dataset_train, 'r') as file_train:\n",
    "            data_train = yaml.safe_load(file_train)\n",
    "            labels_train = data_train['names']\n",
    "        with open(route_dataset_val,'r') as file_val:\n",
    "            data_val= yaml.safe_load(file_val)\n",
    "            labels_val= data_val['names']\n",
    "        total_labels(labels_train, labels_val, route_dataset_train)\n",
    "        \n",
    "        return route_dataset_train, route_dataset_val\n",
    "    except (TypeError, FileNotFoundError) as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "try:\n",
    "    train, val= extract_labels(segmentation_routes)\n",
    "    arrange_dataset_paths(train, val)\n",
    "except TypeError as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Ubicación de la Carpeta Preparada para el Entrenamiento</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar la carpeta que contiene la configuración completa para el entrenamiento\n",
    "data_train= os.path.abspath(main_staticos) + \"\\\\data_affectation\\\\dataset.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuración de las carpetas predeterminadas de YOLO</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificación de las rutas de las carpetas predeterminadas de ultralytics YOLO\n",
    "\n",
    "def set_config_ultralytics(main):\n",
    "    settings.update({'datasets_dir': f'{main}\\\\dist', 'weights_dir': f'{main}\\\\src', 'runs_dir': f'{main}\\\\src\\\\runs'})\n",
    "set_config_ultralytics(main_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Selección versión de modelo YOLOv8</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de variantes para la segmentación de objetos\n",
    "| Modelo      | Nombres de archivo                                                         | Identificador |\n",
    "|-------------|-----------------------------------------------------                       |------------|\n",
    "| YOLOv8      | yolov8n-seg.pt yolov8s-seg.pt yolov8m-seg.pt yolov8l-seg.pt yolov8x-seg.pt | n, s, m, l, x |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación del paquete para la gestión de descarga de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_installation('gdown') # Librería que permitirá descargar las versiones de YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Modelo original</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se está utilizando la versión \"yolov8x-seg.pt\" del modelo. \n"
     ]
    }
   ],
   "source": [
    "def get_model_version():\n",
    "    available_versions= ['n', 's', 'm', 'l', 'x'] # yolov8n.pt , yolov8s.pt , yolov8m.pt , yolov8l.pt , yolov8x.pt\n",
    "    control= True\n",
    "    while control:\n",
    "        version_selection= input(\"Ingrese la versión del modelo que desea utilizar, entre las disponibles están: n, s, m, l, x. Advertencia: Si no desea instalar ninguna ingrese la palabra 'salir' \").lower() \n",
    "        if version_selection == \"salir\":\n",
    "            id_version=None\n",
    "            control=False\n",
    "        elif version_selection in available_versions:\n",
    "            id_version= f'yolov8{version_selection}-seg.pt' \n",
    "        else:\n",
    "            print('Version de modelo inexistente, ingrese nuevamente! ')\n",
    "        return id_version\n",
    "     \n",
    "def model_installation(url, version_name):\n",
    "    \n",
    "    path_save = os.path.abspath(main_folder) + \"\\\\dist\\\\model_version\\\\\" + version_name\n",
    "    if os.path.exists(path_save):\n",
    "        print(f'Se está utilizando la versión \"{version_name}\" del modelo. ')\n",
    "    else:\n",
    "        try:\n",
    "            url_installation = f'{url}/{version_name}'\n",
    "            print(url_installation)\n",
    "            gdown.download(url_installation, path_save, quiet=False)\n",
    "            print('Versión instalada correctamente!')\n",
    "        except (NameError, UnboundLocalError) as e:\n",
    "            print(f'Error en la instalación de la versión del modelo: {e}')\n",
    "    return path_save\n",
    "\n",
    "model_url= 'https://github.com/ultralytics/assets/releases/download/v0.0.0' \n",
    "model_version= get_model_version()\n",
    "\n",
    "if model_version is not None:\n",
    "    model_orig= model_installation(model_url, model_version) \n",
    "else:\n",
    "    print('Ha salido con exito! ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Modelo pre-entrenado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los pesos del experimento que se van a utilizar son c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# Función para obtener el último entrenamiento\n",
    "\n",
    "def get_last_training(dir_src, det_type):\n",
    "    try:\n",
    "        yolo_model_folders= os.listdir(dir_src)\n",
    "        for folder_name in yolo_model_folders:\n",
    "            if folder_name == det_type:\n",
    "                base_path = os.path.abspath(os.path.join(dir_src, folder_name))\n",
    "                files= os.listdir(base_path)\n",
    "                last_experiment = sorted(files)[-1]\n",
    "                model= os.path.join(base_path, last_experiment, \"weights\", \"best.pt\")\n",
    "                print(f'Los pesos del experimento que se van a utilizar son {model}')\n",
    "                return model\n",
    "        else:\n",
    "            print(f'No existe ningún experimento de entrenamiento en la carpeta {dir_src}')\n",
    "            return None\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'Error: {e}')\n",
    "        \n",
    "# Llamado para obtener el último entrenamiento del modo segmentación\n",
    "try:\n",
    "    version_affectation= \"srcv5\" # Nombre de la carpeta donde se encuentra el modelo pre-entrenado a usar\n",
    "    detection_type_affectation= \"segmentation\" # Establece el modo de detecciones de Yolo (deteccion o segmentación)\n",
    "    dir_model_version_affectation=os.path.abspath(os.path.join(main_production, version_affectation)+ f\"\\\\model_{detection_type_affectation}\") \n",
    "    model_affectation= get_last_training(dir_model_version_affectation, detection_type_affectation) \n",
    "except NameError:\n",
    "    print('Las rutas no se encuentran activas. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">ENTRENAMIENTO</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.28 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\model_version\\yolov8n-seg.pt, data=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_affectation\\dataset.yaml, epochs=30, patience=30, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=1, project=segmentation, name=training_affectation, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=1, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=segmentation\\training_affectation\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004470  ultralytics.nn.modules.head.Segment          [2, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3264006 parameters, 3263990 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA not detected, using default CPU batch-size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_affectation\\YOLODataset_train\\labels.cache... 199 images, 0 backgrounds, 0 corrupt: 100%|██████████| 199/199 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_affectation\\YOLODataset_val\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to segmentation\\training_affectation\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1msegmentation\\training_affectation\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      2.114      4.487      3.576      1.754        100        640: 100%|██████████| 13/13 [02:12<00:00, 10.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00607      0.545     0.0342     0.0101    0.00247      0.303    0.00608    0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.977      3.851      2.991      1.633         75        640: 100%|██████████| 13/13 [02:02<00:00,  9.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00722      0.596     0.0456     0.0151    0.00304      0.267    0.00374   0.000882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.946      3.587      2.824       1.63         61        640: 100%|██████████| 13/13 [01:55<00:00,  8.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235    0.00696      0.593     0.0222    0.00819    0.00263      0.218    0.00265   0.000637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.908      3.491      2.688      1.582         94        640: 100%|██████████| 13/13 [02:00<00:00,  9.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0685     0.0922     0.0426      0.015     0.0339     0.0353      0.012    0.00192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G      1.944      3.507      2.554      1.578         93        640: 100%|██████████| 13/13 [02:00<00:00,  9.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235       0.64     0.0652     0.0456     0.0141      0.586     0.0435     0.0182    0.00392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G      1.976      3.461      2.542      1.569        123        640: 100%|██████████| 13/13 [02:05<00:00,  9.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0531       0.16     0.0218    0.00782     0.0379     0.0217    0.00692    0.00152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.963      3.455      2.523      1.586         76        640: 100%|██████████| 13/13 [02:01<00:00,  9.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.219      0.111     0.0727     0.0226     0.0243     0.0217     0.0163    0.00478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G      1.994      3.408      2.486      1.571        127        640: 100%|██████████| 13/13 [02:02<00:00,  9.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.105      0.103     0.0442     0.0162     0.0991     0.0705     0.0152    0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.929      3.396      2.422      1.543        105        640: 100%|██████████| 13/13 [02:05<00:00,  9.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.102       0.13     0.0404     0.0147     0.0311     0.0591    0.00873    0.00232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G        1.9      3.292      2.417      1.548        106        640: 100%|██████████| 13/13 [01:57<00:00,  9.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235     0.0715      0.118     0.0441     0.0163     0.0476     0.0455    0.00814    0.00202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G       1.86      3.164      2.356      1.514         61        640: 100%|██████████| 13/13 [02:03<00:00,  9.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.154      0.113     0.0761     0.0254     0.0718     0.0511    0.00985    0.00259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G       1.94      3.168      2.351      1.562        142        640: 100%|██████████| 13/13 [02:02<00:00,  9.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.145      0.166     0.0792     0.0315      0.144     0.0829     0.0345    0.00648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G      1.862      3.171      2.278      1.495         75        640: 100%|██████████| 13/13 [02:01<00:00,  9.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:12<00:00,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235       0.13      0.268     0.0911     0.0372      0.102     0.0773     0.0344    0.00821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.807      3.116      2.162      1.452        140        640: 100%|██████████| 13/13 [01:58<00:00,  9.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.192      0.215      0.117     0.0472     0.0987      0.113     0.0429     0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.788      3.053      2.098      1.447        121        640: 100%|██████████| 13/13 [02:06<00:00,  9.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.249       0.15      0.099     0.0353      0.219     0.0752     0.0474     0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.771      3.071      2.125      1.466         93        640: 100%|██████████| 13/13 [01:59<00:00,  9.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.216      0.224       0.11     0.0407      0.109      0.112     0.0385     0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.754      3.004      2.051      1.405         65        640: 100%|██████████| 13/13 [02:00<00:00,  9.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.176      0.156     0.0993     0.0462      0.162     0.0726     0.0439     0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.738      3.028      2.021        1.4        137        640: 100%|██████████| 13/13 [02:00<00:00,  9.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.151       0.18      0.093      0.042      0.122     0.0834     0.0431     0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.689      2.897      1.991      1.386         78        640: 100%|██████████| 13/13 [02:00<00:00,  9.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.224      0.197      0.128     0.0594      0.199      0.116     0.0718     0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.729      2.909      2.014      1.393         53        640: 100%|██████████| 13/13 [02:00<00:00,  9.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.257      0.232      0.142     0.0549      0.181      0.181     0.0708     0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G      1.808      2.967      2.239      1.483         34        640: 100%|██████████| 13/13 [01:51<00:00,  8.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.171      0.145      0.105     0.0442      0.124      0.094     0.0391     0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.746      2.866      2.135       1.44         59        640: 100%|██████████| 13/13 [01:50<00:00,  8.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.217       0.18      0.115     0.0497      0.131     0.0967     0.0437      0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G      1.705      2.897      2.078       1.45         28        640: 100%|██████████| 13/13 [01:49<00:00,  8.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.279      0.172      0.144     0.0621      0.209      0.149     0.0806     0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.677      2.766       2.04      1.431         28        640: 100%|██████████| 13/13 [01:49<00:00,  8.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.221      0.232      0.149     0.0707      0.162      0.157     0.0897     0.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.623        2.7      1.961      1.374         55        640: 100%|██████████| 13/13 [01:48<00:00,  8.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.255      0.257      0.186     0.0816      0.326      0.157      0.123     0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G      1.608      2.732      1.886      1.362         52        640: 100%|██████████| 13/13 [01:50<00:00,  8.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.227      0.303      0.186     0.0918      0.164      0.197        0.1     0.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G       1.61      2.648      1.897      1.351         53        640: 100%|██████████| 13/13 [01:50<00:00,  8.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.248      0.265      0.175     0.0822      0.244      0.162      0.126     0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G      1.602      2.684      1.841      1.354         82        640: 100%|██████████| 13/13 [01:50<00:00,  8.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.282      0.239      0.186     0.0785      0.231      0.138     0.0888     0.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G      1.542      2.611      1.792       1.34         32        640: 100%|██████████| 13/13 [01:48<00:00,  8.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:11<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.309      0.243      0.191     0.0709        0.2      0.149      0.083     0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G      1.524       2.52      1.736      1.307         35        640: 100%|██████████| 13/13 [01:50<00:00,  8.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.282      0.289      0.205     0.0776      0.181      0.175      0.086     0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 1.083 hours.\n",
      "Optimizer stripped from segmentation\\training_affectation\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from segmentation\\training_affectation\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating segmentation\\training_affectation\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235      0.226      0.303      0.186     0.0919      0.252       0.13      0.108     0.0408\n",
      "Speed: 2.1ms preprocess, 111.6ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1msegmentation\\training_affectation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "PROJECT='segmentation' # Permite asignar un nombre al directorio de inicio que contendrá los experimentos de segmentación de objetos, y debe estar entre comillas; se recomienda no utilsizar espacios en el nombre.\n",
    "NAME='training_affectation' # El nombre del experimento entrenamiento para segmentación de instancias debe ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "TASK='segment' # Define la tarea principal que desea realizar con el modelo YOLO v8; en este caso, la segmentación implica el uso de máscaras para identificar objetos individuales en una imagen y segmentarlos del resto de la imagen.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada. Puede especificarlo como un número entero, como imgsz a 640 para obtener un cuadrado perfecto, o como una tupla, como imgsz=(640,480) para establecer dimensiones específicas de ancho y alto. Se recomienda ajustar este valor según el tamaño del objeto que desea segmentar. Para la segmentación de objetos pequeños, se recomienda aumentar el valor a más de 640 píxeles para obtener una resolución más alta.\n",
    "DATA= data_train #  Le permite indicar la ruta al archivo que contiene los metadatos que utilizara el modelo segmentación de objetos y su configuración en formato YAML. Si especifica el valor data=None, el conjunto de datos coco128-seg.yaml se utiliza de forma predeterminada; de lo contrario, escriba la ruta al archivo YAML entre comillas utilizando barras diagonales (/) en lugar de barras invertidas (\\).\n",
    "EPOCHS=30 # Establezca el número de épocas del modelo YOLO v8 en la tarea de segmentación. Este valor representa el número total de iteraciones en todo el conjunto de datos de entrenamiento. Se recomienda experimentar con este parámetro dependiendo de la cantidad de imágenes disponibles. Si tiene un conjunto de datos grande, considere aumentar este valor por encima de 30 para obtener mejores resultados. Por otro lado, establecer epochs=None hará que el modelo continúe entrenándose hasta que la pérdida de validación deje de mejorar.\n",
    "BATCH=-1 # Define la cantidad de imágenes procesadas simultáneamente en una iteración del modelo YOLO v8 en la segmentación. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta automáticamente el tamaño del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del parámetro como un número entero.\n",
    "OPTIMIZER='auto' # Define el algoritmo de optimización para el modelo de segmentación YOLO. Su elección ajusta los pesos del modelo durante el entrenamiento y es crucial para la velocidad y rendimiento. Puede tomar valores como 'SGD', 'Adam', 'Adamax', 'AdamW', 'NAdam', 'RAdam', 'RMSProp' y 'auto', este último selecciona automáticamente el optimizador más adecuado a la tarea segmentación de objetos.\n",
    "WORKERS=1 # Especifica la cantidad de subprocesos o núcleos utilizados para cargar datos en el modelo segmentación YOLO. Se recomienda ajustar la cantidad de subprocesos a la cantidad de núcleos de CPU disponibles en el sistema.\n",
    "DEVICE= 'cpu' # Especifica el dispositivo de ejecución para la versión del modelo yolov8 en la operación de segmentación. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generación de gráficos que permite visualizar y monitorear la pérdida y la precisión durante el entrenamiento de segmentación de objetos. Establecer plots=True activara la función; si desea desactivarla, establezca el valor del hiperparámetro en False.\n",
    "SAVE=False # Cuando se establece en True, el modelo guarda puntos de control periódicamente durante el entrenamiento de segmentación. Se recomienda tener cuidado al establecer este valor en Verdadero, ya que está relacionado con el hiperparámetro SAVE_PERIOD; si establece el valor del hiperparametro a False, la función Save_Period se desactivará.\n",
    "SAVE_PERIOD=-1 # Se utiliza para especificar con qué frecuencia se guardan los puntos de control durante el entrenamiento de segmentación. Si se establece en un valor mayor que 0, el modelo guardará puntos de control cada número especificado de épocas. Sin embargo, si save_period se establece en -1, significa que la función esta deshabilitada.\n",
    "PATIENCE=30 # Representa el número esperado de épocas durante el entrenamiento de segmentación. Si no se observa mejora en el conjunto de validación dentro de un período específico, se detiene el proceso. Esta técnica de parada temprana se utiliza para evitar el sobreajuste del modelo. Se recomienda ajustar este hiperparámetro en función de la duración esperada del entrenamiento.\n",
    "VERBOSE=False # Se utiliza para controlar el número de impresiones durante la ejecución del entrenamiento de segmentación. Para suprimir la salida de información básica únicamente, debe establecer el valor del hiperparámetro en False, pero si desea una salida de progreso más detallada, establezca el valor en True.\n",
    "RECT= False # Habilita la formación rectangular en cada lote, redimensionando las imágenes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de entrenamiento en la segmentación de instancias. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente lote.\n",
    "COS_LR=False # Reemplaza el decaimiento escalonado predeterminado de YOLOv8, que reduce la tasa de aprendizaje en ciertas épocas, con el decaimiento escalonado cos_lr. Este ajusta la tasa de aprendizaje según las épocas restantes y la tasa de aprendizaje inicial, proporcionando una disminución más suave. Establezca este hiperparámetro en True para una reducción gradual de la tasa de aprendizaje, de lo contrario establezca en False.\n",
    "FRACTION= 1.0 # Controla la fracción del conjunto de datos que se utilizara para el entrenamiento de segmentación. Debes establecer este parámetro entre 0.0 y 1.0. Por defecto, cuando es 1.0, se emplea el 100% de las imágenes disponibles en el conjunto de datos.\n",
    "EXIST_OK=False # Controla la sobreescritura de un experimento de segmentación existente. Cuando se establece en False, el sistema no sobrescribirá, en su lugar devolverá una ruta incrementada. Esto es útil para prevenir la sobreescritura accidental de experimentos anteriores. Para activar la función, asigna el valor True.\n",
    "OVERLAP_MASK=True # Determina si las máscaras que representan áreas de interés en la imagen deben superponerse. Establecer el valor del hiperparametro a True permite que estas máscaras compartan áreas, lo que significa que los límites de los objetos en la imagen puede coincidir parcialmente. Esta opción ahorra memoria, acelera el entrenamiento, y es especialmente útil para grandes conjuntos de datos o modelos complejos.\n",
    "MASK_RATIO=1 # Configure la reducción de muestreo para la máscara de segmentación. Se sugiere fijar el valor en el rango de 1 para entrenamiento en resolución nativa, ideal para aplicaciones que demandan alta precisión, hasta 4 para una reducción en un factor de 4, acelerando el entrenamiento con una precisión aceptable y ahorrando memoria. Este hiperparámetro solo acepta valores enteros.\n",
    "\n",
    "def train(model_segmentation):\n",
    "    try:\n",
    "        model_segmentation.train(project=PROJECT,name=NAME, task=TASK, data=DATA, imgsz=IMGSZ, epochs=EPOCHS, batch=BATCH, workers=WORKERS, device=DEVICE, plots=PLOTS, verbose=VERBOSE, rect=RECT, cos_lr=COS_LR, optimizer=OPTIMIZER, patience=PATIENCE, exist_ok=EXIST_OK, overlap_mask=OVERLAP_MASK, mask_ratio=MASK_RATIO, fraction=FRACTION)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "# --Inicio Menú\n",
    "while True:\n",
    "    try:\n",
    "        option_train = input('Por favor, indique el tipo de modelo que desea utilizar: \"original\" o \"entrenado\". Si desea cancelar el proceso, indique \"salir\": ').lower()\n",
    "        if option_train == \"salir\":\n",
    "            break\n",
    "        elif option_train == \"original\":\n",
    "            train(YOLO(model_orig))\n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        elif option_train == \"entrenado\":\n",
    "            train(YOLO(model_affectation)) \n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        else:\n",
    "            print('Character not valid, try again. ')\n",
    "    except Exception as e:\n",
    "        print(f'Error when performing the training task: {e}')\n",
    "# --Finalización Menú"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">Configuración para la exportación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px;\">A continuación se muestra una tabla de referencia para exportar un modelo YOLOv8 entrenado en la tarea segmentación de instancias. Tenga en cuenta que configurar el parámetro de `format` es fundamental para el proceso de exportación. Antes de continuar, asegúrese de verificar y ajustar estos valores a sus requisitos específicos: </span>\n",
    "\n",
    "| Formatos                                                             | Asignación | Extensión                     | Hiperparámetros                                            | Descripción                                        |\n",
    "|--------------------------------------------------------------------|-------------------|---------------------------|-----------------------------------------------------|----------------------------------------------------|\n",
    "| [PyTorch](https://pytorch.org/)                                    | -                 | `yolov8n.pt`              | -                                                   | Modelo en formato PyTorch                           |\n",
    "| [TorchScript](https://pytorch.org/docs/stable/jit.html)            | \"torchscript\"     | `yolov8n.torchscript`     | `imgsz`, `optimize`                                 | Simplifica la implementación de modelos PyTorch en entornos de producción y aplicaciones eficientes, mejorando la portabilidad y el rendimiento al permitir ejecutar una representación intermedia en entornos sin Python.                       |\n",
    "| [ONNX](https://onnx.ai/)                                           | \"onnx\"            | `yolov8n.onnx`            | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     | Desarrollado para promover la interoperabilidad, la optimización del hardware y la colaboración entre comunidades, al tiempo que responde a la necesidad de portabilidad de los modelos entre distintos marcos y herramientas de aprendizaje automático.                              |\n",
    "| [OpenVINO](https://docs.openvino.ai/latest/index.html)             | \"openvino\"        | `yolov8n_openvino_model/` | `imgsz`, `half`, `int8`                             | Elaborado para promover la interoperabilidad, la optimización del hardware y el despliegue eficiente de modelos a través de diferentes marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware Intel.                     |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt)                  | \"engine\"          | `yolov8n.engine`          | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` | Permite promover la interoperabilidad, la optimización del hardware y la implantación eficiente de modelos en distintos marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware de NVIDIA.                     |\n",
    "| [CoreML](https://github.com/apple/coremltools)                     | \"coreml\"          | `yolov8n.mlpackage`       | `imgsz`, `half`, `int8`, `nms`                      | Posibilita promover la interoperabilidad, la optimización del hardware y el despliegue eficiente de modelos a través de diferentes marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware de Apple.                            |\n",
    "| [TF SavedModel](https://www.tensorflow.org/guide/saved_model)      | \"saved_model\"     | `yolov8n_saved_model/`    | `imgsz`, `keras`, `int8`                            | Empleado para guardar, compartir y desplegar modelos entrenados con TensorFlow. Versátil y facilita el despliegue en diversas plataformas como servidores, dispositivos móviles, embebidos y navegadores.                     |\n",
    "| [TF Lite](https://www.tensorflow.org/lite)                         | \"tflite\"          | `yolov8n.tflite`          | `imgsz`, `half`, `int8`                             | Diseñado para el aprendizaje automático en dispositivos, TF Lite aborda restricciones clave como latencia, privacidad, conectividad, tamaño y consumo de energía. Es esencial para desplegar modelos en dispositivos móviles e integrados, ofreciendo una solución ligera y eficiente.                           |\n",
    "| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | \"edgetpu\"         | `yolov8n_edgetpu.tflite`  | `imgsz`                                             | Utilizado para desplegar modelos de aprendizaje automático en el Edge TPU de TensorFlow. El Edge TPU es un pequeño ASIC (Circuito Integrado Específico de Aplicación) diseñado por Google para ofrecer inferencias de aprendizaje automático de alto rendimiento en dispositivos de bajo consumo.                       |\n",
    "| [TF.js](https://www.tensorflow.org/js)                             | \"tfjs\"            | `yolov8n_web_model/`      | `imgsz`                                             | Facilita el despliegue de modelos de aprendizaje automático en navegadores web y Node.js, destacando la portabilidad y la facilidad de uso.                    |\n",
    "| [PaddlePaddle](https://github.com/PaddlePaddle)                    | \"paddle\"          | `yolov8n_paddle_model/`   | `imgsz`                                             | Utilizado para desplegar modelos en PaddlePaddle, una plataforma de aprendizaje profundo de código abierto, paralela y distribuida que tiene su origen en la práctica industrial.                      |\n",
    "| [ncnn](https://github.com/Tencent/ncnn)                            | \"ncnn\"            | `yolov8n_ncnn_model/`     | `imgsz`, `half`                                     | Formato optimizado para plataformas móviles, ofreciendo alto rendimiento. Puede incluir una estructura de archivo de modelo con información sobre capas, blobs de entrada y salida, y otros parámetros.                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">EXPORTACIÓN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation2\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 38, 8400), (1, 32, 160, 160)) (6.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.6s, saved as 'c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation2\\weights\\best.onnx' (12.6 MB)\n",
      "\n",
      "Export complete (3.9s)\n",
      "Results saved to \u001b[1mC:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation2\\weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation2\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=segment model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation2\\weights\\best.onnx imgsz=640 data=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_affectation\\dataset.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "FORMAT='onnx' # Seleccione el formato de exportación del modelo segmentación, empleando la tabla previamente proporcionada; en la columna \"Asignación\" se indican las opciones para ajustar este valor.\n",
    "INT8=False # Establezca este parámetro en True al utilizar la CPU y en False en caso contrario. La cuantificación a INT8 mejora la eficiencia del modelo segmentación en cuanto a memoria y velocidad de inferencia, especialmente en hardware que admite esta precisión.\n",
    "HALF=False # Configúrelo en True cuando use la GPU; en caso contrario, False. La cuantificación a FP16 mejora la eficiencia de la memoria del modelo segmentación y la velocidad de inferencia, especialmente en hardware que admite precisión de punto flotante de 16 bits.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada para la exportación del modelo de segmentación. Puede especificarlo como un número entero, por ejemplo, 640 para un cuadrado perfecto, o como una tupla, por ejemplo, (640, 480) para dimensiones específicas de ancho y alto. Las imágenes que ingreses al modelo después de la exportación deben tener las mismas dimensiones específicas que has configurado para adaptarse a los requisitos del escenario de despliegue.\n",
    "OPTIMIZE=False # Controla la optimización en modelos de segmentación de instancias a TorchScript para su implementación móvil. Es importante destacar que esta función puede resultar en un aumento significativo en el tamaño del modelo exportado, lo cual puede no ser ideal para aplicaciones móviles. Se configura con True para activar y False para desactivar.\n",
    "DYNAMIC=False # Controla la habilitación de ejes dinámicos en modelos de segmentación, lo cual es particularmente útil para gestionar tamaños de lote variables. Esta característica funciona bien en escenarios donde el tamaño del lote puede cambiar durante la inferencia, como aplicaciones en tiempo real o de transmisión por secuencias. Los valores aceptados son Verdadero para habilitar la función y Falso para deshabilitarla.\n",
    "SIMPLIFY=False # En la exportación de modelos de segmentación a ONNX|TensorRT, este hiperparámetro personaliza la complejidad del modelo, optimizando, eliminando capas redundantes y reduciendo la precisión de los parámetros. Se activa con True y se desactiva con False.\n",
    "OPSET=None # Especifica la versión del conjunto de operadores en ONNX al exportar el modelo segmentación desde marcos como PyTorch o TensorFlow. Si se deja en \"None\", ONNX utilizará automáticamente la versión más reciente disponible; para una versión específica, asigne el número entre comillas, por ejemplo, \"11\".\n",
    "WORKSPACE=4.0 # En la exportación de modelos de segmentación a TensorRT, establece el tamaño del espacio de trabajo en GB asignado para optimizar y preparar el modelo de red neuronal. Este espacio se utiliza durante el proceso de construcción del motor para lograr una ejecución eficiente en hardware GPU mediante la biblioteca TensorRT.\n",
    "NMS=False # En la exportación de modelos de segmentación a CoreML, controla la inclusión de la Supresión No Máxima (NMS) en el modelo para eliminar cuadros delimitadores redundantes en la segmentación de instancias y mejorar la precisión de las predicciones. Establecer 'NMS' en 'False' ignora NMS en los modelos CoreML exportados.  Este ajuste, configurable durante la exportación del modelo YOLO, lo que permite a los usuarios optimizar la implementación del modelo en una variedad de plataformas y dispositivos.\n",
    "KERAS= False # En la exportación de modelos de segmentación a TF SavedModel y TF Lite, permite optimizar el despliegue en diversas plataformas y dispositivos. Incluye también el formato del archivo, el dispositivo de ejecución y la posibilidad de manejar múltiples etiquetas por caja. Establezca el valor del hiperparámetro en True si está familiarizado con Keras; de lo contrario, en False para excluir su uso en la exportación.\n",
    "\n",
    "def export(model_export):\n",
    "    try:\n",
    "        model_export=YOLO(model_export)\n",
    "        model_export.export(format=FORMAT, imgsz=IMGSZ, dynamic=DYNAMIC, opset=OPSET, workspace=WORKSPACE, nms=NMS, keras=KERAS, int8=INT8, half=HALF, optimize=OPTIMIZE, simplify=SIMPLIFY)\n",
    "    except Exception as e: \n",
    "        print(f'Error in the export of the model: {e}')\n",
    "\n",
    "export(model_affectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Exporting to the format: torchscript\n",
      " Configuration included: imgsz=640, optimize=False\n",
      "Successful export: \n",
      "Ultralytics YOLOv8.2.31  Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 38, 8400), (1, 32, 160, 160)) (6.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.1.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  3.8s, saved as 'c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.torchscript' (12.9 MB)\n",
      "\n",
      "Export complete (6.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\u001b[0m\n",
      "Predict:         yolo predict task=segment model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=segment model=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.torchscript imgsz=640 data=c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_afectacion\\dataset.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# Opción valor por defecto flexible\n",
    "class Exportacion:\n",
    "    def __init__(self, model, format, imgsz=640, **kwargs): \n",
    "        self.model = model # dirección del modelo a exportar\n",
    "        self.format = format # nombre del formato de exportación seleccionado \n",
    "        self.imgsz = imgsz # tamaño de imagen global\n",
    "        self.hyperparameter = kwargs # diccionario con el valor de hiperparámetros a modificar\n",
    "        self.formats_config = { # Configuración establecida por defecto, en la forma -> Formato : {hiperparámetro = valor}\n",
    "            \"torchscript\": {'optimize': True},\n",
    "            \"onnx\": {'half': False, 'dynamic': False, 'simplify': False, 'opset': None},\n",
    "            \"openvino\": {'half': False, 'int8': False}, # requirements: Ultralytics requirement ['openvino>=2024.0.0'] \n",
    "            \"engine\": {'half': False, 'dynamic': False, 'simplify': False, 'workspace': 4.0}, # Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n",
    "            \"coreml\": {'half': False, 'int8': False, 'nms': False}, # requirements: Ultralytics requirement ['coremltools>=7.0'] \n",
    "            \"saved_model\": {'keras': False, 'int8': False}, # requirements: Ultralytics requirements ['tf_keras', 'onnx2tf>1.17.5,<=1.22.3', 'sng4onnx>=1.0.1', 'onnxslim==0.1.28', 'onnx_graphsurgeon>=0.3.26', 'tflite_support'] \n",
    "            \"tflite\": {'half': False, 'int8': False}, # requirements: Ultralytics requirements ['tf_keras', 'onnx2tf>1.17.5,<=1.22.3', 'sng4onnx>=1.0.1', 'onnxslim==0.1.28', 'onnx_graphsurgeon>=0.3.26', 'tflite_support'] \n",
    "            \"edgetpu\": {}, # Edge TPU export only supported on Linux. See https://coral.ai/docs/edgetpu/compiler\n",
    "            \"tfjs\": {}, # requirements: Ultralytics requirements ['tf_keras', 'onnx2tf>1.17.5,<=1.22.3', 'sng4onnx>=1.0.1', 'onnxslim==0.1.28', 'onnx_graphsurgeon>=0.3.26', 'tflite_support'] \n",
    "            \"paddle\": {}, # requirements: Ultralytics requirements ['paddlepaddle', 'x2paddle'] \n",
    "            \"ncnn\": {'half': False} # requirements: Ultralytics requirement ['ncnn'] \n",
    "        }\n",
    "        \n",
    "        \n",
    "    def remove_parameters(self):\n",
    "        # Elimina los parámetros que no son compatibles con el formato de exportación seleccionado\n",
    "        keys_to_remove = [param for param in self.hyperparameter.keys() if param not in self.formats_config[self.format]]\n",
    "        print(keys_to_remove)\n",
    "           \n",
    "        for invalid_parameter in keys_to_remove:\n",
    "            del self.hyperparameter[invalid_parameter]\n",
    "        \n",
    "        self.apply_defaults()\n",
    "            \n",
    "    def apply_defaults(self):\n",
    "    # Aplica los valores por defecto a los hiperparámetros que no han sido modificados por el usuario\n",
    "        for param, default in self.formats_config[self.format].items():\n",
    "            if param not in self.hyperparameter:  # Verifica si el usuario modificó el parámetro de manera manual\n",
    "                self.hyperparameter[param] = default  # Asigna un valor por defecto al parámetro si no fue modificado\n",
    "           \n",
    "    def export_model(self):\n",
    "        print(f'Exporting to the format: {self.format}\\n Configuration included: imgsz={self.imgsz}, {\", \".join([f\"{k}={v}\" for k, v in self.hyperparameter.items()])}')\n",
    "        try:\n",
    "            model_export = YOLO(self.model) \n",
    "            print('Successful export: ')\n",
    "            model_export.export(format=self.format, imgsz=self.imgsz, **self.hyperparameter)\n",
    "        except Exception as e: \n",
    "            print(f'Error in the export of the model: {e}')\n",
    "\n",
    "# Menú\n",
    "def export_format():\n",
    "    formats= {'1': 'torchscript', '2': 'onnx', '3': 'openvino', '4': 'engine', '5': 'coreml', '6': 'saved_model', '7': 'tflite', '8': 'edgetpu', '9': 'tfjs', '10': 'paddle', '11': 'ncnn'} # Se establecen los formatos a los que se puede exportar los modelos YOLO\n",
    "    while True:\n",
    "        format_selection = input(f'Seleccione el número del formato a exportar el modelo: {\", \".join([f\"{identificador}: {valor}\" for identificador, valor in formats.items()])}') \n",
    "        if format_selection in formats: # Verifica que el identificador coincida con un formato\n",
    "            object_= Exportacion(model_affectation, formats[format_selection], optimize=False) # Crea una instancia de la clase, la cual recibe el modelo y el formato a exportar, además, de manera opcional se puede modificar el valor de los parámetros \n",
    "            object_.remove_parameters() \n",
    "            object_.export_model() \n",
    "            break \n",
    "        else: \n",
    "            print('Unsupported format! ')\n",
    "              \n",
    "export_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">VALIDACIÓN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.220 🚀 Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_affectation\\YOLODataset_val\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:08<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235          1      0.865      0.929      0.929       0.01     0.0109    0.00502      0.001\n",
      "            abolladura         49         46          1          1      0.995      0.995     0.0201     0.0217       0.01    0.00201\n",
      "                 rayon         49        189          1       0.73      0.863      0.863          0          0          0          0\n",
      "Speed: 2.7ms preprocess, 124.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\validation_affectation\\predictions.json...\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\validation_affectation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "NAME='validation_affectation_srcv5' # El nombre del experimento de validación para segmentación de instancias deben ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "DATA= data_train # Permite indicar la ruta al archivo que contiene los metadatos necesarios para el proceso de validación, la ruta debe ser proporcionada entre comillas.\n",
    "SAVE_JSON=True # Si se configura como True, habilita la funcionalidad de guardar los resultados obtenidos de manera detallada del proceso de validación en un formato estructurado JSON.\n",
    "IMGSZ=640 # Establece las dimensiones en píxeles de la imagen de entrada para la validación del modelo de segmentación. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda usar el mismo valor que utilizo durante el entrenamiento del modelo.\n",
    "BATCH=16 # Define la cantidad de imágenes procesadas simultáneamente en una iteración para la validación de segmentos. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta automáticamente el tamaño del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del parámetro como un número entero.\n",
    "SAVE_HYBRID=True # Activa la función con True para guardar una versión híbrida de la etiqueta, incluyendo la original y predicciones adicionales. Útil para el análisis detallado del rendimiento del modelo segmentación durante la validación; establezca en False para mostrar solo las predicciones.\n",
    "CONF=0.5 # Establece el umbral de confianza para la validación de clases en la tarea de segmentación. Se recomienda un valor entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión. \n",
    "MAX_DET=10 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara segmentar en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "DEVICE='CPU' # Especifica el dispositivo de ejecución para la prueba de validación en la operación de segmentación. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generación de gráficos que permite visualizar y monitorear la pérdida y la precisión durante la validación en la segmentación de instancias. Establecer plots=True activara la función; si desea desactivarla, establezca el valor del hiperparámetro en False.\n",
    "RECT=False # Habilita la formación rectangular en cada lote, redimensionando las imágenes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de validación en la segmentación de instancias. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente.\n",
    "IOU=0.6 # El umbral predeterminado para la supresión no máxima (NMS) en la validación YOLO es 0,6. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren el mismo segmento. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "\n",
    "def val(model_val):\n",
    "    try:\n",
    "        model_val.val(name=NAME, data=DATA, save_json=SAVE_JSON, imgsz=IMGSZ, batch=BATCH, save_hybrid=SAVE_HYBRID, conf=CONF, max_det=MAX_DET, device=DEVICE, plots=PLOTS, rect=RECT, iou=IOU)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "# --Inicio Menú\n",
    "while True:\n",
    "    try:\n",
    "        option_val = input('Qué tipo de modelo desea utilizar, indique \"original\" o \"entrenado\": ').lower()\n",
    "        if option_val == \"salir\":\n",
    "            break\n",
    "        if option_val == \"original\":\n",
    "            val(YOLO(model_orig))\n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        elif option_val == \"entrenado\":\n",
    "            val(YOLO(model_affectation))\n",
    "            break  # Sale del bucle si la entrada es válida\n",
    "        else:\n",
    "            print('Character not valid, try again. ')\n",
    "    except Exception as e:\n",
    "        print(f'Error when performing the validation task: {e}')\n",
    "# --Finalización Menú"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuración de fuentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Para utilizar múltiples fuentes de datos al realizar predicciones con el modelo, se requiere que se ajuste el parámetro'source' a sus necesidades, tal como se indica en la siguiente tabla:</span>\n",
    "\n",
    "\n",
    "| Fuentes          | Asignación                             | Tipo             | Notas                                                           |\n",
    "| --------------- | ------------------------------------ | ----------------- | --------------------------------------------------------------- |\n",
    "| `image`           | 'image.jpg'                          | str or Path       | Archivo que contiene una única imagen.                                              |\n",
    "| `URL`             | 'https://ultralytics.com/images/bus.jpg' | str               | Dirección que especifica la ubicación de una imagen en la web.                                                 |\n",
    "| `screenshot`      | 'screen'                             | str               | El sistema captura la imagen actualmente visible en la pantalla y la utiliza como entrada para el modelo.                                           |\n",
    "| `PIL`             | Image.open('im.jpg')                 | PIL.Image         | Utilizado para cargar imágenes en formato HWC (altura, ancho, canales) con canales RGB (rojo, verde y azul) mediante la biblioteca Python Imaging Library (PIL).                                   |\n",
    "| `OpenCV`          | cv2.imread('im.jpg')                 | np.ndarray        | Permite la lectura de una imagen desde un archivo en formato HWC con canales BGR (azul, verde, rojo) utilizando la biblioteca OpenCV, almacenando la imagen como un array de NumPy.                    |\n",
    "| `numpy`           | np.zeros((640,1280,3))               | np.ndarray        | Genera un array de ceros con las dimensiones especificadas para un formato HWC con canales BGR, utilizando la biblioteca NumPy.                    |\n",
    "| `torch`           | torch.zeros(16,3,320,640)            | torch.Tensor      | Crea un tensor de ceros con las dimensiones especificadas para un formato HWC con canales RGB, empleando el framework PyTorch.               |\n",
    "| `CSV`             | 'sources.csv'                        | str or Path       | Archivo de texto que almacena las rutas a las imágenes que se procesarán.   |\n",
    "| `video`          | 'video.mp4'                          | str or Path       | Proporciona acceso a un archivo de video único.                       |\n",
    "| `directory`      | 'path/'                              | str or Path       | Directorio que contiene múltiples archivos de imagen.               |\n",
    "| `glob`           | 'path/*.jpg'                         | str               | Permite acceder a varias imágenes en un directorio usando expresiones de coincidencia de patrones. |\n",
    "| `YouTube`        | 'https://youtu.be/LNwODJXcvt4'       | str               | Facilita el acceso a videos desde la plataforma YouTube.                                         |\n",
    "| `stream`         | 'rtsp://example.com/media.mp4'      | str               | Permite la conexión a flujos de video o audio en tiempo real mediante protocolos como RTSP, RTMP, TCP o IP, ya sea a través de internet o una red local. |\n",
    "| `multi-stream`   | 'list.streams'                       | str or Path       | Se utiliza para transmitir varios flujos de medios simultáneamente, permitiendo el procesamiento y análisis paralelo de múltiples flujos de medios. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Formatos para las imágenes: </span>\n",
    "\n",
    "| Image Suffixes | Reference                           |\n",
    "| --------------- | ----------------------------------- |\n",
    "| .bmp            | [Microsoft BMP File Format](https://docs.fileformat.com/es/image/bmp/)           |\n",
    "| .dng            | [Adobe DNG](https://docs.fileformat.com/es/image/dng/)                           |\n",
    "| .jpeg           | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .jpg            | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .mpo            | [Multi Picture Object](https://docs.fileformat.com/es/image/mpo/)                |\n",
    "| .png            | [Portable Network Graphics](https://docs.fileformat.com/es/image/png/)           |\n",
    "| .tif            | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .tiff           | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .webp           | [WebP](https://docs.fileformat.com/es/image/webp/)                                |\n",
    "| .pfm            | [Portable FloatMap](https://docs.fileformat.com/font/pfm/)                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Formatos para los videos: </span>\n",
    "\n",
    "| Video Suffixes | Reference                           |\n",
    "| -------------- | ----------------------------------- |\n",
    "| .asf           | [Advanced Systems Format](https://docs.fileformat.com/es/video/asf/)             |\n",
    "| .avi           | [Audio Video Interleave](https://docs.fileformat.com/es/video/avi/)              |\n",
    "| .gif           | [Graphics Interchange Format]()          |\n",
    "| .m4v           | [MPEG-4 Part 14](https://docs.fileformat.com/es/video/m4v/)                      |\n",
    "| .mkv           | [Matroska](https://docs.fileformat.com/es/video/mkv/)                            |\n",
    "| .mov           | [QuickTime File Format](https://docs.fileformat.com/es/video/mov/)               |\n",
    "| .mp4           | [MPEG-4](https://docs.fileformat.com/es/video/mp4/)          |\n",
    "| .mpeg          | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .mpg           | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .ts            | [MPEG Transport Stream](https://docs.fileformat.com/es/video/ts/)               |\n",
    "| .wmv           | [Windows Media Video](https://docs.fileformat.com/es/video/wmv/)                 |\n",
    "| .webm          | [WebM Project](https://docs.fileformat.com/es/video/webm/)                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_path(path): \n",
    "    return os.path.normpath(path).replace(os.sep, '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Manipulación múltiples clases</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">PREDICCIÓN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 1 car, 892.9ms\n",
      "image 2/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 1 car, 1022.7ms\n",
      "image 3/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 1 car, 544.0ms\n",
      "image 4/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 2 cars, 1045.1ms\n",
      "image 5/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 1 car, 958.8ms\n",
      "image 6/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 (no detections), 885.5ms\n",
      "image 7/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 1225.7ms\n",
      "image 8/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 1 car, 898.6ms\n",
      "image 9/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 1 car, 975.0ms\n",
      "image 10/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 (no detections), 697.2ms\n",
      "image 11/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 1 car, 772.0ms\n",
      "image 12/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 2 cars, 894.0ms\n",
      "image 13/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 1 car, 868.6ms\n",
      "image 14/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 1 car, 867.4ms\n",
      "image 15/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 3 cars, 553.0ms\n",
      "image 16/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 607.6ms\n",
      "image 17/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 (no detections), 666.0ms\n",
      "image 18/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 1 car, 812.5ms\n",
      "image 19/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 1 car, 818.6ms\n",
      "image 20/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 1 car, 604.0ms\n",
      "image 21/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg: 448x640 1 car, 816.0ms\n",
      "image 22/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 1153.1ms\n",
      "image 23/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 (no detections), 1218.7ms\n",
      "image 24/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 car, 680.0ms\n",
      "image 25/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 1 car, 817.0ms\n",
      "Speed: 4.5ms preprocess, 851.8ms inference, 3.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\n",
      "\n",
      "image 1/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\20170531_010133[1].jpg: 416x640 (no detections), 137.1ms\n",
      "image 2/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\5-320w-320w[1].jpg: 480x640 1 abolladura, 133.0ms\n",
      "image 3/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\Car-Dent[1].png: 384x640 1 abolladura, 126.0ms\n",
      "image 4/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\Charlotte-Toyota-service-1-1024x683[1].jpg: 448x640 3 rayons, 121.0ms\n",
      "image 5/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\Charlotte-Toyota-service-1-1024x683[2].jpg: 512x640 1 abolladura, 147.0ms\n",
      "image 6/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\GSDH75MG6FAM7FSG43RFQLN5R4[1].jpg: 416x640 2 abolladuras, 107.0ms\n",
      "image 7/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\OIP (4)[1].jpeg: 480x640 1 rayon, 115.0ms\n",
      "image 8/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\OIP(3)[1].jpeg: 448x640 (no detections), 101.0ms\n",
      "image 9/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R2[1].jpeg: 544x640 (no detections), 122.0ms\n",
      "image 10/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R2[2].jpeg: 320x640 (no detections), 120.0ms\n",
      "image 11/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R3[1].jpeg: 448x640 3 abolladuras, 127.0ms\n",
      "image 12/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R5[1].jpeg: 512x640 1 abolladura, 221.0ms\n",
      "image 13/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R7[1].png: 576x640 1 abolladura, 118.0ms\n",
      "image 14/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R7[2].png: 384x640 1 abolladura, 89.0ms\n",
      "image 15/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R7[3].png: 608x640 (no detections), 169.0ms\n",
      "image 16/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\R[1].jpg: 512x640 1 abolladura, 1 rayon, 111.0ms\n",
      "image 17/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\abolladura-en-un-coche-632c58a6e2ea5[1].jpg: 448x640 1 rayon, 105.0ms\n",
      "image 18/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800[1].jpg: 448x640 (no detections), 81.0ms\n",
      "image 19/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\big_ray[1].jpg: 416x640 (no detections), 119.0ms\n",
      "image 20/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503[1].jpg: 448x640 (no detections), 107.0ms\n",
      "image 21/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0[1].jpg: 352x640 1 abolladura, 1 rayon, 93.0ms\n",
      "image 22/22 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpeqsjz1tu\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675[1].jpg: 448x640 2 abolladuras, 96.0ms\n",
      "Speed: 2.4ms preprocess, 121.1ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_affectation_srcv5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "SOURCE= dir_prueba # Establezca el origen de datos que el modelo de detección utilizará para realizar predicciones. Configure el valor de este hiperparámetro según la tabla proporcionada anteriormente.\n",
    "MAX_DET=3 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara predecir en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada durante la predicción en tareas de detección. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda utilizar los mismos valores utilizados durante el entrenamiento del modelo para mantener la coherencia en la inferencia.\n",
    "CONF=0.5 # Establece el umbral de confianza durante el proceso de predicción en la tarea de detección. Se recomienda establecer el valor hiperparámetro entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión en la inferencia.\n",
    "LINE_WIDTH= None # Determina el grosor en píxeles de los cuadros delimitadores que rodean los objetos detectados por el modelo. Puede establecer el grosor de la línea como un número entero en el que, a mayor valor, la línea será más gruesa, también puede utilizar como valor None para que el grosor se ajuste de forma automatizada, proporcionando una línea proporcional al tamaño de la imagen.\n",
    "VISUALIZE=False # Determina si las características del modelo de detección deben mostrarse durante la predicción. Establecer esto en True permite que las características se muestren como mapas intermedias, lo que hace que el modelo sea más fácil de entender. Si se establece en False, no se mostrarán las características del modelo. \n",
    "IOU=0.7 # El umbral predeterminado para la supresión no máxima (NMS) en la validación YOLO es 0,7. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren la misma detección. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "DEVICE='cpu' # Especifica el dispositivo de ejecución para la prueba de predicción en la operación de detección. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "VID_STRIDE=False # Controla la velocidad de los fotogramas durante el proceso de predicción en vídeos o secuencias de tiempo real. Al establecerlo en True el modelo se adapta a la velocidad de fotogramas especificada por la fuente de vídeo, procesando cada fotograma individualmente. Para desactivar esta función indique como valor False.\n",
    "STREAM_BUFFER=False # Controla el almacenamiento en búfer de los fotogramas para la detección. Si es True, se almacenan todos los fotogramas para el procesamiento en tiempo real de vídeos o transmisiones en directo; si es False, devuelve el fotograma más reciente.\n",
    "SAVE_FRAMES=False # Controla la captura y almacenamiento de los fotogramas predichos por el modelo de detección. Con True, se guardarán todos los fotogramas individuales predichos; con False, no se realizará el almacenamiento de los fotogramas.\n",
    "AUGMENT=True # Aplica transformaciones a las imágenes de entrada, tales como giros, rotaciones, recortes y cambios de color, para diversificar los datos y mejorar la predicción en la detección. Establecer en True para activar la función, False para desactivar.\n",
    "SAVE_CROP=False # Determina si se deben guardar imágenes recortadas con los resultados durante la predicción en la detección. Al establecerlo en \"False\", las imágenes recortadas no se guardarán, lo que reduce el tamaño del archivo. Con el valor \"True\", se guardarán las imágenes recortadas correspondientes a las áreas detectadas.\n",
    "SHOW=False # Determina si se deben mostrar las imágenes o vídeos detectados durante la predicción. Al establecerlo en \"True\", permite la visualización de las predicciones en el mismo entorno, proporcionando una representación visual de los resultados. Si se establece en \"False\", las predicciones no se mostrarán. \n",
    "SAVE_TXT= False #\n",
    "SAVE_CONF=True #\n",
    "SAVE=True #\n",
    "\n",
    "def thread_safe_predict(model, output_queue, id_class, conf_value, name_experiment, data, saved_verification, txt_verification, max_detection): #  Realiza una predicción segura utilizando un modelo YOLO.\n",
    "    try:\n",
    "        local_model = YOLO(model) # Inicializa el modelo YOLO.\n",
    "        results = local_model.predict(source= data, save=saved_verification, classes=id_class, conf=conf_value, name=name_experiment, save_txt=txt_verification, max_det=max_detection, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, save_crop=SAVE_CROP, show=SHOW, save_frames=SAVE_FRAMES, save_conf=SAVE_CONF, retina_masks=True, agnostic_nms=True) # Se establecen los hiperpametros a utilizar en el proceso de predicción.\n",
    "        output_queue.put((results)) # Pone los resultados en la cola.\n",
    "        \n",
    "    except Exception as e: # Atrapa cualquier mensaje de error. \n",
    "        print(f'Error when executing the prediction task: {e}')\n",
    "\n",
    "def create_crops(results_car, dir): #  Crea recortes a partir de objetos detectados en una imagen.\n",
    "    for attribute_car in results_car: # Recorre los resultados de la segmentación de carro.\n",
    "        img_data = np.copy(attribute_car.orig_img) # Copia la imagen original.\n",
    "        img_path = Path(attribute_car.path) \n",
    "        img_name = img_path.stem # Obtiene el nombre de la imagen por medio de la ruta.\n",
    "        img_extension = img_path.suffix # Obtiene la extensión de la imagen.\n",
    "\n",
    "        for ci, c in enumerate(attribute_car): # Itera sobre cada objeto detectado.\n",
    "            b_mask = np.zeros(img_data.shape[:2], np.uint8) # Crea una máscara binaria del tamaño de la imagen original, inicializada a ceros.\n",
    "            contour = c.masks.xy.pop().astype(np.int32).reshape(-1, 1, 2) # Extrae el contorno del objeto, lo convierte a enteros y lo reconfigura para drawContours.\n",
    "            _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED) # Dibuja el contorno en la máscara binaria, rellenando el área del objeto.\n",
    "             \n",
    "            mask3ch = cv2.cvtColor(b_mask, cv2.COLOR_GRAY2BGR) # Convierte la máscara binaria a 3 canales.\n",
    "            isolated = cv2.bitwise_and(mask3ch, img_data) # Permite aislar el objeto de la imagen. Para fondo trasparente \"isolated = np.dstack([img_data, b_mask])\".\n",
    "            \n",
    "            x1, y1, x2, y2 = c.boxes.xyxy.cpu().numpy().squeeze().astype(np.int32) # Obtiene las coordenadas de la caja delimitadora.\n",
    "            iso_crop = isolated[y1:y2, x1:x2] # Recorta el objeto aislado.\n",
    "\n",
    "            file_name = f'{img_name}[{ci +1}]{img_extension}'  # Se crea un nombre de archivo para el recorte.\n",
    "            cv2.imwrite(os.path.join(dir, file_name), iso_crop) # Guardar el recorte en el directorio temporal.\n",
    "\n",
    "def temp_controller(results_car): # Maneja el directorio temporal para los resultados del coche.\n",
    "    dir_temp = tempfile.mkdtemp() # Se crea un directorio temporal, establezca entre los (prefix='', dir='') si desea controlar el nombre y la ruta donde se guardara el directorio temporal.\n",
    "    create_crops(results_car, dir_temp)  # Crea recortes a partir de los resultados de los coches.\n",
    "    return dir_temp# Devuelve la ruta del directorio temporal.\n",
    "\n",
    "def delete_temp(temp_car): # Permite eliminar un directorio temporal.\n",
    "    try: \n",
    "        shutil.rmtree(temp_car)  # Elimina un directorio temporal según la ruta especificada.\n",
    "        print(f'Temporary directory {temp_car} successfully deleted!')\n",
    "    except Exception as e: # Captura cualquier excepción e imprime un mensaje de error.\n",
    "        print(f'Error deleting the directory: {e}')\n",
    "\n",
    "output_queue = Queue() # Creación de una cola para comunicación segura con hilos.\n",
    "try: \n",
    "    Thread(target=thread_safe_predict, args=(model_orig, output_queue, 2, 0.2, \"predict_car\", SOURCE, False, False, MAX_DET)).start() # Inicio de un nuevo hilo para la predicción del coche.\n",
    "    results_car= output_queue.get() # Obtiene los resultados de la cola.\n",
    "    dir_temp_car=temp_controller(results_car) # Manejo de un directorio temporal para los resultados del coche.\n",
    "    print(dir_temp_car)\n",
    "    try:\n",
    "        Thread(target=thread_safe_predict, args=(model_affectation, output_queue, [0, 1], 0.39, \"predict_affectation_seg_srcv5-seg\", dir_temp_car, SAVE, SAVE_TXT, MAX_DET)).start()  # Inicia un nuevo hilo para la predicción de afectación, la cual se basara en los resultados de vehiculo.\n",
    "        results_affectation= output_queue.get() # Obtiene los resultados de la cola.\n",
    "        #delete_temp(dir_temp_car) # Eliminar el directorio temporal para los resultados de los coches.\n",
    "    except Exception as e: # Captura de excepciones para la predicción de afectación.\n",
    "        print(f\"No vehicle images found: {e} \")\n",
    "        \n",
    "except Exception as e: # Captura de excepciones para la predicción de coches.\n",
    "    print(f\"Error in prediction by: {e} \") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_settings:\n",
    "    def __init__(self, name, base_setup, kwargs, project='', imgsz=640, device='cpu', save=True):\n",
    "        self.project = project\n",
    "        self.name = name\n",
    "        self.imgsz = imgsz\n",
    "        self.device = device\n",
    "        self.save = save\n",
    "        self.base_setup = base_setup # Diccionario de configuración de tarea\n",
    "        self.changes = kwargs # Parametros de modificacion \n",
    "    \n",
    "    def _remove_parameters(self): # Remover parametros que no pertenecen a la tarea\n",
    "        try:\n",
    "            keys_to_remove = [param for param in self.changes.keys() if param not in self.base_setup] \n",
    "            print(f'Parameters not available for the task: {keys_to_remove}')\n",
    "            \n",
    "            for invalid_parameter in keys_to_remove:\n",
    "                del self.changes[invalid_parameter] # Remueve los parametros no validos\n",
    "        except Exception as e:\n",
    "            print(f'{e}')\n",
    "            \n",
    "    def set_apply_defaults(self): # Aplicar valores por defecto a parametros no modificados\n",
    "        try:\n",
    "            self._remove_parameters()\n",
    "            parameters_base = {**self.changes, 'name': self.name, 'imgsz': self.imgsz, 'device': self.device, 'save': self.save}\n",
    "            self.base_setup.update(parameters_base)\n",
    "            \n",
    "            print(f'Configuration included: {\", \".join([f\"{k}={v}\" for k, v in self.base_setup.items()])}')\n",
    "            return self.base_setup\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'{e}')\n",
    "\n",
    "    def loading_model(self, model): \n",
    "        try:\n",
    "            print(f'Using the model: {model}')\n",
    "            self.instance_model = YOLO(model) # Crear la instancia del modelo\n",
    "            return self.instance_model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error when loading the model: {e}\")\n",
    "\n",
    "# Función para obtener el modelo\n",
    "def model_menu():\n",
    "    models_types = {'1':'original', '2':'entrenado'}\n",
    "    while True:\n",
    "        try:\n",
    "            option = input(f'Ingrese el identificador del modelo que desea utilizar para la ejecución de la tarea: {\", \".join([f\"{id_model}: {value}\" for id_model, value in models_types.items()])}.\\nSi desea cancelar el proceso ingrese la palabra \\'salir\\'.').lower()\n",
    "            if option == \"salir\":\n",
    "                break\n",
    "            if option in models_types:\n",
    "                if models_types[option] == \"original\":\n",
    "                    return model_orig\n",
    "                else:\n",
    "                    return model_affectation\n",
    "            else:\n",
    "                print('Character not valid, try again. ')\n",
    "        except Exception as e:\n",
    "            print(f'Error when performing the validation task: {e}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without a selected model there can be no training! \n"
     ]
    }
   ],
   "source": [
    "class Train:\n",
    "    def __init__(self, instance_model, data, **kwargs):\n",
    "        self.data = data\n",
    "        self.custom_settings = kwargs\n",
    "        self.instance_model = instance_model\n",
    "        self.training_settings= { # Configuracion de parametros base flexible\n",
    "            'task': 'segment',\n",
    "            'epochs': 30,\n",
    "            'patience': 30,\n",
    "            'optimizer': 'auto',\n",
    "            'workers': 1,\n",
    "            'plots': True, \n",
    "            'verbose': False, \n",
    "            'rect': False, \n",
    "            'cos_lr': False, \n",
    "            'fraction': 1.0, \n",
    "            'exist_ok': False, \n",
    "            'overlap_mask': True, \n",
    "            'mask_ratio': 1\n",
    "            }\n",
    "    \n",
    "        self.config = Custom_settings(project='segmentation', name='training_affectation', base_setup=self.training_settings, kwargs= self.custom_settings)\n",
    "        self.config.set_apply_defaults()\n",
    "        \n",
    "    def training(self): # Entrenamiento\n",
    "        try: \n",
    "            self.config.loading_model(self.instance_model).train(data=self.data, **self.training_settings)\n",
    "        except Exception as e:\n",
    "            print(f'Error in the training: {e}') \n",
    "\n",
    "try:\n",
    "    model_train= model_menu() \n",
    "    if model_train:\n",
    "        object_training = Train(instance_model=model_train, data=data_train,\n",
    "                    epochs=1,\n",
    "                    patience=1,\n",
    "                    max_det=5, vid_stride=False) \n",
    "        object_training.training()\n",
    "    else: \n",
    "        print('Without a selected model there can be no training! ')\n",
    "except NameError as e:\n",
    "    print(f'{e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters not available for the task: ['cos_lr', 'fraction', 'exist_ok']\n",
      "Model: c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.pt\n",
      "Configuration included: save_json=True, save_hybrid=True, conf=0.4, max_det=10, plots=True, rect=False, iou=0.6, name=validation_affectation_srcv5, imgsz=640, device=cpu, save=True\n",
      "Ultralytics YOLOv8.2.31  Python-3.10.13 torch-2.1.1 CPU (AMD Ryzen 5 4500U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258454 parameters, 0 gradients, 12.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\data_affectation\\YOLODataset_val\\labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|██████████| 49/49 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:20<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         49        235          1      0.865      0.925      0.925     0.0263     0.0326     0.0141    0.00186\n",
      "            abolladura         33         46          1          1      0.995      0.995     0.0526     0.0652     0.0282    0.00373\n",
      "                 rayon         29        189          1       0.73      0.855      0.855          0          0          0          0\n",
      "Speed: 5.5ms preprocess, 335.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Saving c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\validation_affectation_srcv5\\predictions.json...\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\validation_affectation_srcv5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class Val:\n",
    "    def __init__(self, instance_model, data, **kwargs):\n",
    "        self.instance_model = instance_model\n",
    "        self.data = data\n",
    "        self.custom_settings = kwargs\n",
    "        self.validation_settings = {\n",
    "            'save_json': True,\n",
    "            'save_hybrid': True,\n",
    "            'conf': 0.5,\n",
    "            'max_det': 10,\n",
    "            'plots': True,\n",
    "            'rect': False,\n",
    "            'iou': 0.6\n",
    "            }\n",
    "        \n",
    "        self.config = Custom_settings(name=\"validation_affectation_srcv5\", base_setup=self.validation_settings, kwargs= self.custom_settings)\n",
    "        self.config.set_apply_defaults()\n",
    "    \n",
    "    def validation(self): # Validación\n",
    "        try:\n",
    "            self.config.loading_model(self.instance_model).val(data= self.data, **self.validation_settings)\n",
    "        except Exception as e:\n",
    "            print(f'Error in the validation process: {e}')\n",
    "\n",
    "try:\n",
    "    model_val= model_menu()\n",
    "    if model_val:\n",
    "        object_validation = Val(instance_model=model_val, data=data_train, \n",
    "                                cos_lr= False, \n",
    "                                fraction= 1.0, \n",
    "                                exist_ok= False, conf= 0.4)\n",
    "        object_validation.validation()\n",
    "    else:\n",
    "        print(\"Without a selected model there can be no validation!\")\n",
    "except NameError as e:\n",
    "    print(f'{e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opción valor por defecto flexible\n",
    "class Settings_export(Custom_settings):\n",
    "    def __init__(self, id_format, imgsz, base_setup, kwargs):\n",
    "        self.id_format = id_format\n",
    "        self.changes = kwargs\n",
    "        self.base_setup = base_setup\n",
    "        super().__init__(imgsz, base_setup, kwargs)\n",
    "    \n",
    "    def _remove_parameters(self):\n",
    "        try:\n",
    "            keys_to_remove = [param for param in self.changes.keys() if param not in self.base_setup[self.id_format]] \n",
    "            print(f'Parameters not available for the task: {keys_to_remove}')\n",
    "            \n",
    "            for invalid_parameter in keys_to_remove:\n",
    "                del self.changes[invalid_parameter] # Remueve los parametros no validos               \n",
    "        except Exception as e:\n",
    "            print(f'eror{e}')\n",
    "    \n",
    "    def set_apply_defaults(self): \n",
    "        try:\n",
    "            self._remove_parameters()\n",
    "            parameters_base = {**self.changes, 'imgsz': self.imgsz}\n",
    "            self.changes.update(parameters_base)\n",
    "            print(f'Configuration included: {\", \".join([f\"{k}={v}\" for k, v in self.changes.items()])}')\n",
    "        except Exception as e:\n",
    "            print(f'{e}')\n",
    "    \n",
    "class Exportacion():\n",
    "    def __init__(self, model, format, **kwargs): \n",
    "        self.model = model # dirección del modelo a exportar\n",
    "        self.format = format # nombre del formato de exportación seleccionado \n",
    "        self.custom_settings = kwargs # diccionario con el valor de hiperparámetros a modificar\n",
    "        self.formats_config = { # Configuración establecida por defecto, en la forma -> Formato : {hiperparámetro = valor}\n",
    "            \"torchscript\": {'optimize': False},\n",
    "            \"onnx\": {'half': False, 'dynamic': False, 'simplify': False, 'opset': None},\n",
    "            \"openvino\": {'half': False, 'int8': False}, # requirements: Ultralytics requirement ['openvino>=2024.0.0'] \n",
    "            \"engine\": {'half': False, 'dynamic': False, 'simplify': False, 'workspace': 4.0}, # Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n",
    "            \"coreml\": {'half': False, 'int8': False, 'nms': False}, # requirements: Ultralytics requirement ['coremltools>=7.0'] \n",
    "            \"saved_model\": {'keras': False, 'int8': False}, # requirements: Ultralytics requirements ['tf_keras', 'onnx2tf>1.17.5,<=1.22.3', 'sng4onnx>=1.0.1', 'onnxslim==0.1.28', 'onnx_graphsurgeon>=0.3.26', 'tflite_support'] \n",
    "            \"tflite\": {'half': False, 'int8': False}, # requirements: Ultralytics requirements ['tf_keras', 'onnx2tf>1.17.5,<=1.22.3', 'sng4onnx>=1.0.1', 'onnxslim==0.1.28', 'onnx_graphsurgeon>=0.3.26', 'tflite_support'] \n",
    "            \"edgetpu\": {}, # Edge TPU export only supported on Linux. See https://coral.ai/docs/edgetpu/compiler\n",
    "            \"tfjs\": {}, # requirements: Ultralytics requirements ['tf_keras', 'onnx2tf>1.17.5,<=1.22.3', 'sng4onnx>=1.0.1', 'onnxslim==0.1.28', 'onnx_graphsurgeon>=0.3.26', 'tflite_support'] \n",
    "            \"paddle\": {}, # requirements: Ultralytics requirements ['paddlepaddle', 'x2paddle'] \n",
    "            \"ncnn\": {'half': False} # requirements: Ultralytics requirement ['ncnn'] \n",
    "        }\n",
    "        \n",
    "        self.config = Settings_export(id_format=self.format, base_setup=self.formats_config, kwargs=self.custom_settings, imgsz=640)\n",
    "        self.config.set_apply_defaults()\n",
    "           \n",
    "    def export_model(self):\n",
    "        try: \n",
    "            self.config.loading_model(self.model).export(format=self.format, **self.custom_settings)\n",
    "        except Exception as e: \n",
    "            print(f'Error in the export of the model: {e}')\n",
    "\n",
    "# Menú\n",
    "def export_format():\n",
    "    formats= {'1': 'torchscript', '2': 'onnx', '3': 'openvino', '4': 'engine', '5': 'coreml', '6': 'saved_model', '7': 'tflite', '8': 'edgetpu', '9': 'tfjs', '10': 'paddle', '11': 'ncnn'} # Se establecen los formatos a los que se puede exportar los modelos YOLO\n",
    "    while True:\n",
    "        format_selection = input(f'Seleccione el número del formato a exportar el modelo: {\", \".join([f\"{identificador}: {valor}\" for identificador, valor in formats.items()])}') \n",
    "        if format_selection in formats: # Verifica que el identificador coincida con un formato\n",
    "            model_export = model_menu()\n",
    "            if model_export:\n",
    "                object_= Exportacion(model=model_export, format=formats[format_selection], optimize=True, half=True, int8= False) # Crea una instancia de la clase, la cual recibe el modelo y el formato a exportar, además, de manera opcional se puede modificar el valor de los parámetros \n",
    "                object_.export_model() \n",
    "                break \n",
    "            else:\n",
    "               print(\"Without a selected model there can be no export!\") \n",
    "        else: \n",
    "            print('Unsupported format! ')\n",
    "              \n",
    "export_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters not available for the task: ['half']\n",
      "Configuration included: conf=0.3, max_det=5, save_txt=False, visualize=False, line_width=None, iou=0.6, vid_stride=False, stream_buffer=False, save_frames=False, augment=False, save_crop=False, show=False, save_conf=True, agnostic_nms=True, retina_masks=False, name=predict_car, imgsz=640, device=cpu, save=False\n",
      "Using the model: c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\dist\\model_version\\yolov8x-seg.pt\n",
      "\n",
      "image 1/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\20170531_010133.jpg: 384x640 1 car, 3197.4ms\n",
      "image 2/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\5-320w-320w.jpg: 480x640 (no detections), 3810.4ms\n",
      "image 3/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Car-Dent.png: 224x640 1 car, 1757.8ms\n",
      "image 4/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Charlotte-Toyota-service-1-1024x683.jpg: 448x640 2 cars, 3483.2ms\n",
      "image 5/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg: 448x640 (no detections), 3470.7ms\n",
      "image 6/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (1).jpg: 480x640 (no detections), 3686.3ms\n",
      "image 7/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (2).jpeg: 640x640 (no detections), 4969.4ms\n",
      "image 8/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP (4).jpeg: 480x640 1 car, 3702.0ms\n",
      "image 9/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\OIP(3).jpeg: 448x640 1 car, 3467.1ms\n",
      "image 10/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpeg: 384x640 (no detections), 2978.0ms\n",
      "image 11/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R.jpg: 384x640 1 car, 3011.4ms\n",
      "image 12/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R2.jpeg: 448x640 2 cars, 3473.3ms\n",
      "image 13/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R3.jpeg: 480x640 1 car, 3691.1ms\n",
      "image 14/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R5.jpeg: 480x640 1 car, 3793.8ms\n",
      "image 15/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R7.png: 288x640 4 cars, 2257.8ms\n",
      "image 16/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\R8.png: 320x640 (no detections), 2468.2ms\n",
      "image 17/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\Webp.net-resizeimage-10-1170x600.jpg: 352x640 (no detections), 2717.3ms\n",
      "image 18/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 1 car, 3482.6ms\n",
      "image 19/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 1 car, 3457.8ms\n",
      "image 20/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\big_ray.jpg: 320x640 1 car, 2465.4ms\n",
      "image 21/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\coche-despus-de-una-ruina-la-necesidad-ser-reparado-esperndola-es-demanda-de-seguro-29745503.jpg: 448x640 1 car, 3538.0ms\n",
      "image 22/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\e1b235cf346a92a59d23c353c5ab913c.jpg: 640x640 (no detections), 6605.7ms\n",
      "image 23/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\paintless-dent-removal-3-1.jpg: 640x640 (no detections), 5243.7ms\n",
      "image 24/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 car, 3961.2ms\n",
      "image 25/25 c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\assets_affectation\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 1 car, 3700.6ms\n",
      "Speed: 2.6ms preprocess, 3535.6ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "resultados [ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 0, 16, 48],\n",
      "        [ 1, 26, 58],\n",
      "        [ 5, 30, 64],\n",
      "        ...,\n",
      "        [ 4,  4, 18],\n",
      "        [ 2,  2, 16],\n",
      "        [ 2,  2, 16]],\n",
      "\n",
      "       [[ 0, 21, 53],\n",
      "        [ 3, 28, 60],\n",
      "        [ 3, 28, 62],\n",
      "        ...,\n",
      "        [ 2,  2, 16],\n",
      "        [ 1,  1, 15],\n",
      "        [ 1,  1, 15]],\n",
      "\n",
      "       [[ 5, 30, 62],\n",
      "        [ 7, 32, 64],\n",
      "        [ 1, 28, 62],\n",
      "        ...,\n",
      "        [ 2,  2, 16],\n",
      "        [ 2,  2, 16],\n",
      "        [ 3,  3, 17]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[13, 32, 59],\n",
      "        [14, 33, 60],\n",
      "        [14, 33, 60],\n",
      "        ...,\n",
      "        [22, 28, 39],\n",
      "        [21, 27, 38],\n",
      "        [19, 25, 36]],\n",
      "\n",
      "       [[ 1, 20, 47],\n",
      "        [ 4, 23, 50],\n",
      "        [ 7, 26, 53],\n",
      "        ...,\n",
      "        [22, 28, 39],\n",
      "        [22, 28, 39],\n",
      "        [19, 25, 36]],\n",
      "\n",
      "       [[12, 31, 58],\n",
      "        [13, 32, 59],\n",
      "        [13, 32, 59],\n",
      "        ...,\n",
      "        [23, 29, 40],\n",
      "        [24, 30, 41],\n",
      "        [21, 27, 38]]], dtype=uint8)\n",
      "orig_shape: (900, 1600)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\20170531_010133.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.0138492584228516, 'inference': 3197.3752975463867, 'postprocess': 5.99980354309082}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 247],\n",
      "        [255, 255, 249],\n",
      "        [240, 239, 230],\n",
      "        ...,\n",
      "        [ 99,  92,  86],\n",
      "        [102,  92,  87],\n",
      "        [111, 102,  97]],\n",
      "\n",
      "       [[204, 203, 194],\n",
      "        [222, 220, 211],\n",
      "        [214, 212, 203],\n",
      "        ...,\n",
      "        [ 83,  72,  65],\n",
      "        [113, 102,  95],\n",
      "        [125, 111, 104]],\n",
      "\n",
      "       [[153, 152, 143],\n",
      "        [190, 189, 180],\n",
      "        [198, 197, 188],\n",
      "        ...,\n",
      "        [ 69,  50,  39],\n",
      "        [ 98,  79,  68],\n",
      "        [108,  88,  78]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 88,  78,  75],\n",
      "        [ 81,  71,  68],\n",
      "        [ 83,  73,  70],\n",
      "        ...,\n",
      "        [ 30,  35,  32],\n",
      "        [ 28,  36,  32],\n",
      "        [ 28,  36,  32]],\n",
      "\n",
      "       [[ 85,  74,  71],\n",
      "        [ 80,  70,  67],\n",
      "        [ 87,  77,  74],\n",
      "        ...,\n",
      "        [ 30,  35,  32],\n",
      "        [ 28,  36,  32],\n",
      "        [ 28,  36,  32]],\n",
      "\n",
      "       [[ 80,  70,  67],\n",
      "        [ 80,  70,  67],\n",
      "        [ 80,  70,  67],\n",
      "        ...,\n",
      "        [ 30,  35,  32],\n",
      "        [ 28,  36,  32],\n",
      "        [ 28,  36,  32]]], dtype=uint8)\n",
      "orig_shape: (229, 306)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\5-320w-320w.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 1.9989013671875, 'inference': 3810.4043006896973, 'postprocess': 2.991914749145508}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[221, 209, 203],\n",
      "        [223, 211, 204],\n",
      "        [221, 210, 203],\n",
      "        ...,\n",
      "        [ 32,  94,  58],\n",
      "        [ 34,  95,  64],\n",
      "        [ 33,  95,  65]],\n",
      "\n",
      "       [[222, 211, 204],\n",
      "        [223, 211, 206],\n",
      "        [223, 212, 205],\n",
      "        ...,\n",
      "        [ 35,  95,  60],\n",
      "        [ 39,  99,  71],\n",
      "        [ 37,  97,  69]],\n",
      "\n",
      "       [[220, 208, 202],\n",
      "        [221, 209, 203],\n",
      "        [221, 209, 203],\n",
      "        ...,\n",
      "        [ 37,  96,  62],\n",
      "        [ 41, 100,  72],\n",
      "        [ 40,  98,  71]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 78,  81,  86],\n",
      "        [ 77,  81,  86],\n",
      "        [ 78,  82,  86],\n",
      "        ...,\n",
      "        [207, 212, 213],\n",
      "        [209, 214, 216],\n",
      "        [210, 215, 218]],\n",
      "\n",
      "       [[ 78,  81,  85],\n",
      "        [ 78,  81,  85],\n",
      "        [ 77,  79,  84],\n",
      "        ...,\n",
      "        [207, 211, 213],\n",
      "        [207, 211, 215],\n",
      "        [206, 213, 216]],\n",
      "\n",
      "       [[ 77,  79,  83],\n",
      "        [ 78,  80,  83],\n",
      "        [ 78,  80,  84],\n",
      "        ...,\n",
      "        [199, 207, 209],\n",
      "        [201, 207, 208],\n",
      "        [204, 211, 213]]], dtype=uint8)\n",
      "orig_shape: (300, 900)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\Car-Dent.png'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 1.0018348693847656, 'inference': 1757.7862739562988, 'postprocess': 3.0028820037841797}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[114, 122, 129],\n",
      "        [124, 132, 139],\n",
      "        [137, 147, 154],\n",
      "        ...,\n",
      "        [220, 225, 228],\n",
      "        [218, 223, 226],\n",
      "        [217, 222, 225]],\n",
      "\n",
      "       [[101, 107, 114],\n",
      "        [109, 117, 124],\n",
      "        [123, 131, 138],\n",
      "        ...,\n",
      "        [223, 228, 231],\n",
      "        [221, 226, 229],\n",
      "        [220, 225, 228]],\n",
      "\n",
      "       [[ 82,  86,  91],\n",
      "        [ 89,  95, 100],\n",
      "        [104, 110, 115],\n",
      "        ...,\n",
      "        [226, 231, 234],\n",
      "        [224, 229, 232],\n",
      "        [223, 228, 231]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[189, 189, 189],\n",
      "        [195, 195, 195],\n",
      "        [191, 191, 191],\n",
      "        ...,\n",
      "        [237, 235, 235],\n",
      "        [237, 235, 235],\n",
      "        [237, 235, 235]],\n",
      "\n",
      "       [[186, 186, 186],\n",
      "        [192, 192, 192],\n",
      "        [187, 187, 187],\n",
      "        ...,\n",
      "        [237, 235, 235],\n",
      "        [237, 235, 235],\n",
      "        [237, 235, 235]],\n",
      "\n",
      "       [[182, 182, 182],\n",
      "        [188, 188, 188],\n",
      "        [184, 184, 184],\n",
      "        ...,\n",
      "        [237, 235, 235],\n",
      "        [237, 235, 235],\n",
      "        [237, 235, 235]]], dtype=uint8)\n",
      "orig_shape: (683, 1024)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\Charlotte-Toyota-service-1-1024x683.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.011465072631836, 'inference': 3483.222484588623, 'postprocess': 6.997823715209961}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[165, 166, 164],\n",
      "        [161, 162, 160],\n",
      "        [164, 162, 161],\n",
      "        ...,\n",
      "        [232, 229, 221],\n",
      "        [232, 229, 221],\n",
      "        [233, 231, 221]],\n",
      "\n",
      "       [[155, 158, 156],\n",
      "        [153, 156, 154],\n",
      "        [157, 158, 156],\n",
      "        ...,\n",
      "        [235, 232, 224],\n",
      "        [235, 232, 224],\n",
      "        [235, 233, 223]],\n",
      "\n",
      "       [[158, 163, 161],\n",
      "        [159, 164, 162],\n",
      "        [161, 166, 164],\n",
      "        ...,\n",
      "        [238, 235, 227],\n",
      "        [237, 234, 226],\n",
      "        [237, 234, 226]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[134, 140, 147],\n",
      "        [125, 129, 134],\n",
      "        [141, 144, 149],\n",
      "        ...,\n",
      "        [ 79,  80,  84],\n",
      "        [ 61,  63,  64],\n",
      "        [ 39,  39,  39]],\n",
      "\n",
      "       [[147, 152, 161],\n",
      "        [150, 153, 161],\n",
      "        [146, 149, 154],\n",
      "        ...,\n",
      "        [117, 119, 129],\n",
      "        [119, 124, 127],\n",
      "        [ 64,  69,  70]],\n",
      "\n",
      "       [[ 81,  85,  96],\n",
      "        [ 66,  68,  78],\n",
      "        [ 54,  53,  62],\n",
      "        ...,\n",
      "        [ 98, 106, 119],\n",
      "        [115, 125, 132],\n",
      "        [121, 133, 135]]], dtype=uint8)\n",
      "orig_shape: (680, 1024)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\GSDH75MG6FAM7FSG43RFQLN5R4.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 1.9993782043457031, 'inference': 3470.719814300537, 'postprocess': 3.012418746948242}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[131, 126, 125],\n",
      "        [129, 124, 123],\n",
      "        [131, 121, 121],\n",
      "        ...,\n",
      "        [252, 255, 253],\n",
      "        [251, 254, 252],\n",
      "        [251, 254, 252]],\n",
      "\n",
      "       [[125, 120, 119],\n",
      "        [126, 121, 120],\n",
      "        [129, 121, 121],\n",
      "        ...,\n",
      "        [251, 254, 252],\n",
      "        [250, 253, 251],\n",
      "        [250, 253, 251]],\n",
      "\n",
      "       [[117, 112, 111],\n",
      "        [120, 115, 114],\n",
      "        [126, 118, 118],\n",
      "        ...,\n",
      "        [252, 255, 253],\n",
      "        [251, 254, 252],\n",
      "        [251, 254, 252]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[108, 144, 180],\n",
      "        [110, 148, 183],\n",
      "        [112, 148, 184],\n",
      "        ...,\n",
      "        [ 25,  35,  45],\n",
      "        [ 28,  37,  47],\n",
      "        [ 27,  37,  47]],\n",
      "\n",
      "       [[119, 156, 194],\n",
      "        [115, 154, 192],\n",
      "        [117, 154, 192],\n",
      "        ...,\n",
      "        [ 22,  30,  43],\n",
      "        [ 30,  36,  47],\n",
      "        [ 62,  71,  81]],\n",
      "\n",
      "       [[117, 156, 194],\n",
      "        [115, 154, 192],\n",
      "        [115, 154, 192],\n",
      "        ...,\n",
      "        [ 24,  30,  43],\n",
      "        [ 30,  36,  47],\n",
      "        [ 64,  70,  81]]], dtype=uint8)\n",
      "orig_shape: (338, 474)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\OIP (1).jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.015352249145508, 'inference': 3686.288356781006, 'postprocess': 2.975940704345703}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[220, 218, 217],\n",
      "        [220, 218, 217],\n",
      "        [221, 219, 218],\n",
      "        ...,\n",
      "        [249, 252, 255],\n",
      "        [249, 252, 255],\n",
      "        [249, 252, 255]],\n",
      "\n",
      "       [[228, 226, 225],\n",
      "        [228, 226, 225],\n",
      "        [227, 225, 224],\n",
      "        ...,\n",
      "        [248, 251, 255],\n",
      "        [248, 251, 255],\n",
      "        [248, 251, 255]],\n",
      "\n",
      "       [[224, 222, 221],\n",
      "        [225, 223, 222],\n",
      "        [225, 223, 222],\n",
      "        ...,\n",
      "        [246, 249, 253],\n",
      "        [246, 249, 253],\n",
      "        [246, 249, 253]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 43,  47,  48],\n",
      "        [ 40,  44,  45],\n",
      "        [ 43,  47,  48],\n",
      "        ...,\n",
      "        [ 20,  29,  42],\n",
      "        [ 17,  26,  36],\n",
      "        [ 15,  24,  34]],\n",
      "\n",
      "       [[ 33,  37,  38],\n",
      "        [ 31,  35,  36],\n",
      "        [ 36,  40,  41],\n",
      "        ...,\n",
      "        [ 21,  29,  42],\n",
      "        [ 19,  25,  36],\n",
      "        [ 17,  23,  34]],\n",
      "\n",
      "       [[ 28,  32,  33],\n",
      "        [ 26,  30,  31],\n",
      "        [ 31,  35,  36],\n",
      "        ...,\n",
      "        [ 21,  29,  42],\n",
      "        [ 19,  25,  36],\n",
      "        [ 17,  23,  34]]], dtype=uint8)\n",
      "orig_shape: (300, 300)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\OIP (2).jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 4.024267196655273, 'inference': 4969.448089599609, 'postprocess': 3.9339065551757812}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[178, 160, 255],\n",
      "        [178, 160, 255],\n",
      "        [177, 160, 255],\n",
      "        ...,\n",
      "        [208, 210, 211],\n",
      "        [207, 209, 210],\n",
      "        [206, 208, 209]],\n",
      "\n",
      "       [[179, 161, 255],\n",
      "        [179, 162, 255],\n",
      "        [180, 163, 255],\n",
      "        ...,\n",
      "        [208, 210, 211],\n",
      "        [207, 209, 210],\n",
      "        [205, 207, 208]],\n",
      "\n",
      "       [[179, 162, 255],\n",
      "        [180, 163, 255],\n",
      "        [181, 164, 255],\n",
      "        ...,\n",
      "        [209, 211, 212],\n",
      "        [207, 209, 210],\n",
      "        [205, 207, 208]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[131, 142, 146],\n",
      "        [122, 133, 137],\n",
      "        [111, 122, 126],\n",
      "        ...,\n",
      "        [184, 192, 199],\n",
      "        [183, 191, 198],\n",
      "        [186, 194, 201]],\n",
      "\n",
      "       [[122, 133, 137],\n",
      "        [115, 126, 130],\n",
      "        [105, 116, 120],\n",
      "        ...,\n",
      "        [191, 199, 206],\n",
      "        [191, 199, 206],\n",
      "        [192, 200, 207]],\n",
      "\n",
      "       [[244, 255, 255],\n",
      "        [244, 255, 255],\n",
      "        [243, 254, 255],\n",
      "        ...,\n",
      "        [245, 253, 255],\n",
      "        [245, 253, 255],\n",
      "        [245, 253, 255]]], dtype=uint8)\n",
      "orig_shape: (768, 1024)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\OIP (4).jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.0105113983154297, 'inference': 3701.986312866211, 'postprocess': 6.000280380249023}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 45, 181, 247],\n",
      "        [ 45, 181, 247],\n",
      "        [ 44, 180, 246],\n",
      "        ...,\n",
      "        [140, 134, 127],\n",
      "        [144, 134, 127],\n",
      "        [144, 134, 127]],\n",
      "\n",
      "       [[ 43, 179, 245],\n",
      "        [ 42, 178, 244],\n",
      "        [ 41, 177, 243],\n",
      "        ...,\n",
      "        [144, 136, 129],\n",
      "        [140, 130, 123],\n",
      "        [140, 130, 123]],\n",
      "\n",
      "       [[ 40, 176, 242],\n",
      "        [ 39, 175, 241],\n",
      "        [ 38, 174, 240],\n",
      "        ...,\n",
      "        [146, 137, 128],\n",
      "        [139, 130, 121],\n",
      "        [140, 129, 121]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 254],\n",
      "        [253, 255, 254],\n",
      "        [253, 255, 254],\n",
      "        ...,\n",
      "        [ 44,  37,  34],\n",
      "        [ 36,  29,  26],\n",
      "        [ 55,  48,  45]],\n",
      "\n",
      "       [[255, 255, 254],\n",
      "        [255, 255, 254],\n",
      "        [253, 255, 254],\n",
      "        ...,\n",
      "        [ 44,  37,  34],\n",
      "        [ 51,  44,  41],\n",
      "        [ 71,  64,  61]],\n",
      "\n",
      "       [[255, 255, 252],\n",
      "        [255, 255, 252],\n",
      "        [255, 255, 254],\n",
      "        ...,\n",
      "        [ 42,  37,  34],\n",
      "        [ 49,  44,  41],\n",
      "        [ 71,  66,  63]]], dtype=uint8)\n",
      "orig_shape: (315, 474)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\OIP(3).jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 1.9998550415039062, 'inference': 3467.130661010742, 'postprocess': 6.0024261474609375}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 50,  52,  62],\n",
      "        [ 50,  52,  62],\n",
      "        [ 50,  52,  62],\n",
      "        ...,\n",
      "        [252, 233, 206],\n",
      "        [252, 233, 206],\n",
      "        [253, 234, 207]],\n",
      "\n",
      "       [[ 50,  52,  62],\n",
      "        [ 50,  52,  62],\n",
      "        [ 50,  52,  62],\n",
      "        ...,\n",
      "        [251, 232, 205],\n",
      "        [251, 232, 205],\n",
      "        [252, 233, 206]],\n",
      "\n",
      "       [[ 49,  51,  61],\n",
      "        [ 49,  51,  61],\n",
      "        [ 50,  52,  62],\n",
      "        ...,\n",
      "        [253, 232, 205],\n",
      "        [251, 232, 205],\n",
      "        [252, 233, 206]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[164, 165, 163],\n",
      "        [163, 164, 162],\n",
      "        [164, 162, 161],\n",
      "        ...,\n",
      "        [ 51,  36, 247],\n",
      "        [ 54,  41, 247],\n",
      "        [ 55,  44, 248]],\n",
      "\n",
      "       [[163, 164, 162],\n",
      "        [163, 164, 162],\n",
      "        [164, 162, 161],\n",
      "        ...,\n",
      "        [ 50,  34, 242],\n",
      "        [ 53,  38, 243],\n",
      "        [ 53,  41, 243]],\n",
      "\n",
      "       [[163, 164, 162],\n",
      "        [163, 164, 162],\n",
      "        [162, 163, 161],\n",
      "        ...,\n",
      "        [ 50,  33, 238],\n",
      "        [ 54,  38, 240],\n",
      "        [ 54,  41, 241]]], dtype=uint8)\n",
      "orig_shape: (781, 1300)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R.jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 1.9986629486083984, 'inference': 2978.041172027588, 'postprocess': 1.9998550415039062}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[124, 142, 143],\n",
      "        [124, 142, 143],\n",
      "        [124, 142, 143],\n",
      "        ...,\n",
      "        [ 39,  34,  35],\n",
      "        [ 41,  36,  37],\n",
      "        [ 43,  38,  39]],\n",
      "\n",
      "       [[124, 142, 143],\n",
      "        [124, 142, 143],\n",
      "        [124, 142, 143],\n",
      "        ...,\n",
      "        [ 37,  32,  33],\n",
      "        [ 39,  34,  35],\n",
      "        [ 41,  36,  37]],\n",
      "\n",
      "       [[124, 142, 143],\n",
      "        [124, 142, 143],\n",
      "        [124, 142, 143],\n",
      "        ...,\n",
      "        [ 34,  29,  30],\n",
      "        [ 36,  31,  32],\n",
      "        [ 38,  33,  34]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  8,  10,  10],\n",
      "        [  9,  11,  11],\n",
      "        [ 10,  12,  12],\n",
      "        ...,\n",
      "        [109, 128, 131],\n",
      "        [104, 125, 127],\n",
      "        [102, 123, 125]],\n",
      "\n",
      "       [[ 10,  12,  12],\n",
      "        [ 12,  14,  14],\n",
      "        [ 14,  16,  16],\n",
      "        ...,\n",
      "        [110, 129, 132],\n",
      "        [104, 125, 127],\n",
      "        [ 99, 120, 122]],\n",
      "\n",
      "       [[ 13,  15,  15],\n",
      "        [ 16,  18,  18],\n",
      "        [ 19,  21,  21],\n",
      "        ...,\n",
      "        [114, 133, 136],\n",
      "        [107, 128, 130],\n",
      "        [101, 122, 124]]], dtype=uint8)\n",
      "orig_shape: (558, 988)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.0322799682617188, 'inference': 3011.4386081695557, 'postprocess': 4.999876022338867}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 45,  31,  25],\n",
      "        [ 42,  32,  22],\n",
      "        [ 38,  29,  19],\n",
      "        ...,\n",
      "        [244, 249, 250],\n",
      "        [252, 255, 253],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 78,  59,  44],\n",
      "        [ 73,  53,  42],\n",
      "        [ 66,  50,  33],\n",
      "        ...,\n",
      "        [168, 184, 230],\n",
      "        [201, 215, 234],\n",
      "        [252, 255, 253]],\n",
      "\n",
      "       [[ 55,  46,  32],\n",
      "        [ 54,  44,  34],\n",
      "        [ 50,  44,  31],\n",
      "        ...,\n",
      "        [146, 154, 224],\n",
      "        [121, 134, 208],\n",
      "        [202, 212, 230]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 18,  18,  18],\n",
      "        [ 34,  32,  31],\n",
      "        [ 33,  34,  30],\n",
      "        ...,\n",
      "        [190, 184, 179],\n",
      "        [177, 163, 165],\n",
      "        [158, 146, 146]],\n",
      "\n",
      "       [[ 13,  11,  10],\n",
      "        [ 11,  11,  11],\n",
      "        [ 26,  24,  24],\n",
      "        ...,\n",
      "        [172, 164, 157],\n",
      "        [164, 151, 149],\n",
      "        [167, 161, 156]],\n",
      "\n",
      "       [[ 13,  11,  10],\n",
      "        [  7,   5,   4],\n",
      "        [ 11,   9,   9],\n",
      "        ...,\n",
      "        [174, 160, 161],\n",
      "        [172, 163, 160],\n",
      "        [175, 166, 162]]], dtype=uint8)\n",
      "orig_shape: (300, 450)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R2.jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.0145645141601562, 'inference': 3473.283290863037, 'postprocess': 8.999824523925781}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[110, 112,  93],\n",
      "        [111, 113,  94],\n",
      "        [107, 109,  89],\n",
      "        ...,\n",
      "        [224, 207, 186],\n",
      "        [223, 206, 185],\n",
      "        [223, 206, 185]],\n",
      "\n",
      "       [[114, 114,  96],\n",
      "        [116, 118,  99],\n",
      "        [116, 117,  97],\n",
      "        ...,\n",
      "        [223, 206, 185],\n",
      "        [223, 206, 185],\n",
      "        [222, 205, 184]],\n",
      "\n",
      "       [[138, 136, 118],\n",
      "        [136, 136, 118],\n",
      "        [135, 133, 115],\n",
      "        ...,\n",
      "        [222, 205, 184],\n",
      "        [221, 204, 183],\n",
      "        [221, 204, 183]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 63,  64,  62],\n",
      "        [ 59,  60,  58],\n",
      "        [ 58,  59,  57],\n",
      "        ...,\n",
      "        [ 58,  58,  52],\n",
      "        [ 62,  62,  56],\n",
      "        [ 56,  57,  48]],\n",
      "\n",
      "       [[ 59,  58,  54],\n",
      "        [ 63,  62,  58],\n",
      "        [ 57,  56,  52],\n",
      "        ...,\n",
      "        [ 64,  63,  59],\n",
      "        [ 73,  72,  68],\n",
      "        [ 62,  62,  56]],\n",
      "\n",
      "       [[ 57,  56,  52],\n",
      "        [ 71,  70,  66],\n",
      "        [ 65,  64,  60],\n",
      "        ...,\n",
      "        [ 60,  59,  55],\n",
      "        [ 71,  70,  66],\n",
      "        [ 63,  62,  58]]], dtype=uint8)\n",
      "orig_shape: (450, 600)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R3.jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.027677536010742, 'inference': 3691.096782684326, 'postprocess': 5.023002624511719}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[177, 146, 121],\n",
      "        [177, 146, 121],\n",
      "        [177, 146, 121],\n",
      "        ...,\n",
      "        [ 70,  75,  74],\n",
      "        [ 69,  74,  73],\n",
      "        [ 67,  72,  71]],\n",
      "\n",
      "       [[177, 146, 121],\n",
      "        [177, 146, 121],\n",
      "        [177, 146, 121],\n",
      "        ...,\n",
      "        [ 70,  75,  74],\n",
      "        [ 69,  74,  73],\n",
      "        [ 67,  72,  71]],\n",
      "\n",
      "       [[176, 146, 121],\n",
      "        [176, 146, 121],\n",
      "        [176, 146, 121],\n",
      "        ...,\n",
      "        [ 73,  78,  77],\n",
      "        [ 72,  77,  76],\n",
      "        [ 70,  75,  74]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4,   4,   4],\n",
      "        [  3,   3,   3],\n",
      "        [  3,   3,   3],\n",
      "        ...,\n",
      "        [122, 130, 129],\n",
      "        [121, 132, 130],\n",
      "        [120, 131, 129]],\n",
      "\n",
      "       [[  4,   4,   4],\n",
      "        [  3,   3,   3],\n",
      "        [  3,   3,   3],\n",
      "        ...,\n",
      "        [113, 121, 120],\n",
      "        [116, 127, 125],\n",
      "        [123, 134, 132]],\n",
      "\n",
      "       [[  4,   4,   4],\n",
      "        [  3,   3,   3],\n",
      "        [  3,   3,   3],\n",
      "        ...,\n",
      "        [107, 115, 114],\n",
      "        [110, 121, 119],\n",
      "        [124, 135, 133]]], dtype=uint8)\n",
      "orig_shape: (480, 640)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R5.jpeg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 1.983642578125, 'inference': 3793.8451766967773, 'postprocess': 5.995512008666992}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 97,  97, 165],\n",
      "        [ 86,  84, 173],\n",
      "        [ 91,  85, 179],\n",
      "        ...,\n",
      "        [228, 217, 212],\n",
      "        [231, 215, 213],\n",
      "        [227, 212, 207]],\n",
      "\n",
      "       [[ 93,  79, 185],\n",
      "        [ 91,  74, 193],\n",
      "        [ 90,  76, 194],\n",
      "        ...,\n",
      "        [233, 215, 214],\n",
      "        [231, 214, 214],\n",
      "        [234, 221, 213]],\n",
      "\n",
      "       [[ 99,  84, 182],\n",
      "        [ 92,  82, 187],\n",
      "        [ 98,  82, 182],\n",
      "        ...,\n",
      "        [226, 216, 207],\n",
      "        [228, 216, 209],\n",
      "        [231, 216, 212]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4,   2,   0],\n",
      "        [  8,   3,   2],\n",
      "        [  6,   0,   3],\n",
      "        ...,\n",
      "        [ 28,  35,  33],\n",
      "        [ 78,  89,  86],\n",
      "        [ 95, 109,  96]],\n",
      "\n",
      "       [[  6,   1,   9],\n",
      "        [  2,   2,   3],\n",
      "        [  5,   1,   5],\n",
      "        ...,\n",
      "        [ 28,  38,  37],\n",
      "        [ 88,  99,  91],\n",
      "        [105, 120, 100]],\n",
      "\n",
      "       [[ 17,  14,  12],\n",
      "        [  8,   0,   0],\n",
      "        [ 10,   2,   0],\n",
      "        ...,\n",
      "        [ 39,  45,  38],\n",
      "        [ 83,  96,  95],\n",
      "        [ 96, 104,  99]]], dtype=uint8)\n",
      "orig_shape: (557, 1300)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R7.png'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.0110607147216797, 'inference': 2257.770776748657, 'postprocess': 8.013248443603516}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [254, 254, 254],\n",
      "        ...,\n",
      "        [131, 172, 175],\n",
      "        [143, 184, 187],\n",
      "        [140, 181, 184]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [254, 254, 254],\n",
      "        ...,\n",
      "        [138, 179, 182],\n",
      "        [151, 192, 195],\n",
      "        [148, 189, 192]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [254, 254, 254],\n",
      "        ...,\n",
      "        [139, 180, 183],\n",
      "        [150, 191, 194],\n",
      "        [148, 189, 192]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[106,  94,  92],\n",
      "        [100,  88,  86],\n",
      "        [113, 101,  99],\n",
      "        ...,\n",
      "        [ 57,  60,  64],\n",
      "        [ 64,  69,  70],\n",
      "        [ 90,  95,  96]],\n",
      "\n",
      "       [[102,  90,  88],\n",
      "        [106,  94,  92],\n",
      "        [ 99,  87,  85],\n",
      "        ...,\n",
      "        [ 72,  75,  79],\n",
      "        [111, 116, 117],\n",
      "        [130, 135, 136]],\n",
      "\n",
      "       [[103,  91,  89],\n",
      "        [101,  89,  87],\n",
      "        [113, 101,  99],\n",
      "        ...,\n",
      "        [ 76,  79,  83],\n",
      "        [ 91,  96,  97],\n",
      "        [ 81,  86,  87]]], dtype=uint8)\n",
      "orig_shape: (918, 2028)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\R8.png'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.0024776458740234, 'inference': 2468.1544303894043, 'postprocess': 2.001047134399414}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 45,  47,  47],\n",
      "        [ 45,  47,  47],\n",
      "        [ 45,  47,  47],\n",
      "        ...,\n",
      "        [198, 215, 234],\n",
      "        [196, 215, 236],\n",
      "        [194, 215, 236]],\n",
      "\n",
      "       [[ 45,  47,  47],\n",
      "        [ 45,  47,  47],\n",
      "        [ 45,  47,  47],\n",
      "        ...,\n",
      "        [197, 214, 233],\n",
      "        [196, 215, 236],\n",
      "        [194, 215, 236]],\n",
      "\n",
      "       [[ 45,  47,  47],\n",
      "        [ 45,  47,  47],\n",
      "        [ 45,  47,  47],\n",
      "        ...,\n",
      "        [196, 213, 232],\n",
      "        [195, 214, 235],\n",
      "        [193, 214, 235]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 78, 109, 124],\n",
      "        [ 78, 109, 124],\n",
      "        [ 79, 110, 125],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[ 73, 104, 119],\n",
      "        [ 73, 104, 119],\n",
      "        [ 73, 104, 119],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[ 70, 101, 116],\n",
      "        [ 69, 100, 115],\n",
      "        [ 69, 100, 115],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]]], dtype=uint8)\n",
      "orig_shape: (600, 1170)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\Webp.net-resizeimage-10-1170x600.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.000093460083008, 'inference': 2717.252492904663, 'postprocess': 2.990245819091797}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[188, 199, 221],\n",
      "        [187, 200, 222],\n",
      "        [187, 200, 222],\n",
      "        ...,\n",
      "        [ 43,  32,  34],\n",
      "        [ 43,  32,  34],\n",
      "        [ 43,  32,  34]],\n",
      "\n",
      "       [[188, 199, 221],\n",
      "        [187, 200, 222],\n",
      "        [186, 200, 222],\n",
      "        ...,\n",
      "        [ 44,  33,  35],\n",
      "        [ 44,  33,  35],\n",
      "        [ 44,  33,  35]],\n",
      "\n",
      "       [[188, 199, 221],\n",
      "        [187, 200, 222],\n",
      "        [186, 200, 222],\n",
      "        ...,\n",
      "        [ 43,  35,  35],\n",
      "        [ 43,  35,  35],\n",
      "        [ 43,  35,  35]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[191, 214, 216],\n",
      "        [194, 217, 219],\n",
      "        [196, 219, 221],\n",
      "        ...,\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13],\n",
      "        [ 13,  13,  13]],\n",
      "\n",
      "       [[194, 217, 219],\n",
      "        [197, 220, 222],\n",
      "        [200, 223, 225],\n",
      "        ...,\n",
      "        [ 14,  14,  14],\n",
      "        [ 14,  14,  14],\n",
      "        [ 14,  14,  14]],\n",
      "\n",
      "       [[202, 225, 227],\n",
      "        [206, 229, 231],\n",
      "        [210, 233, 235],\n",
      "        ...,\n",
      "        [ 14,  14,  14],\n",
      "        [ 14,  14,  14],\n",
      "        [ 14,  14,  14]]], dtype=uint8)\n",
      "orig_shape: (800, 1200)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\abolladura-en-un-coche-632c58a6e2ea5.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 4.009246826171875, 'inference': 3482.638359069824, 'postprocess': 6.010532379150391}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 50,  55,  58],\n",
      "        [ 51,  56,  59],\n",
      "        [ 52,  57,  60],\n",
      "        ...,\n",
      "        [ 54,  40, 145],\n",
      "        [ 54,  40, 145],\n",
      "        [ 54,  40, 145]],\n",
      "\n",
      "       [[ 45,  50,  53],\n",
      "        [ 47,  52,  55],\n",
      "        [ 50,  55,  58],\n",
      "        ...,\n",
      "        [ 54,  40, 145],\n",
      "        [ 54,  40, 145],\n",
      "        [ 54,  40, 145]],\n",
      "\n",
      "       [[ 42,  47,  50],\n",
      "        [ 45,  50,  53],\n",
      "        [ 49,  54,  57],\n",
      "        ...,\n",
      "        [ 55,  41, 146],\n",
      "        [ 55,  41, 146],\n",
      "        [ 55,  41, 146]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 92,  80,  76],\n",
      "        [ 92,  80,  76],\n",
      "        [ 92,  80,  76],\n",
      "        ...,\n",
      "        [ 15,  16,  14],\n",
      "        [ 15,  16,  14],\n",
      "        [ 15,  16,  14]],\n",
      "\n",
      "       [[ 83,  71,  67],\n",
      "        [ 83,  71,  67],\n",
      "        [ 83,  71,  67],\n",
      "        ...,\n",
      "        [ 13,  14,  12],\n",
      "        [ 13,  14,  12],\n",
      "        [ 13,  14,  12]],\n",
      "\n",
      "       [[ 14,   2,   0],\n",
      "        [ 14,   2,   0],\n",
      "        [ 14,   2,   0],\n",
      "        ...,\n",
      "        [  2,   3,   1],\n",
      "        [  2,   3,   1],\n",
      "        [  2,   3,   1]]], dtype=uint8)\n",
      "orig_shape: (800, 1200)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.024412155151367, 'inference': 3457.7817916870117, 'postprocess': 6.000995635986328}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[110, 133, 141],\n",
      "        [109, 132, 140],\n",
      "        [108, 134, 141],\n",
      "        ...,\n",
      "        [ 63,  47,  35],\n",
      "        [ 62,  46,  34],\n",
      "        [ 60,  44,  32]],\n",
      "\n",
      "       [[108, 131, 139],\n",
      "        [107, 133, 140],\n",
      "        [104, 130, 137],\n",
      "        ...,\n",
      "        [ 63,  47,  35],\n",
      "        [ 62,  46,  34],\n",
      "        [ 61,  45,  33]],\n",
      "\n",
      "       [[104, 130, 137],\n",
      "        [104, 130, 137],\n",
      "        [107, 132, 142],\n",
      "        ...,\n",
      "        [ 63,  47,  34],\n",
      "        [ 64,  46,  35],\n",
      "        [ 64,  46,  35]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[192, 205, 207],\n",
      "        [201, 214, 216],\n",
      "        [205, 218, 220],\n",
      "        ...,\n",
      "        [ 22,  20,  20],\n",
      "        [ 24,  22,  21],\n",
      "        [ 28,  26,  25]],\n",
      "\n",
      "       [[206, 219, 221],\n",
      "        [206, 219, 221],\n",
      "        [203, 216, 218],\n",
      "        ...,\n",
      "        [ 23,  21,  21],\n",
      "        [ 23,  21,  20],\n",
      "        [ 30,  28,  27]],\n",
      "\n",
      "       [[211, 224, 226],\n",
      "        [206, 219, 221],\n",
      "        [201, 213, 217],\n",
      "        ...,\n",
      "        [ 28,  23,  24],\n",
      "        [ 31,  27,  26],\n",
      "        [ 34,  30,  29]]], dtype=uint8)\n",
      "orig_shape: (287, 600)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\big_ray.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.000093460083008, 'inference': 2465.4250144958496, 'postprocess': 3.999948501586914}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[251, 249, 249],\n",
      "        [251, 249, 249],\n",
      "        [251, 249, 249],\n",
      "        ...,\n",
      "        [  1,   3,   4],\n",
      "        [  1,   3,   4],\n",
      "        [  1,   3,   4]],\n",
      "\n",
      "       [[251, 249, 249],\n",
      "        [251, 249, 249],\n",
      "        [251, 249, 249],\n",
      "        ...,\n",
      "        [  1,   3,   4],\n",
      "        [  1,   3,   4],\n",
      "        [  1,   3,   4]],\n",
      "\n",
      "       [[251, 249, 249],\n",
      "        [251, 249, 249],\n",
      "        [251, 249, 249],\n",
      "        ...,\n",
      "        [  1,   3,   4],\n",
      "        [  1,   3,   4],\n",
      "        [  1,   3,   4]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  2,   1,   3],\n",
      "        [  2,   1,   3],\n",
      "        [  2,   1,   3],\n",
      "        ...,\n",
      "        [ 70,  80,  90],\n",
      "        [ 70,  80,  90],\n",
      "        [ 70,  80,  90]],\n",
      "\n",
      "       [[  2,   1,   3],\n",
      "        [  2,   1,   3],\n",
      "        [  2,   1,   3],\n",
      "        ...,\n",
      "        [ 72,  82,  92],\n",
      "        [ 73,  83,  93],\n",
      "        [ 73,  83,  93]],\n",
      "\n",
      "       [[  2,   1,   3],\n",
      "        [  2,   1,   3],\n",
      "        [  2,   1,   3],\n",
      "        ...,\n",
      "        [ 74,  84,  94],\n",
      "        [ 74,  84,  94],\n",
      "        [ 75,  85,  95]]], dtype=uint8)\n",
      "orig_shape: (533, 800)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.0221939086914062, 'inference': 3538.0280017852783, 'postprocess': 4.985570907592773}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[186, 183, 204],\n",
      "        [186, 183, 204],\n",
      "        [186, 183, 204],\n",
      "        ...,\n",
      "        [  0,   2,   0],\n",
      "        [  0,   2,   0],\n",
      "        [  0,   2,   0]],\n",
      "\n",
      "       [[186, 183, 204],\n",
      "        [186, 183, 204],\n",
      "        [186, 183, 204],\n",
      "        ...,\n",
      "        [  0,   2,   0],\n",
      "        [  0,   2,   0],\n",
      "        [  0,   2,   0]],\n",
      "\n",
      "       [[186, 183, 204],\n",
      "        [186, 183, 204],\n",
      "        [186, 183, 204],\n",
      "        ...,\n",
      "        [  0,   2,   0],\n",
      "        [  0,   4,   1],\n",
      "        [  0,   4,   1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 87, 105, 100],\n",
      "        [ 88, 106, 101],\n",
      "        [ 92, 110, 104],\n",
      "        ...,\n",
      "        [  4,  10,  14],\n",
      "        [  4,  10,  14],\n",
      "        [  4,  10,  14]],\n",
      "\n",
      "       [[ 87, 105, 100],\n",
      "        [ 88, 106, 101],\n",
      "        [ 92, 110, 104],\n",
      "        ...,\n",
      "        [  4,  12,  15],\n",
      "        [  4,  12,  15],\n",
      "        [  2,  10,  14]],\n",
      "\n",
      "       [[ 87, 105, 100],\n",
      "        [ 88, 106, 101],\n",
      "        [ 92, 110, 104],\n",
      "        ...,\n",
      "        [  4,  12,  15],\n",
      "        [  4,  12,  15],\n",
      "        [  4,  12,  15]]], dtype=uint8)\n",
      "orig_shape: (800, 800)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\e1b235cf346a92a59d23c353c5ab913c.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 4.002809524536133, 'inference': 6605.672121047974, 'postprocess': 4.015922546386719}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[222, 191, 176],\n",
      "        [216, 187, 172],\n",
      "        [214, 185, 170],\n",
      "        ...,\n",
      "        [241, 229, 229],\n",
      "        [168, 160, 160],\n",
      "        [ 99,  94,  93]],\n",
      "\n",
      "       [[213, 184, 169],\n",
      "        [213, 184, 169],\n",
      "        [215, 186, 171],\n",
      "        ...,\n",
      "        [243, 231, 229],\n",
      "        [171, 162, 159],\n",
      "        [ 90,  85,  82]],\n",
      "\n",
      "       [[213, 184, 169],\n",
      "        [213, 184, 169],\n",
      "        [216, 187, 172],\n",
      "        ...,\n",
      "        [247, 235, 229],\n",
      "        [180, 172, 165],\n",
      "        [ 94,  88,  81]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[150, 128, 133],\n",
      "        [146, 124, 129],\n",
      "        [174, 155, 158],\n",
      "        ...,\n",
      "        [205, 179, 167],\n",
      "        [167, 155, 145],\n",
      "        [135, 134, 124]],\n",
      "\n",
      "       [[169, 148, 156],\n",
      "        [147, 126, 134],\n",
      "        [160, 142, 149],\n",
      "        ...,\n",
      "        [204, 178, 166],\n",
      "        [169, 157, 147],\n",
      "        [137, 136, 126]],\n",
      "\n",
      "       [[161, 140, 149],\n",
      "        [150, 131, 140],\n",
      "        [171, 153, 160],\n",
      "        ...,\n",
      "        [203, 177, 165],\n",
      "        [166, 154, 144],\n",
      "        [137, 136, 126]]], dtype=uint8)\n",
      "orig_shape: (600, 600)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\paintless-dent-removal-3-1.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.9963722229003906, 'inference': 5243.744373321533, 'postprocess': 4.99415397644043}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[155, 159, 154],\n",
      "        [165, 169, 164],\n",
      "        [168, 169, 165],\n",
      "        ...,\n",
      "        [ 73,  88,  97],\n",
      "        [ 76,  92,  99],\n",
      "        [ 76,  92,  99]],\n",
      "\n",
      "       [[157, 161, 156],\n",
      "        [163, 167, 162],\n",
      "        [166, 167, 163],\n",
      "        ...,\n",
      "        [ 82,  97, 106],\n",
      "        [ 80,  96, 103],\n",
      "        [ 80,  96, 103]],\n",
      "\n",
      "       [[164, 165, 161],\n",
      "        [162, 163, 159],\n",
      "        [164, 165, 161],\n",
      "        ...,\n",
      "        [ 84, 102, 109],\n",
      "        [ 85, 101, 108],\n",
      "        [ 85, 101, 108]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[107, 101,  94],\n",
      "        [110, 104,  97],\n",
      "        [113, 107, 100],\n",
      "        ...,\n",
      "        [139, 155, 161],\n",
      "        [142, 161, 166],\n",
      "        [142, 161, 166]],\n",
      "\n",
      "       [[100,  94,  87],\n",
      "        [103,  97,  90],\n",
      "        [107, 101,  94],\n",
      "        ...,\n",
      "        [140, 156, 162],\n",
      "        [143, 162, 167],\n",
      "        [143, 162, 167]],\n",
      "\n",
      "       [[ 88,  82,  75],\n",
      "        [ 92,  86,  79],\n",
      "        [ 97,  91,  84],\n",
      "        ...,\n",
      "        [143, 159, 165],\n",
      "        [138, 157, 162],\n",
      "        [138, 157, 162]]], dtype=uint8)\n",
      "orig_shape: (456, 850)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 2.0003318786621094, 'inference': 3961.158037185669, 'postprocess': 4.998922348022461}, ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 63,  89, 136],\n",
      "        [ 65,  91, 138],\n",
      "        [ 67,  93, 140],\n",
      "        ...,\n",
      "        [206, 207, 205],\n",
      "        [206, 207, 205],\n",
      "        [207, 208, 206]],\n",
      "\n",
      "       [[ 66,  92, 139],\n",
      "        [ 67,  93, 140],\n",
      "        [ 68,  94, 141],\n",
      "        ...,\n",
      "        [206, 207, 205],\n",
      "        [206, 207, 205],\n",
      "        [206, 207, 205]],\n",
      "\n",
      "       [[ 69,  95, 142],\n",
      "        [ 69,  95, 142],\n",
      "        [ 69,  95, 142],\n",
      "        ...,\n",
      "        [205, 206, 204],\n",
      "        [205, 206, 204],\n",
      "        [205, 206, 204]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[112, 109, 111],\n",
      "        [117, 116, 118],\n",
      "        [124, 121, 123],\n",
      "        ...,\n",
      "        [157, 166, 176],\n",
      "        [156, 165, 175],\n",
      "        [156, 165, 175]],\n",
      "\n",
      "       [[114, 111, 113],\n",
      "        [120, 117, 119],\n",
      "        [125, 122, 124],\n",
      "        ...,\n",
      "        [157, 166, 176],\n",
      "        [156, 165, 175],\n",
      "        [156, 165, 175]],\n",
      "\n",
      "       [[114, 111, 113],\n",
      "        [120, 117, 119],\n",
      "        [125, 122, 124],\n",
      "        ...,\n",
      "        [157, 166, 176],\n",
      "        [157, 166, 176],\n",
      "        [156, 165, 175]]], dtype=uint8)\n",
      "orig_shape: (675, 1013)\n",
      "path: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\assets_affectation\\\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\matrix\\\\pruebayolo\\\\proyecto_yolo\\\\src\\\\runs\\\\segment\\\\predict_car'\n",
      "speed: {'preprocess': 3.0074119567871094, 'inference': 3700.629949569702, 'postprocess': 4.998445510864258}]\n",
      "ee C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\n",
      "Parameters not available for the task: ['rect']\n",
      "Configuration included: conf=0.39, max_det=10, save_txt=False, visualize=False, line_width=None, iou=0.6, vid_stride=False, stream_buffer=False, save_frames=False, augment=False, save_crop=False, show=False, save_conf=True, agnostic_nms=True, retina_masks=True, name=predict_affectation_seg_srcv5-seg, imgsz=640, device=cpu, save=True\n",
      "Using the model: c:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\srcv5\\model_segmentation\\segmentation\\training_affectation\\weights\\best.pt\n",
      "\n",
      "image 1/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\20170531_010133[1].jpg: 416x640 (no detections), 229.0ms\n",
      "image 2/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\Car-Dent[1].png: 384x640 2 abolladuras, 209.0ms\n",
      "image 3/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\Charlotte-Toyota-service-1-1024x683[1].jpg: 448x640 3 rayons, 237.0ms\n",
      "image 4/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\Charlotte-Toyota-service-1-1024x683[2].jpg: 512x640 (no detections), 255.0ms\n",
      "image 5/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\OIP (4)[1].jpeg: 480x640 1 abolladura, 1 rayon, 254.0ms\n",
      "image 6/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\OIP(3)[1].jpeg: 448x640 (no detections), 224.0ms\n",
      "image 7/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R2[1].jpeg: 544x640 (no detections), 272.6ms\n",
      "image 8/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R2[2].jpeg: 320x640 (no detections), 172.0ms\n",
      "image 9/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R3[1].jpeg: 448x640 3 abolladuras, 241.0ms\n",
      "image 10/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R5[1].jpeg: 512x640 1 abolladura, 257.1ms\n",
      "image 11/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R7[1].png: 576x640 1 abolladura, 290.0ms\n",
      "image 12/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R7[2].png: 384x640 1 abolladura, 246.1ms\n",
      "image 13/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R7[3].png: 608x640 (no detections), 327.9ms\n",
      "image 14/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R7[4].png: 640x640 1 abolladura, 317.0ms\n",
      "image 15/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\R[1].jpg: 512x640 1 abolladura, 257.0ms\n",
      "image 16/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\abolladura-en-un-coche-632c58a6e2ea5[1].jpg: 448x640 1 rayon, 226.0ms\n",
      "image 17/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800[1].jpg: 448x640 (no detections), 221.0ms\n",
      "image 18/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\big_ray[1].jpg: 416x640 (no detections), 206.0ms\n",
      "image 19/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\coche-despus-de-una-ruina-la-necesidad-ser-reparado-esperndola-es-demanda-de-seguro-29745503[1].jpg: 448x640 (no detections), 221.0ms\n",
      "image 20/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0[1].jpg: 352x640 1 abolladura, 1 rayon, 179.0ms\n",
      "image 21/21 C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675[1].jpg: 448x640 2 abolladuras, 220.0ms\n",
      "Speed: 2.9ms preprocess, 241.0ms inference, 6.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mc:\\Users\\matrix\\pruebayolo\\proyecto_yolo\\src\\runs\\segment\\predict_affectation_seg_srcv5-seg2\u001b[0m\n",
      "Temporary directory C:\\Users\\jemss\\AppData\\Local\\Temp\\tmpbtodfyfu successfully deleted!\n"
     ]
    }
   ],
   "source": [
    "class Predict: \n",
    "    def __init__(self, name, isinstance_model, data, classes, save_value, **kwargs):\n",
    "        self.name = name \n",
    "        self.isinstance_model = isinstance_model\n",
    "        self.data = data \n",
    "        self.classes= classes\n",
    "        self.save_value = save_value\n",
    "        self.custom_settings = kwargs\n",
    "        self.prediction_settings = {\n",
    "            'conf': 0.4,\n",
    "            'max_det': 10,\n",
    "            'save_txt': False,\n",
    "            'visualize': False,\n",
    "            'line_width': None,\n",
    "            'iou': 0.6,\n",
    "            'vid_stride': False,\n",
    "            'stream_buffer': False,\n",
    "            'save_frames': False,\n",
    "            'augment': False, # augment=True -> Error when executing the prediction task: 'NoneType' object is not subscriptable\n",
    "            'save_crop': False,\n",
    "            'show': False,\n",
    "            'save_conf': True,\n",
    "            'agnostic_nms': True,\n",
    "            'retina_masks': False\n",
    "            }\n",
    "        \n",
    "        self.config = Custom_settings(name=self.name, base_setup=self.prediction_settings, kwargs= self.custom_settings, save=self.save_value)\n",
    "        self.config.set_apply_defaults()\n",
    "        \n",
    "    def prediction(self):\n",
    "        try:\n",
    "            results = self.config.loading_model(self.isinstance_model).predict(source=self.data, classes=self.classes, **self.prediction_settings)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f'Error when executing the prediction task: {e}')\n",
    "    \n",
    "    def _temp_controller(self, results_car): # Maneja el directorio temporal para los resultados del coche.\n",
    "        try:\n",
    "            print('resultados', results_car)\n",
    "            dir_temp = tempfile.mkdtemp() # Se crea un directorio temporal, establezca entre los (prefix='', dir='') si desea controlar el nombre y la ruta donde se guardara el directorio temporal.\n",
    "            print('ee', dir_temp)\n",
    "            self._create_crops(results_car, dir_temp)  # Crea recortes a partir de los resultados de los coches.\n",
    "            return dir_temp # Devuelve la ruta del directorio temporal.\n",
    "        except Exception as e:\n",
    "            print(f'{e}')\n",
    "    \n",
    "    def _create_crops(self, results_car, dir_temp): #  Crea recortes a partir de objetos detectados en una imagen.\n",
    "        try:\n",
    "            for attribute_car in results_car: # Recorre los resultados de la segmentación de carro.\n",
    "                img_data = np.copy(attribute_car.orig_img) # Copia la imagen original.\n",
    "                img_path = Path(attribute_car.path) \n",
    "                img_name = img_path.stem # Obtiene el nombre de la imagen por medio de la ruta.\n",
    "                img_extension = img_path.suffix # Obtiene la extensión de la imagen.\n",
    "\n",
    "                for ci, c in enumerate(attribute_car): # Itera sobre cada objeto detectado.\n",
    "                    b_mask = np.zeros(img_data.shape[:2], np.uint8) # Crea una máscara binaria del tamaño de la imagen original, inicializada a ceros.\n",
    "                    contour = c.masks.xy.pop().astype(np.int32).reshape(-1, 1, 2) # Extrae el contorno del objeto, lo convierte a enteros y lo reconfigura para drawContours.\n",
    "                    _ = cv2.drawContours(b_mask, [contour], -1, (255, 255, 255), cv2.FILLED) # Dibuja el contorno en la máscara binaria, rellenando el área del objeto.\n",
    "                    \n",
    "                    mask3ch = cv2.cvtColor(b_mask, cv2.COLOR_GRAY2BGR) # Convierte la máscara binaria a 3 canales.\n",
    "                    isolated = cv2.bitwise_and(mask3ch, img_data) # Permite aislar el objeto de la imagen. Para fondo trasparente \"isolated = np.dstack([img_data, b_mask])\".\n",
    "                    \n",
    "                    x1, y1, x2, y2 = c.boxes.xyxy.cpu().numpy().squeeze().astype(np.int32) # Obtiene las coordenadas de la caja delimitadora.\n",
    "                    iso_crop = isolated[y1:y2, x1:x2] # Recorta el objeto aislado.\n",
    "\n",
    "                    file_name = f'{img_name}[{ci +1}]{img_extension}'  # Se crea un nombre de archivo para el recorte.\n",
    "                    cv2.imwrite(os.path.join(dir_temp, file_name), iso_crop) # Guardar el recorte en el directorio temporal.\"\"\"\n",
    "        except Exception as e:\n",
    "            print(f'{e}')\n",
    "\n",
    "    def _delete_temp(self, temp_car): # Permite eliminar un directorio temporal.\n",
    "        try: \n",
    "            shutil.rmtree(temp_car)  # Elimina un directorio temporal según la ruta especificada.\n",
    "            print(f'Temporary directory {temp_car} successfully deleted!')\n",
    "        except Exception as e: # Captura cualquier excepción e imprime un mensaje de error.\n",
    "            print(f'Error deleting the directory: {e}')\n",
    "\n",
    "# model_affectation, output_queue, [0, 1], 0.39, \"predict_affectation_seg_srcv5-seg\", dir_temp_car, SAVE, SAVE_TXT, MAX_DET\n",
    "\n",
    "try:\n",
    "    object_car = Predict(name='predict_car', isinstance_model=model_orig, data=dir_prueba, classes=2, conf=0.3, max_det=5, half=True, save_value=False)\n",
    "    results_car=object_car.prediction()\n",
    "    temp=object_car._temp_controller(results_car)\n",
    "    try:\n",
    "        object_affectation = Predict(name='predict_affectation_seg_srcv5-seg', isinstance_model=model_affectation, data=temp, classes=[0, 1], conf=0.39, max_det=10, retina_masks= True, rect= False, save_value=True)\n",
    "        results_affectation = object_affectation.prediction()\n",
    "        object_car._delete_temp(temp)\n",
    "    except Exception as e:\n",
    "            print(f'{e}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'{e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Función de área para mascaras segmentadas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Dataframe con las áreas totales</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_030a7_row0_col0, #T_030a7_row0_col1, #T_030a7_row0_col2, #T_030a7_row0_col3, #T_030a7_row0_col4, #T_030a7_row1_col0, #T_030a7_row1_col1, #T_030a7_row1_col2, #T_030a7_row1_col3, #T_030a7_row1_col4, #T_030a7_row2_col0, #T_030a7_row2_col1, #T_030a7_row2_col2, #T_030a7_row2_col3, #T_030a7_row2_col4, #T_030a7_row3_col0, #T_030a7_row3_col1, #T_030a7_row3_col2, #T_030a7_row3_col3, #T_030a7_row3_col4, #T_030a7_row4_col0, #T_030a7_row4_col1, #T_030a7_row4_col2, #T_030a7_row4_col3, #T_030a7_row4_col4, #T_030a7_row5_col0, #T_030a7_row5_col1, #T_030a7_row5_col2, #T_030a7_row5_col3, #T_030a7_row5_col4, #T_030a7_row6_col0, #T_030a7_row6_col1, #T_030a7_row6_col2, #T_030a7_row6_col3, #T_030a7_row6_col4, #T_030a7_row7_col0, #T_030a7_row7_col1, #T_030a7_row7_col2, #T_030a7_row7_col3, #T_030a7_row7_col4, #T_030a7_row8_col0, #T_030a7_row8_col1, #T_030a7_row8_col2, #T_030a7_row8_col3, #T_030a7_row8_col4, #T_030a7_row9_col0, #T_030a7_row9_col1, #T_030a7_row9_col2, #T_030a7_row9_col3, #T_030a7_row9_col4, #T_030a7_row10_col0, #T_030a7_row10_col1, #T_030a7_row10_col2, #T_030a7_row10_col3, #T_030a7_row10_col4, #T_030a7_row11_col0, #T_030a7_row11_col1, #T_030a7_row11_col2, #T_030a7_row11_col3, #T_030a7_row11_col4, #T_030a7_row12_col0, #T_030a7_row12_col1, #T_030a7_row12_col2, #T_030a7_row12_col3, #T_030a7_row12_col4, #T_030a7_row13_col0, #T_030a7_row13_col1, #T_030a7_row13_col2, #T_030a7_row13_col3, #T_030a7_row13_col4, #T_030a7_row14_col0, #T_030a7_row14_col1, #T_030a7_row14_col2, #T_030a7_row14_col3, #T_030a7_row14_col4, #T_030a7_row15_col0, #T_030a7_row15_col1, #T_030a7_row15_col2, #T_030a7_row15_col3, #T_030a7_row15_col4, #T_030a7_row16_col0, #T_030a7_row16_col1, #T_030a7_row16_col2, #T_030a7_row16_col3, #T_030a7_row16_col4, #T_030a7_row17_col0, #T_030a7_row17_col1, #T_030a7_row17_col2, #T_030a7_row17_col3, #T_030a7_row17_col4, #T_030a7_row18_col0, #T_030a7_row18_col1, #T_030a7_row18_col2, #T_030a7_row18_col3, #T_030a7_row18_col4, #T_030a7_row19_col0, #T_030a7_row19_col1, #T_030a7_row19_col2, #T_030a7_row19_col3, #T_030a7_row19_col4, #T_030a7_row20_col0, #T_030a7_row20_col1, #T_030a7_row20_col2, #T_030a7_row20_col3, #T_030a7_row20_col4, #T_030a7_row21_col0, #T_030a7_row21_col1, #T_030a7_row21_col2, #T_030a7_row21_col3, #T_030a7_row21_col4, #T_030a7_row22_col0, #T_030a7_row22_col1, #T_030a7_row22_col2, #T_030a7_row22_col3, #T_030a7_row22_col4, #T_030a7_row23_col0, #T_030a7_row23_col1, #T_030a7_row23_col2, #T_030a7_row23_col3, #T_030a7_row23_col4, #T_030a7_row24_col0, #T_030a7_row24_col1, #T_030a7_row24_col2, #T_030a7_row24_col3, #T_030a7_row24_col4, #T_030a7_row25_col0, #T_030a7_row25_col1, #T_030a7_row25_col2, #T_030a7_row25_col3, #T_030a7_row25_col4, #T_030a7_row26_col0, #T_030a7_row26_col1, #T_030a7_row26_col2, #T_030a7_row26_col3, #T_030a7_row26_col4, #T_030a7_row27_col0, #T_030a7_row27_col1, #T_030a7_row27_col2, #T_030a7_row27_col3, #T_030a7_row27_col4, #T_030a7_row28_col0, #T_030a7_row28_col1, #T_030a7_row28_col2, #T_030a7_row28_col3, #T_030a7_row28_col4 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_030a7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_030a7_level0_col0\" class=\"col_heading level0 col0\" >equivalencia</th>\n",
       "      <th id=\"T_030a7_level0_col1\" class=\"col_heading level0 col1\" >area abolladura</th>\n",
       "      <th id=\"T_030a7_level0_col2\" class=\"col_heading level0 col2\" >area rayon</th>\n",
       "      <th id=\"T_030a7_level0_col3\" class=\"col_heading level0 col3\" >area carro</th>\n",
       "      <th id=\"T_030a7_level0_col4\" class=\"col_heading level0 col4\" >afectacion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >imagen</th>\n",
       "      <th class=\"index_name level1\" >&nbsp;</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row0\" class=\"row_heading level0 row0\" >20170531_010133.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row0\" class=\"row_heading level1 row0\" >0</th>\n",
       "      <td id=\"T_030a7_row0_col0\" class=\"data row0 col0\" >20170531_010133[1].jpg</td>\n",
       "      <td id=\"T_030a7_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row0_col4\" class=\"data row0 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row1\" class=\"row_heading level0 row1\" >5-320w-320w.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row1\" class=\"row_heading level1 row1\" >1</th>\n",
       "      <td id=\"T_030a7_row1_col0\" class=\"data row1 col0\" >5-320w-320w[1].jpg</td>\n",
       "      <td id=\"T_030a7_row1_col1\" class=\"data row1 col1\" >14932</td>\n",
       "      <td id=\"T_030a7_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row1_col3\" class=\"data row1 col3\" >62874</td>\n",
       "      <td id=\"T_030a7_row1_col4\" class=\"data row1 col4\" >47942 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row2\" class=\"row_heading level0 row2\" >Car-Dent.png</th>\n",
       "      <th id=\"T_030a7_level1_row2\" class=\"row_heading level1 row2\" >2</th>\n",
       "      <td id=\"T_030a7_row2_col0\" class=\"data row2 col0\" >Car-Dent[1].png</td>\n",
       "      <td id=\"T_030a7_row2_col1\" class=\"data row2 col1\" >34156</td>\n",
       "      <td id=\"T_030a7_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row2_col3\" class=\"data row2 col3\" >134698</td>\n",
       "      <td id=\"T_030a7_row2_col4\" class=\"data row2 col4\" >100542 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"2\">Charlotte-Toyota-service-1-1024x683.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row3\" class=\"row_heading level1 row3\" >3</th>\n",
       "      <td id=\"T_030a7_row3_col0\" class=\"data row3 col0\" >Charlotte-Toyota-service-1-1024x683[1].jpg</td>\n",
       "      <td id=\"T_030a7_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row3_col2\" class=\"data row3 col2\" >13391</td>\n",
       "      <td id=\"T_030a7_row3_col3\" class=\"data row3 col3\" >584878</td>\n",
       "      <td id=\"T_030a7_row3_col4\" class=\"data row3 col4\" >571487 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level1_row4\" class=\"row_heading level1 row4\" >4</th>\n",
       "      <td id=\"T_030a7_row4_col0\" class=\"data row4 col0\" >Charlotte-Toyota-service-1-1024x683[2].jpg</td>\n",
       "      <td id=\"T_030a7_row4_col1\" class=\"data row4 col1\" >6581</td>\n",
       "      <td id=\"T_030a7_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row4_col3\" class=\"data row4 col3\" >29400</td>\n",
       "      <td id=\"T_030a7_row4_col4\" class=\"data row4 col4\" >22819 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row5\" class=\"row_heading level0 row5\" >GSDH75MG6FAM7FSG43RFQLN5R4.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row5\" class=\"row_heading level1 row5\" >5</th>\n",
       "      <td id=\"T_030a7_row5_col0\" class=\"data row5 col0\" >GSDH75MG6FAM7FSG43RFQLN5R4[1].jpg</td>\n",
       "      <td id=\"T_030a7_row5_col1\" class=\"data row5 col1\" >79546</td>\n",
       "      <td id=\"T_030a7_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row5_col3\" class=\"data row5 col3\" >518024</td>\n",
       "      <td id=\"T_030a7_row5_col4\" class=\"data row5 col4\" >438478 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row6\" class=\"row_heading level0 row6\" >OIP (1).jpg</th>\n",
       "      <th id=\"T_030a7_level1_row6\" class=\"row_heading level1 row6\" >6</th>\n",
       "      <td id=\"T_030a7_row6_col0\" class=\"data row6 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row6_col4\" class=\"data row6 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row7\" class=\"row_heading level0 row7\" >OIP (2).jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row7\" class=\"row_heading level1 row7\" >7</th>\n",
       "      <td id=\"T_030a7_row7_col0\" class=\"data row7 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row7_col4\" class=\"data row7 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row8\" class=\"row_heading level0 row8\" >OIP (4).jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row8\" class=\"row_heading level1 row8\" >8</th>\n",
       "      <td id=\"T_030a7_row8_col0\" class=\"data row8 col0\" >OIP (4)[1].jpeg</td>\n",
       "      <td id=\"T_030a7_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row8_col2\" class=\"data row8 col2\" >284</td>\n",
       "      <td id=\"T_030a7_row8_col3\" class=\"data row8 col3\" >677376</td>\n",
       "      <td id=\"T_030a7_row8_col4\" class=\"data row8 col4\" >677092 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row9\" class=\"row_heading level0 row9\" >OIP(3).jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row9\" class=\"row_heading level1 row9\" >9</th>\n",
       "      <td id=\"T_030a7_row9_col0\" class=\"data row9 col0\" >OIP(3)[1].jpeg</td>\n",
       "      <td id=\"T_030a7_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row9_col4\" class=\"data row9 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row10\" class=\"row_heading level0 row10\" >R.jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row10\" class=\"row_heading level1 row10\" >10</th>\n",
       "      <td id=\"T_030a7_row10_col0\" class=\"data row10 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row10_col4\" class=\"data row10 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row11\" class=\"row_heading level0 row11\" >R.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row11\" class=\"row_heading level1 row11\" >11</th>\n",
       "      <td id=\"T_030a7_row11_col0\" class=\"data row11 col0\" >R[1].jpg</td>\n",
       "      <td id=\"T_030a7_row11_col1\" class=\"data row11 col1\" >40800</td>\n",
       "      <td id=\"T_030a7_row11_col2\" class=\"data row11 col2\" >62</td>\n",
       "      <td id=\"T_030a7_row11_col3\" class=\"data row11 col3\" >327278</td>\n",
       "      <td id=\"T_030a7_row11_col4\" class=\"data row11 col4\" >286416 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row12\" class=\"row_heading level0 row12\" rowspan=\"2\">R2.jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row12\" class=\"row_heading level1 row12\" >12</th>\n",
       "      <td id=\"T_030a7_row12_col0\" class=\"data row12 col0\" >R2[1].jpeg</td>\n",
       "      <td id=\"T_030a7_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row12_col3\" class=\"data row12 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row12_col4\" class=\"data row12 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level1_row13\" class=\"row_heading level1 row13\" >13</th>\n",
       "      <td id=\"T_030a7_row13_col0\" class=\"data row13 col0\" >R2[2].jpeg</td>\n",
       "      <td id=\"T_030a7_row13_col1\" class=\"data row13 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row13_col3\" class=\"data row13 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row13_col4\" class=\"data row13 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row14\" class=\"row_heading level0 row14\" >R3.jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row14\" class=\"row_heading level1 row14\" >14</th>\n",
       "      <td id=\"T_030a7_row14_col0\" class=\"data row14 col0\" >R3[1].jpeg</td>\n",
       "      <td id=\"T_030a7_row14_col1\" class=\"data row14 col1\" >88224</td>\n",
       "      <td id=\"T_030a7_row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row14_col3\" class=\"data row14 col3\" >199908</td>\n",
       "      <td id=\"T_030a7_row14_col4\" class=\"data row14 col4\" >111684 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row15\" class=\"row_heading level0 row15\" >R5.jpeg</th>\n",
       "      <th id=\"T_030a7_level1_row15\" class=\"row_heading level1 row15\" >15</th>\n",
       "      <td id=\"T_030a7_row15_col0\" class=\"data row15 col0\" >R5[1].jpeg</td>\n",
       "      <td id=\"T_030a7_row15_col1\" class=\"data row15 col1\" >27675</td>\n",
       "      <td id=\"T_030a7_row15_col2\" class=\"data row15 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row15_col3\" class=\"data row15 col3\" >262338</td>\n",
       "      <td id=\"T_030a7_row15_col4\" class=\"data row15 col4\" >234663 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"3\">R7.png</th>\n",
       "      <th id=\"T_030a7_level1_row16\" class=\"row_heading level1 row16\" >16</th>\n",
       "      <td id=\"T_030a7_row16_col0\" class=\"data row16 col0\" >R7[1].png</td>\n",
       "      <td id=\"T_030a7_row16_col1\" class=\"data row16 col1\" >25550</td>\n",
       "      <td id=\"T_030a7_row16_col2\" class=\"data row16 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row16_col3\" class=\"data row16 col3\" >289600</td>\n",
       "      <td id=\"T_030a7_row16_col4\" class=\"data row16 col4\" >264050 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level1_row17\" class=\"row_heading level1 row17\" >17</th>\n",
       "      <td id=\"T_030a7_row17_col0\" class=\"data row17 col0\" >R7[2].png</td>\n",
       "      <td id=\"T_030a7_row17_col1\" class=\"data row17 col1\" >35777</td>\n",
       "      <td id=\"T_030a7_row17_col2\" class=\"data row17 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row17_col3\" class=\"data row17 col3\" >259768</td>\n",
       "      <td id=\"T_030a7_row17_col4\" class=\"data row17 col4\" >223991 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level1_row18\" class=\"row_heading level1 row18\" >18</th>\n",
       "      <td id=\"T_030a7_row18_col0\" class=\"data row18 col0\" >R7[3].png</td>\n",
       "      <td id=\"T_030a7_row18_col1\" class=\"data row18 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row18_col2\" class=\"data row18 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row18_col3\" class=\"data row18 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row18_col4\" class=\"data row18 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row19\" class=\"row_heading level0 row19\" >R8.png</th>\n",
       "      <th id=\"T_030a7_level1_row19\" class=\"row_heading level1 row19\" >19</th>\n",
       "      <td id=\"T_030a7_row19_col0\" class=\"data row19 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row19_col1\" class=\"data row19 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row19_col2\" class=\"data row19 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row19_col3\" class=\"data row19 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row19_col4\" class=\"data row19 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row20\" class=\"row_heading level0 row20\" >Webp.net-resizeimage-10-1170x600.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row20\" class=\"row_heading level1 row20\" >20</th>\n",
       "      <td id=\"T_030a7_row20_col0\" class=\"data row20 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row20_col1\" class=\"data row20 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row20_col2\" class=\"data row20 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row20_col3\" class=\"data row20 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row20_col4\" class=\"data row20 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row21\" class=\"row_heading level0 row21\" >abolladura-en-un-coche-632c58a6e2ea5.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row21\" class=\"row_heading level1 row21\" >21</th>\n",
       "      <td id=\"T_030a7_row21_col0\" class=\"data row21 col0\" >abolladura-en-un-coche-632c58a6e2ea5[1].jpg</td>\n",
       "      <td id=\"T_030a7_row21_col1\" class=\"data row21 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row21_col2\" class=\"data row21 col2\" >228</td>\n",
       "      <td id=\"T_030a7_row21_col3\" class=\"data row21 col3\" >769696</td>\n",
       "      <td id=\"T_030a7_row21_col4\" class=\"data row21 col4\" >769468 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row22\" class=\"row_heading level0 row22\" >abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row22\" class=\"row_heading level1 row22\" >22</th>\n",
       "      <td id=\"T_030a7_row22_col0\" class=\"data row22 col0\" >abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800[1].jpg</td>\n",
       "      <td id=\"T_030a7_row22_col1\" class=\"data row22 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row22_col2\" class=\"data row22 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row22_col3\" class=\"data row22 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row22_col4\" class=\"data row22 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row23\" class=\"row_heading level0 row23\" >big_ray.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row23\" class=\"row_heading level1 row23\" >23</th>\n",
       "      <td id=\"T_030a7_row23_col0\" class=\"data row23 col0\" >big_ray[1].jpg</td>\n",
       "      <td id=\"T_030a7_row23_col1\" class=\"data row23 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row23_col2\" class=\"data row23 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row23_col3\" class=\"data row23 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row23_col4\" class=\"data row23 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row24\" class=\"row_heading level0 row24\" >coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row24\" class=\"row_heading level1 row24\" >24</th>\n",
       "      <td id=\"T_030a7_row24_col0\" class=\"data row24 col0\" >coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503[1].jpg</td>\n",
       "      <td id=\"T_030a7_row24_col1\" class=\"data row24 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row24_col2\" class=\"data row24 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row24_col3\" class=\"data row24 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row24_col4\" class=\"data row24 col4\" >0 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row25\" class=\"row_heading level0 row25\" >e1b235cf346a92a59d23c353c5ab913c.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row25\" class=\"row_heading level1 row25\" >25</th>\n",
       "      <td id=\"T_030a7_row25_col0\" class=\"data row25 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row25_col1\" class=\"data row25 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row25_col2\" class=\"data row25 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row25_col3\" class=\"data row25 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row25_col4\" class=\"data row25 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row26\" class=\"row_heading level0 row26\" >paintless-dent-removal-3-1.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row26\" class=\"row_heading level1 row26\" >26</th>\n",
       "      <td id=\"T_030a7_row26_col0\" class=\"data row26 col0\" >sin coincidencia</td>\n",
       "      <td id=\"T_030a7_row26_col1\" class=\"data row26 col1\" >0</td>\n",
       "      <td id=\"T_030a7_row26_col2\" class=\"data row26 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row26_col3\" class=\"data row26 col3\" >0</td>\n",
       "      <td id=\"T_030a7_row26_col4\" class=\"data row26 col4\" >0px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row27\" class=\"row_heading level0 row27\" >rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row27\" class=\"row_heading level1 row27\" >27</th>\n",
       "      <td id=\"T_030a7_row27_col0\" class=\"data row27 col0\" >rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0[1].jpg</td>\n",
       "      <td id=\"T_030a7_row27_col1\" class=\"data row27 col1\" >1762</td>\n",
       "      <td id=\"T_030a7_row27_col2\" class=\"data row27 col2\" >241</td>\n",
       "      <td id=\"T_030a7_row27_col3\" class=\"data row27 col3\" >361604</td>\n",
       "      <td id=\"T_030a7_row27_col4\" class=\"data row27 col4\" >359601 px^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_030a7_level0_row28\" class=\"row_heading level0 row28\" >trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg</th>\n",
       "      <th id=\"T_030a7_level1_row28\" class=\"row_heading level1 row28\" >28</th>\n",
       "      <td id=\"T_030a7_row28_col0\" class=\"data row28 col0\" >trucos-para-quitar-abolladuras-del-coche.imagen-1013x675[1].jpg</td>\n",
       "      <td id=\"T_030a7_row28_col1\" class=\"data row28 col1\" >73564</td>\n",
       "      <td id=\"T_030a7_row28_col2\" class=\"data row28 col2\" >0</td>\n",
       "      <td id=\"T_030a7_row28_col3\" class=\"data row28 col3\" >498496</td>\n",
       "      <td id=\"T_030a7_row28_col4\" class=\"data row28 col4\" >424932 px^2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2f51f48ab00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_area(vertices): \n",
    "    total_mask_area = 0 # Se inicializa una variable acumuladora para almacenar la suma total del área de cada máscara por clase en una imagen.\n",
    "    for point in vertices: # Recorre los puntos de contorno que se encuentran separados por medio de una lista para cada región segmentada.\n",
    "        x_coordinate = point[:, 0] # Asigna todas las filas correspondientes a la primera columna como coordenada X del formato de masks.xy que entrega por medio de arreglos los vértices (x, y) en pixel.\n",
    "        y_coordinate = point[:, 1] # Asigna todas las filas correspondientes a la segunda columna como coordenada Y.\n",
    "        mask_area = np.round(0.5 * abs(np.dot(x_coordinate, np.roll(y_coordinate, 1)) - np.dot(y_coordinate, np.roll(x_coordinate, 1)))).astype(int) # Almacena el resultado del área por máscara, basándose en la fórmula Shoelace o lazada de Gauss. Utiliza la suma y la resta de los productos cruzados de las coordenadas de los vértices del polígono; el término np.roll(y, 1) y np.roll(x, 1) crean versiones desplazadas circularmente, lo cual es esencial para que np.dot() calcule el producto punto de los vértices del polígono. La diferencia entre los productos cruzados se multiplicará por 1/2 tomando el valor absoluto.\n",
    "        total_mask_area += mask_area #  Acumula cada área individual para entregar un área total de afectación por clase.\n",
    "    return total_mask_area \n",
    "\n",
    "def find_coincidence(filename): \n",
    "    # El nombre del archivo que contiene un número de variante entre corchetes.\n",
    "    return filename.split('[')[0] + os.path.splitext(filename)[1] # Extrae el nombre original de la imagen eliminando el número de variante entre corchetes y conservando la extensión del archivo.\n",
    "\n",
    "def search_for_mask_affectation(segmentation_results, image_instance): # Encuentra subimágenes comunes en los resultados de segmentación y obtiene el área de cada clase de afectación (abolladura y rayón) para cada subimagen.\n",
    "    sub_image_results = []\n",
    "    for attribute in segmentation_results: # Se itera sobre los resultados de la segmentación.\n",
    "        if find_coincidence(os.path.basename(attribute.path)) == image_instance: # Para relacionar ambos formatos de imagen sin sobrescribir las posibles subimágenes con el mismo nombre que se puedan encontrar, se envía a la función \"find_coincidente\" la base del nombre por parte de los resultados de afectación (esta tendrá un formato nombre_en_común[1].extensión_común).\n",
    "            # En los resultados de las máscaras cuando se manejan múltiples clases de objetos (hiperparámetro de predicción classes= []) en una imagen, es difícil referenciar las coordenadas que pertenecen a cada clase de objeto detectado, por lo tanto, es necesario separar dichos resultados de coordenadas. \n",
    "            dent_coordinates = [] # Inicializa una lista temporal para las coordenadas de abolladura.\n",
    "            scratch_coordinates = [] # Inicializa una lista temporal para las coordenadas de rayón.\n",
    "            tensor = attribute.boxes.cls # Almacena los valores del tensor, que hacen referencia al cuadro delimitador de cada máscara.\n",
    "            for position, value in enumerate(tensor): # Itera sobre los valores del tensor y las posiciones correspondientes.\n",
    "                if value == 0.: # Si el valor del tensor es 0, corresponde a una detección de abolladura.\n",
    "                    dent_coordinates.append(attribute.masks.xy[position]) # Añade las coordenadas de la máscara a la lista de abolladuras.\n",
    "                elif value == 1.:  # Asegura que solo maneje dos clases de afectación.\n",
    "                    scratch_coordinates.append(attribute.masks.xy[position]) # Añade las coordenadas de la máscara a la lista de rayon.\n",
    "            dent_area, scratch_area = calculate_area(dent_coordinates), calculate_area(scratch_coordinates) # Calcula el área para cada clase de afectación.\n",
    "            sub_image_results.append((attribute.path, dent_area, scratch_area)) # Añade los resultados a la lista principal. \n",
    "    return sub_image_results if sub_image_results else [] # Retorna una lista de tuplas que contienen el nombre de la subimagen, el área de abolladura y el área del rayón, ej: [(ruta_variante, área_total_abolladura, área_total_rayón)].\n",
    "\n",
    "def process_main_detection(affectation_results, car_results): # Función main que controla todo el proceso.\n",
    "    dataframe_columns= ['imagen', 'equivalencia', 'area abolladura', 'area rayon', 'area carro', 'afectacion'] # Se definen las columnas del DataFrame.\n",
    "    data=[] # Se inicializa una lista vacía para almacenar los resultados de cada imagen.\n",
    "    \n",
    "    for car in car_results: # Se recorren principalmente los resultados de carro, ya que es el primer filtro por el que pasa el modelo de segmentación, de esta manera en la salida se podrán ver los resultados para todo el conjunto de datos original.\n",
    "        image_control = f'{os.path.basename(car.path)}' # Extrae el nombre base de la imagen de control.\n",
    " \n",
    "        sub_image_data = search_for_mask_affectation(affectation_results, image_control) # Buscar máscaras en la imagen de control.\n",
    "        if sub_image_data:  \n",
    "            for index, segment in enumerate(sub_image_data): # Recorre cada resultado de subimagen encontrada para la imagen de control.\n",
    "                associated_image, dent_area, scratch_area = segment # Extraer la imagen asociada, el área de abolladura y el área de rayón.\n",
    "                \n",
    "                if dent_area > 0 or scratch_area > 0: # Si existe un area de afectación, se calcula el área del coche y el daño total.\n",
    "                    car_area = search_for_mask_car(car) # Recibirá una lista que contendrá los valores de área total para detecciones de vehículos; por ejemplo, [87916, 5504] indica que encontró dos vehículos para la imagen control.\n",
    "                    car_area_id= car_area[index] # Para vincular el área del vehículo con cada subimagen, se selecciona por posición.\n",
    "                    damage_car=vehicle_damage(car_area_id, dent_area, scratch_area) # Optiene el daño de afectación en el vehiculo. \n",
    "                else: # En caso de no encontrarse áreas de afectación, se agregarán resultados predeterminados.\n",
    "                    car_area_id= 0\n",
    "                    damage_car= 0\n",
    "                   \n",
    "                data.append([image_control, f'{os.path.basename(associated_image)}', dent_area, scratch_area, car_area_id, f'{damage_car} px^2']) # Se agregan los resultados obtenidos con el formato [nombre_imagen_control, nombre_imagen_equivalente, clase_1, clase_2, clase_3, daño_total_imagen] tomando una columna por clase con el fin de una visión más general.\n",
    "        else:\n",
    "            data.append([image_control, 'sin coincidencia', 0, 0, 0, '0px^2']) # Si no se encuentran máscaras se añaden valores por defecto.\n",
    "            \n",
    "    df= pd.DataFrame(data, columns=dataframe_columns)  # Se crea un DataFrame a partir de los datos.\n",
    "    grouped= df.groupby(\"imagen\", group_keys=True)[['equivalencia', 'area abolladura', 'area rayon', 'area carro', 'afectacion']].apply(lambda x: x) # Agrupa el DataFrame por imagen y aplicar la función lambda.\n",
    "    return grouped # Retorna un DataFrame de pandas agrupado con los resultados procesados.\n",
    "\n",
    "def search_for_mask_car(car):\n",
    "    car_area_data= [] # Se inicializa una lista vacía para almacenar las áreas de los coches.\n",
    "    for index, _ in enumerate(car.boxes.cls): # En los resultados del modelo YOLO no se puede conocer la cantidad de vehiculos detectados para una imagen. Por lo tanto, es importante guiarse con el tensor para saber cuántos automóviles han sido detectados y poder extraer cada resultado para un procesamiento único.\n",
    "        car_masks= car.masks[index] # Obtiene la máscara para el resultado del coche actual.\n",
    "        car_area_data.append(calculate_area(car_masks.xy))  # Calcula el área de la máscara y la añade a la lista.\n",
    "    return car_area_data # Retorna una lista de las áreas de cada coche detectado por imagen.\n",
    "\n",
    "def vehicle_damage(car_area, dent_area, scratch_area):\n",
    "    if dent_area > 0 and scratch_area > 0: # Comprueba si ambas áreas de la clase de afectación son mayores que 0.\n",
    "        total_affected_area = abs((dent_area + scratch_area) - car_area) # Calcula el área total afectada restando el área del coche a la suma de las áreas de abolladuras y rayón.\n",
    "    else:\n",
    "        total_affected_area = abs(dent_area - car_area) if dent_area > 0 else abs(scratch_area - car_area) if scratch_area > 0 else 0 # Si sólo una de las áreas de afectación es mayor que 0, usa esa área para restarla al área del vehiculo.\n",
    "    return total_affected_area # Devuelve un float que representa el área total afectada del coche.\n",
    "\n",
    "dataframe = process_main_detection(results_affectation, results_car)\n",
    "style= dataframe.style.set_properties(**{'text-align': 'right'})\n",
    "style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe con las áreas individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>area mascara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagen</th>\n",
       "      <th>equivalencia</th>\n",
       "      <th>afectacion</th>\n",
       "      <th>Clase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20170531_010133.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">20170531_010133[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>2</th>\n",
       "      <td>1110288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5-320w-320w.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">5-320w-320w[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">47942 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>3</th>\n",
       "      <td>14932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>5</th>\n",
       "      <td>62874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Car-Dent.png</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Car-Dent[1].png</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">100542 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>6</th>\n",
       "      <td>34156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>8</th>\n",
       "      <td>134698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Charlotte-Toyota-service-1-1024x683.jpg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Charlotte-Toyota-service-1-1024x683[1].jpg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">571487 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rayon</th>\n",
       "      <th>10</th>\n",
       "      <td>9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>11</th>\n",
       "      <td>584878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Charlotte-Toyota-service-1-1024x683[2].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">22819 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>12</th>\n",
       "      <td>6581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>14</th>\n",
       "      <td>29400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">GSDH75MG6FAM7FSG43RFQLN5R4.jpg</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">GSDH75MG6FAM7FSG43RFQLN5R4[1].jpg</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">438478 px^2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">abolladura</th>\n",
       "      <th>15</th>\n",
       "      <td>38058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>41488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>17</th>\n",
       "      <td>518024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIP (1).jpg</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIP (2).jpeg</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">OIP (4).jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">OIP (4)[1].jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">677092 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>21</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>22</th>\n",
       "      <td>677376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">OIP(3).jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">OIP(3)[1].jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>25</th>\n",
       "      <td>138158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R.jpeg</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">R.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">R[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">286416 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>27</th>\n",
       "      <td>40800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>28</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>29</th>\n",
       "      <td>327278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">R2.jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">R2[1].jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>32</th>\n",
       "      <td>87916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">R2[2].jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>35</th>\n",
       "      <td>5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">R3.jpeg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">R3[1].jpeg</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">111684 px^2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">abolladura</th>\n",
       "      <th>36</th>\n",
       "      <td>31188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>23916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>38</th>\n",
       "      <td>199908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">R5.jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">R5[1].jpeg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">234663 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>39</th>\n",
       "      <td>27675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>41</th>\n",
       "      <td>262338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">R7.png</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">R7[1].png</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">264050 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>42</th>\n",
       "      <td>25550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>44</th>\n",
       "      <td>289600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">R7[2].png</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">223991 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>45</th>\n",
       "      <td>35777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>47</th>\n",
       "      <td>259768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">R7[3].png</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>50</th>\n",
       "      <td>4008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R8.png</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Webp.net-resizeimage-10-1170x600.jpg</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">abolladura-en-un-coche-632c58a6e2ea5.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">abolladura-en-un-coche-632c58a6e2ea5[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">769468 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>54</th>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>55</th>\n",
       "      <td>769696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>58</th>\n",
       "      <td>812568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">big_ray.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">big_ray[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>61</th>\n",
       "      <td>111646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>64</th>\n",
       "      <td>283330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1b235cf346a92a59d23c353c5ab913c.jpg</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paintless-dent-removal-3-1.jpg</th>\n",
       "      <th>sin coincidencia</th>\n",
       "      <th>0 px^2</th>\n",
       "      <th>sin mascara</th>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0[1].jpg</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">359601 px^2</th>\n",
       "      <th>abolladura</th>\n",
       "      <th>67</th>\n",
       "      <td>1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>68</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>69</th>\n",
       "      <td>361604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">trucos-para-quitar-abolladuras-del-coche.imagen-1013x675[1].jpg</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">424932 px^2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">abolladura</th>\n",
       "      <th>70</th>\n",
       "      <td>18844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>54720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rayon</th>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carro</th>\n",
       "      <th>72</th>\n",
       "      <td>498496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 area mascara\n",
       "imagen                                             equivalencia                                       afectacion  Clase                      \n",
       "20170531_010133.jpg                                20170531_010133[1].jpg                             0 px^2      abolladura  0             0\n",
       "                                                                                                                  rayon       1             0\n",
       "                                                                                                                  carro       2       1110288\n",
       "5-320w-320w.jpg                                    5-320w-320w[1].jpg                                 47942 px^2  abolladura  3         14932\n",
       "                                                                                                                  rayon       4             0\n",
       "                                                                                                                  carro       5         62874\n",
       "Car-Dent.png                                       Car-Dent[1].png                                    100542 px^2 abolladura  6         34156\n",
       "                                                                                                                  rayon       7             0\n",
       "                                                                                                                  carro       8        134698\n",
       "Charlotte-Toyota-service-1-1024x683.jpg            Charlotte-Toyota-service-1-1024x683[1].jpg         571487 px^2 abolladura  9             0\n",
       "                                                                                                                  rayon       10         9142\n",
       "                                                                                                                              10          673\n",
       "                                                                                                                              10         3576\n",
       "                                                                                                                  carro       11       584878\n",
       "                                                   Charlotte-Toyota-service-1-1024x683[2].jpg         22819 px^2  abolladura  12         6581\n",
       "                                                                                                                  rayon       13            0\n",
       "                                                                                                                  carro       14        29400\n",
       "GSDH75MG6FAM7FSG43RFQLN5R4.jpg                     GSDH75MG6FAM7FSG43RFQLN5R4[1].jpg                  438478 px^2 abolladura  15        38058\n",
       "                                                                                                                              15        41488\n",
       "                                                                                                                  rayon       16            0\n",
       "                                                                                                                  carro       17       518024\n",
       "OIP (1).jpg                                        sin coincidencia                                   0 px^2      sin mascara 18            0\n",
       "OIP (2).jpeg                                       sin coincidencia                                   0 px^2      sin mascara 19            0\n",
       "OIP (4).jpeg                                       OIP (4)[1].jpeg                                    677092 px^2 abolladura  20            0\n",
       "                                                                                                                  rayon       21          284\n",
       "                                                                                                                  carro       22       677376\n",
       "OIP(3).jpeg                                        OIP(3)[1].jpeg                                     0 px^2      abolladura  23            0\n",
       "                                                                                                                  rayon       24            0\n",
       "                                                                                                                  carro       25       138158\n",
       "R.jpeg                                             sin coincidencia                                   0 px^2      sin mascara 26            0\n",
       "R.jpg                                              R[1].jpg                                           286416 px^2 abolladura  27        40800\n",
       "                                                                                                                  rayon       28           62\n",
       "                                                                                                                  carro       29       327278\n",
       "R2.jpeg                                            R2[1].jpeg                                         0 px^2      abolladura  30            0\n",
       "                                                                                                                  rayon       31            0\n",
       "                                                                                                                  carro       32        87916\n",
       "                                                   R2[2].jpeg                                         0 px^2      abolladura  33            0\n",
       "                                                                                                                  rayon       34            0\n",
       "                                                                                                                  carro       35         5504\n",
       "R3.jpeg                                            R3[1].jpeg                                         111684 px^2 abolladura  36        31188\n",
       "                                                                                                                              36        23916\n",
       "                                                                                                                              36        33120\n",
       "                                                                                                                  rayon       37            0\n",
       "                                                                                                                  carro       38       199908\n",
       "R5.jpeg                                            R5[1].jpeg                                         234663 px^2 abolladura  39        27675\n",
       "                                                                                                                  rayon       40            0\n",
       "                                                                                                                  carro       41       262338\n",
       "R7.png                                             R7[1].png                                          264050 px^2 abolladura  42        25550\n",
       "                                                                                                                  rayon       43            0\n",
       "                                                                                                                  carro       44       289600\n",
       "                                                   R7[2].png                                          223991 px^2 abolladura  45        35777\n",
       "                                                                                                                  rayon       46            0\n",
       "                                                                                                                  carro       47       259768\n",
       "                                                   R7[3].png                                          0 px^2      abolladura  48            0\n",
       "                                                                                                                  rayon       49            0\n",
       "                                                                                                                  carro       50         4008\n",
       "R8.png                                             sin coincidencia                                   0 px^2      sin mascara 51            0\n",
       "Webp.net-resizeimage-10-1170x600.jpg               sin coincidencia                                   0 px^2      sin mascara 52            0\n",
       "abolladura-en-un-coche-632c58a6e2ea5.jpg           abolladura-en-un-coche-632c58a6e2ea5[1].jpg        769468 px^2 abolladura  53            0\n",
       "                                                                                                                  rayon       54          228\n",
       "                                                                                                                  carro       55       769696\n",
       "abolladuraautos-fd03b3bae67d7363172c41cc00198c5... abolladuraautos-fd03b3bae67d7363172c41cc00198c5... 0 px^2      abolladura  56            0\n",
       "                                                                                                                  rayon       57            0\n",
       "                                                                                                                  carro       58       812568\n",
       "big_ray.jpg                                        big_ray[1].jpg                                     0 px^2      abolladura  59            0\n",
       "                                                                                                                  rayon       60            0\n",
       "                                                                                                                  carro       61       111646\n",
       "coche-después-de-una-ruina-la-necesidad-ser-rep... coche-después-de-una-ruina-la-necesidad-ser-rep... 0 px^2      abolladura  62            0\n",
       "                                                                                                                  rayon       63            0\n",
       "                                                                                                                  carro       64       283330\n",
       "e1b235cf346a92a59d23c353c5ab913c.jpg               sin coincidencia                                   0 px^2      sin mascara 65            0\n",
       "paintless-dent-removal-3-1.jpg                     sin coincidencia                                   0 px^2      sin mascara 66            0\n",
       "rayonesauto-e68618ca9c3d6859cebc796c300aea97-12... rayonesauto-e68618ca9c3d6859cebc796c300aea97-12... 359601 px^2 abolladura  67         1762\n",
       "                                                                                                                  rayon       68          241\n",
       "                                                                                                                  carro       69       361604\n",
       "trucos-para-quitar-abolladuras-del-coche.imagen... trucos-para-quitar-abolladuras-del-coche.imagen... 424932 px^2 abolladura  70        18844\n",
       "                                                                                                                              70        54720\n",
       "                                                                                                                  rayon       71            0\n",
       "                                                                                                                  carro       72       498496"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_area(vertices): \n",
    "    individual_mask_area= [] # Se inicializa una lista vacia para guardar el área individual de cada objeto segmentado.\n",
    "    if vertices: # Verifica si existe resultados de mascara.xy que proporciona los datos en formato pixel.\n",
    "        for point in vertices: # Recorre los puntos de contorno que se encuentran separados por medio de una lista para cada región segmentada.\n",
    "            x_coordinate = point[:, 0] # Asigna todas las filas correspondientes a la primera columna como coordenada X del formato de masks.xy que entrega por medio de arreglos los vértices (x, y) en pixel. \n",
    "            y_coordinate = point[:, 1] # Asigna todas las filas correspondientes a la segunda columna como coordenada Y.\n",
    "            mask_area = np.round(0.5 * abs(np.dot(x_coordinate, np.roll(y_coordinate, 1)) - np.dot(y_coordinate, np.roll(x_coordinate, 1)))).astype(int) # Almacena el resultado del área por máscara, basándose en la fórmula Shoelace o lazada de Gauss. Utiliza la suma y la resta de los productos cruzados de las coordenadas de los vértices del polígono; el término np.roll(y, 1) y np.roll(x, 1) crean versiones desplazadas circularmente, lo cual es esencial para que np.dot() calcule el producto punto de los vértices del polígono. La diferencia entre los productos cruzados se multiplicará por 1/2 tomando el valor absoluto.\n",
    "            individual_mask_area.append(mask_area) # Añade a la lista el resultado del área.\n",
    "    else:\n",
    "        return 0 # Cuando no exista resultados de mascara se retorna como valor 0, que indica no haber área.\n",
    "    return individual_mask_area \n",
    "\n",
    "def find_coincidence(filename):\n",
    "    # El nombre del archivo que contiene un número de variante entre corchetes.\n",
    "    return filename.split('[')[0] + os.path.splitext(filename)[1] # Extrae el nombre original de la imagen eliminando el número de variante entre corchetes y conservando la extensión del archivo.\n",
    "\n",
    "def search_for_mask_affectation(segmentation_results, image_instance): # Encuentra subimágenes comunes en los resultados de segmentación y obtiene el área de cada clase de afectación (abolladura y rayón) para cada subimagen.\n",
    "    sub_image_results = []\n",
    "    for attribute in segmentation_results: # Se itera sobre los resultados de la segmentación.\n",
    "        if find_coincidence(os.path.basename(attribute.path)) == image_instance: # Para relacionar ambos formatos de imagen sin sobrescribir las posibles subimágenes con el mismo nombre que se puedan encontrar, se envía a la función \"find_coincidente\" la base del nombre por parte de los resultados de afectación (esta tendrá un formato nombre_en_común[1].extensión_común).\n",
    "            # En los resultados de las máscaras cuando se manejan múltiples clases de objetos (hiperparámetro de predicción classes= []) en una imagen, es difícil referenciar las coordenadas que pertenecen a cada clase de objeto detectado, por lo tanto, es necesario separar dichos resultados de coordenadas. \n",
    "            dent_coordinates = [] # Inicializa una lista temporal para las coordenadas de abolladura.\n",
    "            scratch_coordinates = [] # Inicializa una lista temporal para las coordenadas de rayón.\n",
    "            tensor = attribute.boxes.cls # Almacena los valores del tensor, que hacen referencia al cuadro delimitador de cada máscara.\n",
    "            for position, value in enumerate(tensor): # Itera sobre los valores del tensor y las posiciones correspondientes.\n",
    "                if value == 0.: # Si el valor del tensor es 0, corresponde a una detección de abolladura.\n",
    "                    dent_coordinates.append(attribute.masks.xy[position]) # Añade las coordenadas de la máscara a la lista de abolladuras.\n",
    "                elif value == 1.:  # Asegura que solo maneje dos clases de afectación.\n",
    "                    scratch_coordinates.append(attribute.masks.xy[position]) # Añade las coordenadas de la máscara a la lista de rayon.\n",
    "            dent_area, scratch_area = calculate_area(dent_coordinates), calculate_area(scratch_coordinates) # Calcula el área para cada clase de afectación.\n",
    "            sub_image_results.append((attribute.path, dent_area, scratch_area)) # Añade los resultados a la lista principal. \n",
    "    return sub_image_results if sub_image_results else [] # Retorna una lista de tuplas que contienen el nombre de la subimagen, las áreas de abolladura y las áreas de rayón, ej: [(ruta_variante, áreas_abolladura, áreas_rayón)].\n",
    "    \n",
    "def process_main_detection(affectation_class, car_results): # Función main que controla todo el proceso.\n",
    "    columnas= ['imagen', 'equivalencia', 'clase mascara', 'area mascara', 'afectacion'] # Se definen las columnas del DataFrame.\n",
    "    data=[] # Se inicializa una lista vacía para almacenar los resultados de cada imagen.\n",
    "    \n",
    "    for car in car_results: # Se recorren principalmente los resultados de carro, ya que es el primer filtro por el que pasa el modelo de segmentación, de esta manera en la salida se podrán ver los resultados para todo el conjunto de datos original.\n",
    "        control_image = os.path.basename(car.path) # Extrae el nombre base de la imagen de control.\n",
    "        \n",
    "        sub_image_data = search_for_mask_affectation(affectation_class, control_image) # Buscar máscaras en la imagen de control.\n",
    "        \n",
    "        if sub_image_data: \n",
    "            for index, segment in enumerate(sub_image_data): # Recorre cada resultado de subimagen encontrada para la imagen de control.\n",
    "                associated_image, dent_area, scratch_area = segment # Extraer la imagen asociada, el área de abolladura y el área de rayón.\n",
    "                \n",
    "                if dent_area is not None or scratch_area is not None: # Si existe un area de afectación, se calcula el área del coche y el daño total.\n",
    "                    car_area = search_for_mask_car(car) # Recibirá una lista que contendrá los valores de área total para detecciones de vehículos; por ejemplo, [87916, 5504] indica que encontró dos vehículos para la imagen control. \n",
    "                    damage_image= vehicle_damage(car_area[index], dent_area, scratch_area) # Optiene el daño de afectación, vinculando el área del vehículo con cada subimagen.\n",
    "                else: # En caso de no encontrarse áreas de afectación, se agregarán resultados predeterminados.\n",
    "                    car_area = 0\n",
    "                    damage_image= 0\n",
    "\n",
    "                # Para añadir los resultados obtenidos se utiliza el formato: [nombre_imagen_control, nombre_imagen_equivalente, identificador_clase, areas_individuales, daño_total_imagen]con el fin de buscar en cada imagen los resultados de todas las clases manejadas y evitar errores de la función explode de pandas en las listas.\n",
    "                data.append([control_image, f'{os.path.basename(associated_image)}', 'abolladura', dent_area, f'{damage_image} px^2'])\n",
    "                data.append([control_image, f'{os.path.basename(associated_image)}', 'rayon', scratch_area, f'{damage_image} px^2']) \n",
    "                data.append([control_image, f'{os.path.basename(associated_image)}', 'carro', car_area[index], f'{damage_image} px^2'])\n",
    "        else:  \n",
    "            data.append([f'{os.path.basename(control_image)}', 'sin coincidencia', 'sin mascara', 0,  f'0 px^2']) # Si no se encuentran máscaras se añaden valores por defecto.\n",
    "            \n",
    "    orden_clases=['abolladura', 'rayon', 'carro', 'sin mascara'] # Esta lista se creó simplemente con el fin de mantener un orden en la visualización de las clases para el dataframe.\n",
    "    df= pd.DataFrame(data, columns=columnas) # Se crea un DataFrame a partir de los datos.\n",
    "    df['Clase'] = pd.Categorical(df['clase mascara'], categories=orden_clases, ordered=True) \n",
    "    grouped_columns=df.groupby(['imagen', 'equivalencia', 'afectacion', 'Clase'], group_keys=True, as_index=True, observed=False)[[ 'area mascara']].apply(lambda x : x) # Agrupa el DataFrame por imagen y aplicar la función lambda.\n",
    "    grouped_columns_expanded = grouped_columns.explode('area mascara') # Expande el formato de lista inicial de la columna 'area mascara' en diferentes filas manteniendo su eje en la agrupación.\n",
    "    return grouped_columns_expanded\n",
    "\n",
    "def search_for_mask_car(car):\n",
    "    car_area_data= [] # Se inicializa una lista vacía para almacenar las áreas de los coches.\n",
    "    for index, _ in enumerate(car.boxes.cls): # En los resultados del modelo YOLO no se puede conocer la cantidad de vehiculos detectados para una imagen. Por lo tanto, es importante guiarse con el tensor para saber cuántos automóviles han sido detectados y poder extraer cada resultado para un procesamiento único.\n",
    "        mascara= car.masks[index] # Obtiene la máscara para el resultado del coche actual.\n",
    "        car_area_data.append(sum(calculate_area(mascara.xy))) # Calcula el área de la máscara y la añade a la lista.\n",
    "    return car_area_data # Retorna una lista de las áreas de cada coche detectado por imagen.\n",
    "\n",
    "def sum_if_list(area):\n",
    "    return sum(area) if isinstance(area, list) else 0 # Si el parametro es una lista, retornara la suma del contenido de lo contrario devolvera un 0.\n",
    "\n",
    "def vehicle_damage(car_area, dent_area, scratch_area):\n",
    "    # Como el parametro 'dent_area y scratch area' son listas con formato [área total por objeto según clase], se requiere obtener el resultado total de cada clase. \n",
    "    sum_dent = sum_if_list(dent_area) # Recibe la suma total de áreas de abolladuras en una imagen.\n",
    "    sum_scratch = sum_if_list(scratch_area) # Recibe la suma total de áreas de rayon en una imagen.\n",
    "    if sum_dent > 0 and sum_scratch > 0: # Comprueba si ambas áreas de la clase de afectación son mayores que 0.\n",
    "        total_affected_area = abs((sum_dent + sum_scratch) - car_area) # Calcula el área total afectada restando el área del coche a la suma de las áreas de abolladuras y rayón.\n",
    "    else:\n",
    "        total_affected_area= abs(car_area - sum_dent) if sum_dent > 0 else abs(car_area - sum_scratch) if sum_scratch > 0 else 0 # Si sólo una de las áreas es mayor que 0, usa esa área para restarla al área del vehiculo.\n",
    "    return total_affected_area # Devuelve un float que representa el área total afectada del coche.\n",
    "\n",
    "dataframe = process_main_detection(results_affectation, results_car)\n",
    "# En ocasiones, los valores predeterminados no permiten visualizar todos los fotogramas de datos en el marco de datos. Por lo tanto, se establecen el máximo de columnas y filas como None para mostrar absolutamente todo.\n",
    "pd.set_option('display.max_rows', None) # Establece el numero maximo de filas que se mostrarán del dataframe, por defecto se establece en 60.\n",
    "pd.set_option('display.max_columns', None) # Establece el número maximo de columnas que se mostraran, por defecto son 20.\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x640 4 abolladuras, 166.0ms\n",
      "Speed: 4.0ms preprocess, 166.0ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO, solutions\n",
    "\n",
    "model = YOLO(\"C:/Users/matrix/pruebayolo/proyecto_yolo/src/srcv5/model_segmentation/segmentation/training_affectation/weights/best.pt\")\n",
    "names = model.model.names\n",
    "\n",
    "#cap = cv2.VideoCapture(\"path/to/video/file.mp4\")\n",
    "im0 = cv2.imread(\"C:/Users/matrix/pruebayolo/proyecto_yolo/src/assets_affectation/R7.png\")\n",
    "assert im0 is not None, \"Error reading video file\"\n",
    "#w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "#video_writer = cv2.VideoWriter(\"distance_calculation.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init distance-calculation obj\n",
    "dist_obj = solutions.DistanceCalculation(names=names, view_img=True)\n",
    "\n",
    "\"\"\"while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    tracks = model.track(im0, persist=True, show=False)\n",
    "    im0 = dist_obj.start_process(im0, tracks)\n",
    "    video_writer.write(im0)\"\"\" \n",
    "\n",
    "tracks = model.track(im0, persist=True, show=False)\n",
    "im0 = dist_obj.start_process(im0, tracks)\n",
    "\n",
    "#cap.release()\n",
    "#video_writer.release()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('Imagen de salida', im0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 15 rayons, 234.0ms\n",
      "Speed: 4.0ms preprocess, 234.0ms inference, 35.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "\n",
    "# Cargar el modelo\n",
    "model = YOLO(\"C:/Users/matrix/pruebayolo/proyecto_yolo/src/srcv5/model_segmentation/segmentation/training_affectation/weights/best.pt\")\n",
    "names = model.model.names\n",
    "\n",
    "# Leer la imagen\n",
    "im0 = cv2.imread(\"C:/Users/matrix/pruebayolo/proyecto_yolo/src/assets_affectation/Charlotte-Toyota-service-1-1024x683.jpg\")\n",
    "assert im0 is not None, \"Error al leer la imagen\"\n",
    "\n",
    "# Inicializar el objeto para el cálculo de distancias\n",
    "dist_obj = solutions.DistanceCalculation(names=names, view_img=True)\n",
    "\n",
    "# Rastrear los objetos en la imagen\n",
    "tracks = model.track(im0, persist=True, show=False)\n",
    "\n",
    "# Calcular las distancias\n",
    "im0 = dist_obj.start_process(im0, tracks)\n",
    "\n",
    "# Guardar la imagen de salida\n",
    "cv2.imshow('Imagen de salida', im0)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
