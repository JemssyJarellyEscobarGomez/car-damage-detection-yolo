{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación de herramientas de etiquetado</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install labelme # Software de etiquetado que almacena información en archivos JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme # Permite abrir la herramienta labelme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install labelme2yolo # Herramienta de conversión para el formato JSON de labelme a formato texto requerido por los modelos de detección de objetos YOLO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Conversión a formato YOLO</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta de entrenamiento\n",
    "dir_json_train='' # Incluya la dirección de la carpeta que contiene las etiquetas en archivos JSON separadas para el entrenamiento.\n",
    "!labelme2yolo --json_dir {dir_json_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta de validación\n",
    "dir_json_val='' # Incluya la dirección de la carpeta que contiene las etiquetas en archivos JSON separadas para la validación.\n",
    "!labelme2yolo --json_dir {dir_json_val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Carga de librerías</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import gdown\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación de recursos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics # Instalación de la biblioteca Ultralytics\n",
    "\n",
    "ultralytics.checks() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarjeta Grafica: Caption                  \n",
      "\n",
      "AMD Radeon(TM) Graphics. Advertencia: Debe utilizar la CPU para instalación de PyTorch!. \n"
     ]
    }
   ],
   "source": [
    "# Función para determinar si tiene GPU Cuda para instalación de PYTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'CUDA: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    try:\n",
    "        command = 'wmic path win32_videocontroller get caption'\n",
    "        device = subprocess.check_output(command, shell=True, universal_newlines=True)\n",
    "        print(f'Tarjeta Grafica: {device.strip()}. \\nAdvertencia: Debe utilizar la CPU para instalación de PyTorch!. ')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error al ejecutar el comando: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Dirección para instalar mediante el comando la versión de PyTorch en función de los requerimientos computacionales: </span>[Versión PyTorch](https://pytorch.org/get-started/locally/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio # Reemplace en esta linea sin eliminar la expresión ! el comando que obtuvo en la pagina de PyTorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Instalación versión de modelo Yolo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versiones de los modelos para segmentación de objetos\n",
    "\n",
    "ruta_model_yolo=input()\n",
    "if ruta_model_yolo=='v8n':\n",
    "    save='C:/Users/matrix/pruebayolo/yolov8n.pt' # Indique la ruta donde se guardara la descarga.\n",
    "    url = 'https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt'#yolov8n\n",
    "    gdown.download(url,save,quiet=False)\n",
    "elif ruta_model_yolo=='v8s':\n",
    "    save='C:/Users/jemss/Workspace/yolov8s.pt'\n",
    "    url= 'https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt'#yolov8s\n",
    "    gdown.download(url,save,quiet=False)\n",
    "elif ruta_model_yolo=='v8m':\n",
    "    save='C:/Users/jemss/Workspace/yolov8m .pt'\n",
    "    url='https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m-seg.pt' #yolov8m\n",
    "    gdown.download(url,save,quiet=False)\n",
    "elif ruta_model_yolo=='v8l':\n",
    "    save='C:/Users/jemss/Workspace/yolov8l.pt'\n",
    "    url='https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt' #yolov8l\n",
    "    gdown.download(url,save,quiet=False)\n",
    "else:\n",
    "    save='C:/Users/jemss/Workspace/yolov8x.pt'\n",
    "    url='https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-seg.pt' #yolov8x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size:40px \">Carga de rutas</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">ENTRENAMIENTO</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version_YOLO='yolov8n-seg.pt' \n",
    "\n",
    "model_segmentation=YOLO(model_version_YOLO)\n",
    "\n",
    "PROJECT='segmentacion' # Permite asignar un nombre al directorio de inicio que contendrá los experimentos de segmentación de objetos, y debe estar entre comillas; se recomienda no utilsizar espacios en el nombre.\n",
    "NAME='pruebaEntrenamiento' # El nombre del experimento entrenamiento para segmentación de instancias debe ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "TASK='segment' # Define la tarea principal que desea realizar con el modelo YOLO v8; en este caso, la segmentación implica el uso de máscaras para identificar objetos individuales en una imagen y segmentarlos del resto de la imagen.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada. Puede especificarlo como un número entero, como imgsz a 640 para obtener un cuadrado perfecto, o como una tupla, como imgsz=(640,480) para establecer dimensiones específicas de ancho y alto. Se recomienda ajustar este valor según el tamaño del objeto que desea segmentar. Para la segmentación de objetos pequeños, se recomienda aumentar el valor a más de 640 píxeles para obtener una resolución más alta.\n",
    "DATA=\"C:/Users/matrix/pruebayolo/datacopia_car/dataset.yaml\" #  Le permite indicar la ruta al archivo que contiene los metadatos que utilizara el modelo segmentación de objetos y su configuración en formato YAML. Si especifica el valor data=None, el conjunto de datos coco128-seg.yaml se utiliza de forma predeterminada; de lo contrario, escriba la ruta al archivo YAML entre comillas utilizando barras diagonales (/) en lugar de barras invertidas (\\).\n",
    "EPOCHS=30 # Establezca el número de épocas del modelo YOLO v8 en la tarea de segmentación. Este valor representa el número total de iteraciones en todo el conjunto de datos de entrenamiento. Se recomienda experimentar con este parámetro dependiendo de la cantidad de imágenes disponibles. Si tiene un conjunto de datos grande, considere aumentar este valor por encima de 30 para obtener mejores resultados. Por otro lado, establecer epochs=None hará que el modelo continúe entrenándose hasta que la pérdida de validación deje de mejorar.\n",
    "BATCH=-1 # Define la cantidad de imágenes procesadas simultáneamente en una iteración del modelo YOLO v8 en la segmentación. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta automáticamente el tamaño del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del parámetro como un número entero.\n",
    "OPTIMIZER='auto' # Define el algoritmo de optimización para el modelo de segmentación YOLO. Su elección ajusta los pesos del modelo durante el entrenamiento y es crucial para la velocidad y rendimiento. Puede tomar valores como 'SGD', 'Adam', 'Adamax', 'AdamW', 'NAdam', 'RAdam', 'RMSProp' y 'auto', este último selecciona automáticamente el optimizador más adecuado a la tarea segmentación de objetos.\n",
    "WORKERS=1 # Especifica la cantidad de subprocesos o núcleos utilizados para cargar datos en el modelo segmentación YOLO. Se recomienda ajustar la cantidad de subprocesos a la cantidad de núcleos de CPU disponibles en el sistema.\n",
    "DEVICE= 'cpu' # Especifica el dispositivo de ejecución para la versión del modelo yolov8 en la operación de segmentación. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generación de gráficos que permite visualizar y monitorear la pérdida y la precisión durante el entrenamiento de segmentación de objetos. Establecer plots=True activara la función; si desea desactivarla, establezca el valor del hiperparámetro en False.\n",
    "SAVE=False # Cuando se establece en True, el modelo guarda puntos de control periódicamente durante el entrenamiento de segmentación. Se recomienda tener cuidado al establecer este valor en Verdadero, ya que está relacionado con el hiperparámetro SAVE_PERIOD; si establece el valor del hiperparametro a False, la función Save_Period se desactivará.\n",
    "SAVE_PERIOD=-1 # Se utiliza para especificar con qué frecuencia se guardan los puntos de control durante el entrenamiento de segmentación. Si se establece en un valor mayor que 0, el modelo guardará puntos de control cada número especificado de épocas. Sin embargo, si save_period se establece en -1, significa que la función esta deshabilitada.\n",
    "PATIENCE=30 # Representa el número esperado de épocas durante el entrenamiento de segmentación. Si no se observa mejora en el conjunto de validación dentro de un período específico, se detiene el proceso. Esta técnica de parada temprana se utiliza para evitar el sobreajuste del modelo. Se recomienda ajustar este hiperparámetro en función de la duración esperada del entrenamiento.\n",
    "VERBOSE=False # Se utiliza para controlar el número de impresiones durante la ejecución del entrenamiento de segmentación. Para suprimir la salida de información básica únicamente, debe establecer el valor del hiperparámetro en False, pero si desea una salida de progreso más detallada, establezca el valor en True.\n",
    "RECT= False # Habilita la formación rectangular en cada lote, redimensionando las imágenes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de entrenamiento en la segmentación de instancias. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente lote.\n",
    "COS_LR=False # Reemplaza el decaimiento escalonado predeterminado de YOLOv8, que reduce la tasa de aprendizaje en ciertas épocas, con el decaimiento escalonado cos_lr. Este ajusta la tasa de aprendizaje según las épocas restantes y la tasa de aprendizaje inicial, proporcionando una disminución más suave. Establezca este hiperparámetro en True para una reducción gradual de la tasa de aprendizaje, de lo contrario establezca en False.\n",
    "FRACTION= 1.0 # Controla la fracción del conjunto de datos que se utilizara para el entrenamiento de segmentación. Debes establecer este parámetro entre 0.0 y 1.0. Por defecto, cuando es 1.0, se emplea el 100% de las imágenes disponibles en el conjunto de datos.\n",
    "EXIST_OK=False # Controla la sobreescritura de un experimento de segmentación existente. Cuando se establece en False, el sistema no sobrescribirá, en su lugar devolverá una ruta incrementada. Esto es útil para prevenir la sobreescritura accidental de experimentos anteriores. Para activar la función, asigna el valor True.\n",
    "OVERLAP_MASK=True # Determina si las máscaras que representan áreas de interés en la imagen deben superponerse. Establecer el valor del hiperparametro a True permite que estas máscaras compartan áreas, lo que significa que los límites de los objetos en la imagen puede coincidir parcialmente. Esta opción ahorra memoria, acelera el entrenamiento, y es especialmente útil para grandes conjuntos de datos o modelos complejos.\n",
    "MASK_RATIO=1 # Configure la reducción de muestreo para la máscara de segmentación. Se sugiere fijar el valor en el rango de 1 para entrenamiento en resolución nativa, ideal para aplicaciones que demandan alta precisión, hasta 4 para una reducción en un factor de 4, acelerando el entrenamiento con una precisión aceptable y ahorrando memoria. Este hiperparámetro solo acepta valores enteros.\n",
    "\n",
    "model_segmentation.train(project=PROJECT,name=NAME, task=TASK, data=DATA, imgsz=IMGSZ, epochs=EPOCHS, batch=BATCH, workers=WORKERS, device=DEVICE, plots=PLOTS, verbose=VERBOSE, rect=RECT, cos_lr=COS_LR, optimizer=OPTIMIZER, patience=PATIENCE, exist_ok=EXIST_OK, overlap_mask=OVERLAP_MASK, mask_ratio=MASK_RATIO, fraction=FRACTION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">Configuración para la exportación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px;\">A continuación se muestra una tabla de referencia para exportar un modelo YOLOv8 entrenado en la tarea segmentación de instancias. Tenga en cuenta que configurar el parámetro de `format` es fundamental para el proceso de exportación. Antes de continuar, asegúrese de verificar y ajustar estos valores a sus requisitos específicos: </span>\n",
    "\n",
    "| Formatos                                                             | Asignación | Extensión                     | Hyperparámetros                                            | Descripción                                        |\n",
    "|--------------------------------------------------------------------|-------------------|---------------------------|-----------------------------------------------------|----------------------------------------------------|\n",
    "| [PyTorch](https://pytorch.org/)                                    | -                 | `yolov8n.pt`              | -                                                   | Modelo en formato PyTorch                           |\n",
    "| [TorchScript](https://pytorch.org/docs/stable/jit.html)            | \"torchscript\"     | `yolov8n.torchscript`     | `imgsz`, `optimize`                                 | Simplifica la implementación de modelos PyTorch en entornos de producción y aplicaciones eficientes, mejorando la portabilidad y el rendimiento al permitir ejecutar una representación intermedia en entornos sin Python.                       |\n",
    "| [ONNX](https://onnx.ai/)                                           | \"onnx\"            | `yolov8n.onnx`            | `imgsz`, `half`, `dynamic`, `simplify`, `opset`     | Desarrollado para promover la interoperabilidad, la optimización del hardware y la colaboración entre comunidades, al tiempo que responde a la necesidad de portabilidad de los modelos entre distintos marcos y herramientas de aprendizaje automático.                              |\n",
    "| [OpenVINO](https://docs.openvino.ai/latest/index.html)             | \"openvino\"        | `yolov8n_openvino_model/` | `imgsz`, `half`, `int8`                             | Elaborado para promover la interoperabilidad, la optimización del hardware y el despliegue eficiente de modelos a través de diferentes marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware Intel.                     |\n",
    "| [TensorRT](https://developer.nvidia.com/tensorrt)                  | \"engine\"          | `yolov8n.engine`          | `imgsz`, `half`, `dynamic`, `simplify`, `workspace` | Permite promover la interoperabilidad, la optimización del hardware y la implantación eficiente de modelos en distintos marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware de NVIDIA.                     |\n",
    "| [CoreML](https://github.com/apple/coremltools)                     | \"coreml\"          | `yolov8n.mlpackage`       | `imgsz`, `half`, `int8`, `nms`                      | Posibilita promover la interoperabilidad, la optimización del hardware y el despliegue eficiente de modelos a través de diferentes marcos y herramientas de aprendizaje automático, con especial atención a las plataformas de hardware de Apple.                            |\n",
    "| [TF SavedModel](https://www.tensorflow.org/guide/saved_model)      | \"saved_model\"     | `yolov8n_saved_model/`    | `imgsz`, `keras`, `int8`                            | Empleado para guardar, compartir y desplegar modelos entrenados con TensorFlow. Versátil y facilita el despliegue en diversas plataformas como servidores, dispositivos móviles, embebidos y navegadores.                     |\n",
    "| [TF Lite](https://www.tensorflow.org/lite)                         | \"tflite\"          | `yolov8n.tflite`          | `imgsz`, `half`, `int8`                             | Diseñado para el aprendizaje automático en dispositivos, TF Lite aborda restricciones clave como latencia, privacidad, conectividad, tamaño y consumo de energía. Es esencial para desplegar modelos en dispositivos móviles e integrados, ofreciendo una solución ligera y eficiente.                           |\n",
    "| [TF Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | \"edgetpu\"         | `yolov8n_edgetpu.tflite`  | `imgsz`                                             | Utilizado para desplegar modelos de aprendizaje automático en el Edge TPU de TensorFlow. El Edge TPU es un pequeño ASIC (Circuito Integrado Específico de Aplicación) diseñado por Google para ofrecer inferencias de aprendizaje automático de alto rendimiento en dispositivos de bajo consumo.                       |\n",
    "| [TF.js](https://www.tensorflow.org/js)                             | \"tfjs\"            | `yolov8n_web_model/`      | `imgsz`                                             | Facilita el despliegue de modelos de aprendizaje automático en navegadores web y Node.js, destacando la portabilidad y la facilidad de uso.                    |\n",
    "| [PaddlePaddle](https://github.com/PaddlePaddle)                    | \"paddle\"          | `yolov8n_paddle_model/`   | `imgsz`                                             | Utilizado para desplegar modelos en PaddlePaddle, una plataforma de aprendizaje profundo de código abierto, paralela y distribuida que tiene su origen en la práctica industrial.                      |\n",
    "| [ncnn](https://github.com/Tencent/ncnn)                            | \"ncnn\"            | `yolov8n_ncnn_model/`     | `imgsz`, `half`                                     | Formato optimizado para plataformas móviles, ofreciendo alto rendimiento. Puede incluir una estructura de archivo de modelo con información sobre capas, blobs de entrada y salida, y otros parámetros.                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">EXPORTACIÓN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_seg=\"C:/Users/matrix/pruebayolo/segmentacion/pruebaEntrenamiento/weights/best.pt\"\n",
    "\n",
    "selected_model_seg=YOLO(trained_model_seg)\n",
    "\n",
    "FORMAT='onnx' # Seleccione el formato de exportación del modelo segmentación, empleando la tabla previamente proporcionada; en la columna \"Asignación\" se indican las opciones para ajustar este valor.\n",
    "INT8=True # Establezca este parámetro en True al utilizar la CPU y en False en caso contrario. La cuantificación a INT8 mejora la eficiencia del modelo segmentación en cuanto a memoria y velocidad de inferencia, especialmente en hardware que admite esta precisión.\n",
    "HALF=False # Configúrelo en True cuando use la GPU; en caso contrario, False. La cuantificación a FP16 mejora la eficiencia de la memoria del modelo segmentación y la velocidad de inferencia, especialmente en hardware que admite precisión de punto flotante de 16 bits.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada para la exportación del modelo de segmentación. Puede especificarlo como un número entero, por ejemplo, 640 para un cuadrado perfecto, o como una tupla, por ejemplo, (640, 480) para dimensiones específicas de ancho y alto. Las imágenes que ingreses al modelo después de la exportación deben tener las mismas dimensiones específicas que has configurado para adaptarse a los requisitos del escenario de despliegue.\n",
    "OPTIMIZE=False # Controla la optimización en modelos de segmentación de instancias a TorchScript para su implementación móvil. Es importante destacar que esta función puede resultar en un aumento significativo en el tamaño del modelo exportado, lo cual puede no ser ideal para aplicaciones móviles. Se configura con True para activar y False para desactivar.\n",
    "DYNAMIC=False # Controla la habilitación de ejes dinámicos en modelos de segmentación, lo cual es particularmente útil para gestionar tamaños de lote variables. Esta característica funciona bien en escenarios donde el tamaño del lote puede cambiar durante la inferencia, como aplicaciones en tiempo real o de transmisión por secuencias. Los valores aceptados son Verdadero para habilitar la función y Falso para deshabilitarla.\n",
    "SIMPLIFY=False # En la exportación de modelos de segmentación a ONNX|TensorRT, este hiperparámetro personaliza la complejidad del modelo, optimizando, eliminando capas redundantes y reduciendo la precisión de los parámetros. Se activa con True y se desactiva con False.\n",
    "OPSET=None # Especifica la versión del conjunto de operadores en ONNX al exportar el modelo segmentación desde marcos como PyTorch o TensorFlow. Si se deja en \"None\", ONNX utilizará automáticamente la versión más reciente disponible; para una versión específica, asigne el número entre comillas, por ejemplo, \"11\".\n",
    "WORKSPACE=4 # En la exportación de modelos de segmentación a TensorRT, establece el tamaño del espacio de trabajo en GB asignado para optimizar y preparar el modelo de red neuronal. Este espacio se utiliza durante el proceso de construcción del motor para lograr una ejecución eficiente en hardware GPU mediante la biblioteca TensorRT.\n",
    "NMS=False # En la exportación de modelos de segmentación a CoreML, controla la inclusión de la Supresión No Máxima (NMS) en el modelo para eliminar cuadros delimitadores redundantes en la segmentación de instancias y mejorar la precisión de las predicciones. Establecer 'NMS' en 'False' ignora NMS en los modelos CoreML exportados.  Este ajuste, configurable durante la exportación del modelo YOLO, lo que permite a los usuarios optimizar la implementación del modelo en una variedad de plataformas y dispositivos.\n",
    "KERAS= False # En la exportación de modelos de segmentación a TF SavedModel y TF Lite, permite optimizar el despliegue en diversas plataformas y dispositivos. Incluye también el formato del archivo, el dispositivo de ejecución y la posibilidad de manejar múltiples etiquetas por caja. Establezca el valor del hiperparámetro en True si está familiarizado con Keras; de lo contrario, en False para excluir su uso en la exportación.\n",
    "\n",
    "selected_model_seg.export(format=FORMAT, imgsz=IMGSZ, dynamic=DYNAMIC, simplify=SIMPLIFY, opset=OPSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px;\">VALIDACIÓN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_seg='C:/Users/matrix/pruebayolo/segmentacion/segmentacion/pruebaEntrenamiento/weights/best.pt'\n",
    "\n",
    "selected_model_seg=YOLO(trained_model_seg)\n",
    "\n",
    "NAME='pruebaValidacionSeg' # El nombre del experimento de validación para segmentación de instancias deben ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "DATA= 'C:/Users/matrix/pruebayolo/data/dataset.yaml' # Permite indicar la ruta al archivo que contiene los metadatos necesarios para el proceso de validación, la ruta debe ser proporcionada entre comillas.\n",
    "SAVE_JSON=True # Si se configura como True, habilita la funcionalidad de guardar los resultados obtenidos de manera detallada del proceso de validación en un formato estructurado JSON.\n",
    "IMGSZ=640 # Establece las dimensiones en píxeles de la imagen de entrada para la validación del modelo de segmentación. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda usar el mismo valor que utilizo durante el entrenamiento del modelo.\n",
    "BATCH=16 # Define la cantidad de imágenes procesadas simultáneamente en una iteración para la validación de segmentos. El valor predeterminado es 16; se recomienda establecerlo en -1 para aprovechar AutoBatch, que ajusta automáticamente el tamaño del lote para optimizar el rendimiento, evitar problemas de memoria y maximizar la eficiencia del entrenamiento. Si desea personalizarlo, exprese el valor del parámetro como un número entero.\n",
    "SAVE_HYBRID=True # Activa la función con True para guardar una versión híbrida de la etiqueta, incluyendo la original y predicciones adicionales. Útil para el análisis detallado del rendimiento del modelo segmentación durante la validación; establezca en False para mostrar solo las predicciones.\n",
    "CONF=0.5 # Establece el umbral de confianza para la validación de clases en la tarea de segmentación. Se recomienda un valor entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión. \n",
    "MAX_DET=10 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara segmentar en una imagen. Se recomienda establecer un valor alto para evitar perder detecciones relevantes.\n",
    "DEVICE='CPU' # Especifica el dispositivo de ejecución para la prueba de validación en la operación de segmentación. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "PLOTS=True # Utilice valores booleanos (Verdadero o Falso) para controlar la generación de gráficos que permite visualizar y monitorear la pérdida y la precisión durante la validación en la segmentación de instancias. Establecer plots=True activara la función; si desea desactivarla, establezca el valor del hiperparámetro en False.\n",
    "RECT=False # Habilita la formación rectangular en cada lote, redimensionando las imágenes para que todas tengan la misma forma rectangular. Puedes establecerlo en True si tu conjunto de datos es extenso y deseas acelerar el tiempo de validación en la segmentación de instancias. De lo contrario, si se establece en False el modelo se entrena en el orden normal procesando todos los datos de un lote antes de pasar al siguiente.\n",
    "IOU=0.6 # El umbral predeterminado para la supresión no máxima (NMS) en la validación YOLO es 0,6. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren el mismo segmento. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "\n",
    "selected_model_seg.val(name=NAME, data=DATA, save_json=SAVE_JSON, imgsz=IMGSZ, batch=BATCH, save_hybrid=SAVE_HYBRID, conf=CONF, max_det=MAX_DET, device=DEVICE, plots=PLOTS, rect=RECT, iou=IOU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">Configuración de fuentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Para utilizar múltiples fuentes de datos al realizar predicciones con el modelo, se requiere que se ajuste el parámetro'source' a sus necesidades, tal como se indica en la siguiente tabla:</span>\n",
    "\n",
    "\n",
    "| Fuentes          | Asignación                             | Tipo             | Notas                                                           |\n",
    "| --------------- | ------------------------------------ | ----------------- | --------------------------------------------------------------- |\n",
    "| `image`           | 'image.jpg'                          | str or Path       | Archivo que contiene una única imagen.                                              |\n",
    "| `URL`             | 'https://ultralytics.com/images/bus.jpg' | str               | Dirección que especifica la ubicación de una imagen en la web.                                                 |\n",
    "| `screenshot`      | 'screen'                             | str               | El sistema captura la imagen actualmente visible en la pantalla y la utiliza como entrada para el modelo.                                           |\n",
    "| `PIL`             | Image.open('im.jpg')                 | PIL.Image         | Utilizado para cargar imágenes en formato HWC (altura, ancho, canales) con canales RGB (rojo, verde y azul) mediante la biblioteca Python Imaging Library (PIL).                                   |\n",
    "| `OpenCV`          | cv2.imread('im.jpg')                 | np.ndarray        | Permite la lectura de una imagen desde un archivo en formato HWC con canales BGR (azul, verde, rojo) utilizando la biblioteca OpenCV, almacenando la imagen como un array de NumPy.                    |\n",
    "| `numpy`           | np.zeros((640,1280,3))               | np.ndarray        | Genera un array de ceros con las dimensiones especificadas para un formato HWC con canales BGR, utilizando la biblioteca NumPy.                    |\n",
    "| `torch`           | torch.zeros(16,3,320,640)            | torch.Tensor      | Crea un tensor de ceros con las dimensiones especificadas para un formato HWC con canales RGB, empleando el framework PyTorch.               |\n",
    "| `CSV`             | 'sources.csv'                        | str or Path       | Archivo de texto que almacena las rutas a las imágenes que se procesarán.   |\n",
    "| `video`          | 'video.mp4'                          | str or Path       | Proporciona acceso a un archivo de video único.                       |\n",
    "| `directory`      | 'path/'                              | str or Path       | Directorio que contiene múltiples archivos de imagen.               |\n",
    "| `glob`           | 'path/*.jpg'                         | str               | Permite acceder a varias imágenes en un directorio usando expresiones de coincidencia de patrones. |\n",
    "| `YouTube`        | 'https://youtu.be/LNwODJXcvt4'       | str               | Facilita el acceso a videos desde la plataforma YouTube.                                         |\n",
    "| `stream`         | 'rtsp://example.com/media.mp4'      | str               | Permite la conexión a flujos de video o audio en tiempo real mediante protocolos como RTSP, RTMP, TCP o IP, ya sea a través de internet o una red local. |\n",
    "| `multi-stream`   | 'list.streams'                       | str or Path       | Se utiliza para transmitir varios flujos de medios simultáneamente, permitiendo el procesamiento y análisis paralelo de múltiples flujos de medios. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Formatos para las imágenes: </span>\n",
    "\n",
    "| Image Suffixes | Reference                           |\n",
    "| --------------- | ----------------------------------- |\n",
    "| .bmp            | [Microsoft BMP File Format](https://docs.fileformat.com/es/image/bmp/)           |\n",
    "| .dng            | [Adobe DNG](https://docs.fileformat.com/es/image/dng/)                           |\n",
    "| .jpeg           | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .jpg            | [JPEG](https://docs.fileformat.com/es/image/jpeg/)                                |\n",
    "| .mpo            | [Multi Picture Object](https://docs.fileformat.com/es/image/mpo/)                |\n",
    "| .png            | [Portable Network Graphics](https://docs.fileformat.com/es/image/png/)           |\n",
    "| .tif            | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .tiff           | [Tag Image File Format](https://docs.fileformat.com/es/image/tiff/)               |\n",
    "| .webp           | [WebP](https://docs.fileformat.com/es/image/webp/)                                |\n",
    "| .pfm            | [Portable FloatMap](https://docs.fileformat.com/font/pfm/)                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 18px\">Formatos para los videos: </span>\n",
    "\n",
    "| Video Suffixes | Reference                           |\n",
    "| -------------- | ----------------------------------- |\n",
    "| .asf           | [Advanced Systems Format](https://docs.fileformat.com/es/video/asf/)             |\n",
    "| .avi           | [Audio Video Interleave](https://docs.fileformat.com/es/video/avi/)              |\n",
    "| .gif           | [Graphics Interchange Format]()          |\n",
    "| .m4v           | [MPEG-4 Part 14](https://docs.fileformat.com/es/video/m4v/)                      |\n",
    "| .mkv           | [Matroska](https://docs.fileformat.com/es/video/mkv/)                            |\n",
    "| .mov           | [QuickTime File Format](https://docs.fileformat.com/es/video/mov/)               |\n",
    "| .mp4           | [MPEG-4](https://docs.fileformat.com/es/video/mp4/)          |\n",
    "| .mpeg          | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .mpg           | [MPEG-1](https://docs.fileformat.com/es/video/mpeg/)                       |\n",
    "| .ts            | [MPEG Transport Stream](https://docs.fileformat.com/es/video/ts/)               |\n",
    "| .wmv           | [Windows Media Video](https://docs.fileformat.com/es/video/wmv/)                 |\n",
    "| .webm          | [WebM Project](https://docs.fileformat.com/es/video/webm/)                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family: 'Bahnschrift Light'; font-size: 40px\">PREDICCIÓN</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\20170531_010133.jpg: 384x640 (no detections), 148.0ms\n",
      "image 2/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\OIP (1).jpg: 480x640 4 rayons, 106.0ms\n",
      "image 3/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\R.jpg: 384x640 (no detections), 87.0ms\n",
      "image 4/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 (no detections), 114.0ms\n",
      "image 5/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 (no detections), 91.0ms\n",
      "image 6/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\big_ray.jpg: 320x640 (no detections), 77.0ms\n",
      "image 7/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg: 448x640 (no detections), 72.4ms\n",
      "image 8/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayahori.webp: 384x640 1 rayon, 78.0ms\n",
      "image 9/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 rayon, 125.0ms\n",
      "image 10/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 1 abolladura, 93.9ms\n",
      "Speed: 3.5ms preprocess, 99.2ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\matrix\\pruebayolo\\runs\\segment\\PruebaPrediccion\u001b[0m\n",
      "4 labels saved to C:\\Users\\matrix\\pruebayolo\\runs\\segment\\PruebaPrediccion\\labels\n"
     ]
    }
   ],
   "source": [
    "trained_model_seg='C:/Users/matrix/pruebayolo/modelos/segmentacion/experimentos/pruebaEntrenamiento/weights/best.pt'\n",
    "\n",
    "selected_model_seg=YOLO(trained_model_seg)\n",
    "\n",
    "NAME='PruebaPrediccion' # El nombre del experimento de predicción para segmentación de instancias debe ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "SOURCE='C:/Users/matrix/pruebayolo/pruebaimagenes' # Establezca el origen de datos que el modelo de segmentación utilizará para realizar predicciones. Configure el valor de este hiperparámetro según la tabla proporcionada anteriormente.\n",
    "MAX_DET=10 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara predecir en una imagen. Se recomienda establecer un valor alto para evitar perder segmentaciones relevantes.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada durante la predicción en tareas de segmentación. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda utilizar los mismos valores utilizados durante el entrenamiento del modelo para mantener la coherencia en la inferencia.\n",
    "CONF=0.5 # Establece el umbral de confianza durante el proceso de predicción en la tarea de segmentación. Se recomienda establecer el valor hiperparámetro entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión en la inferencia.\n",
    "LINE_WIDTH= None # Determina el grosor en píxeles de los cuadros delimitadores que rodean los segmentos identificados por el modelo. Puede establecer el grosor de la línea como un número entero en el que, a mayor valor, la línea será más gruesa, también puede utilizar como valor None para que el grosor se ajuste de forma automatizada, proporcionando una línea proporcional al tamaño de la imagen.\n",
    "VISUALIZE=False # Determina si las características del modelo de segmentación deben mostrarse durante la predicción. Establecer esto en True permite que las características se muestren como mapas intermedias, lo que hace que el modelo sea más fácil de entender. Si se establece en False, no se mostrarán las características del modelo.\n",
    "SAVE=True #Permite que se guarden copias periódicas del modelo durante unos puntos de control en el entrenamiento.\n",
    "IOU=0.7 # El umbral predeterminado para la supresión no máxima (NMS) en la predicción YOLO es 0,7. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren el mismo segmento. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "DEVICE='cpu' # Especifica el dispositivo de ejecución para la prueba de predicción en la operación de segmentación. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "VID_STRIDE=False # Controla la velocidad de los fotogramas durante el proceso de predicción en vídeos o secuencias de tiempo real. Al establecerlo en True el modelo se adapta a la velocidad de fotogramas especificada por la fuente de vídeo, procesando cada fotograma individualmente. Para desactivar esta función indique como valor False.\n",
    "STREAM_BUFFER=False # Controla el almacenamiento en búfer de los fotogramas para la segmentación. Si es True, se almacenan todos los fotogramas para el procesamiento en tiempo real de vídeos o transmisiones en directo; si es False, devuelve el fotograma más reciente.\n",
    "SAVE_FRAMES=False # Controla la captura y almacenamiento de los fotogramas predichos por el modelo de segmentación. Con True, se guardarán todos los fotogramas individuales predichos; con False, no se realizará el almacenamiento de los fotogramas.\n",
    "AUGMENT=False # Aplica transformaciones a las imágenes de entrada, tales como giros, rotaciones, recortes y cambios de color, para diversificar los datos y mejorar la predicción en la segmentación. Establecer en True para activar la función, False para desactivar.\n",
    "CLASSES=None # Filtra los resultados por clase durante la predicción en segmentación. Puede establecerse con un solo ID de clase o una lista de ID de clases para incluir específicamente esas clases en los resultados. Por ejemplo, \"classes=0\" o \"classes=[0, 1]\", también puede establecer el valor a None que tomara todas las clases configuradas en el dataset.\n",
    "SAVE_CROP=True # Determina si se deben guardar imágenes recortadas con los resultados durante la predicción en la segmentación. Al establecerlo en \"False\", las imágenes recortadas no se guardarán, lo que reduce el tamaño del archivo. Con el valor \"True\", se guardarán las imágenes recortadas correspondientes a las áreas segmentadas.\n",
    "SHOW=False # Determina si se deben mostrar las imágenes o vídeos segmentados durante la predicción. Al establecerlo en \"True\", permite la visualización de las predicciones en el mismo entorno, proporcionando una representación visual de los resultados. Si se establece en \"False\", las predicciones no se mostrarán. \n",
    "RETINA_MASKS=False # Permite el uso de máscaras de segmentación de alta resolución durante la predicción, lo que proporciona como resultado detalles finos. Las máscaras de alta resolución pueden representar objetos con precisión pero aumentan el costo computacional. Para activar esta función, establezca el valor en Verdadero; de lo contrario, configúrelo en Falso.\n",
    "\n",
    "\n",
    "mascara_principal=selected_model_seg.predict(name=NAME, source=SOURCE,conf=CONF, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, save=SAVE, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=CLASSES,  save_crop=SAVE_CROP, show=SHOW, save_frames= SAVE_FRAMES, stream=False, retina_masks=RETINA_MASKS, augment=AUGMENT, pretrained=True                   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\20170531_010133.jpg: 384x640 1 car, 354.0ms\n",
      "image 2/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\OIP (1).jpg: 480x640 (no detections), 475.6ms\n",
      "image 3/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\R.jpg: 384x640 1 car, 359.0ms\n",
      "image 4/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladura-en-un-coche-632c58a6e2ea5.jpg: 448x640 (no detections), 433.1ms\n",
      "image 5/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg: 448x640 1 car, 359.5ms\n",
      "image 6/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\big_ray.jpg: 320x640 1 car, 342.0ms\n",
      "image 7/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg: 448x640 (no detections), 397.2ms\n",
      "image 8/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayahori.webp: 384x640 (no detections), 395.3ms\n",
      "image 9/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg: 352x640 1 car, 322.0ms\n",
      "image 10/10 C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg: 448x640 (no detections), 376.9ms\n",
      "Speed: 2.0ms preprocess, 381.5ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\matrix\\pruebayolo\\runs\\segment\\PruebaPrediccion_car\u001b[0m\n",
      "5 labels saved to C:\\Users\\matrix\\pruebayolo\\runs\\segment\\PruebaPrediccion_car\\labels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_origen='yolov8m-seg.pt'\n",
    "\n",
    "selected_model_seg=YOLO(model_origen)\n",
    "\n",
    "NAME='PruebaPrediccion_car' # El nombre del experimento de predicción para segmentación de instancias debe ir entre comillas. Evite el uso de espacios al nombrar las carpetas; en su lugar, utilice algún formato de nombres como camelCase, snake_case o PascalCase.\n",
    "SOURCE='C:/Users/matrix/pruebayolo/pruebaimagenes' # Establezca el origen de datos que el modelo de segmentación utilizará para realizar predicciones. Configure el valor de este hiperparámetro según la tabla proporcionada anteriormente.\n",
    "MAX_DET=10 # Toma como valor solo números enteros. Índica el límite de la cantidad máxima de objetos que el modelo intentara predecir en una imagen. Se recomienda establecer un valor alto para evitar perder segmentaciones relevantes.\n",
    "IMGSZ=640 # Establezca las dimensiones en píxeles de la imagen de entrada durante la predicción en tareas de segmentación. Puede ser un número entero, como 640 para un cuadrado perfecto, o una tupla, como (640, 480), para dimensiones específicas de ancho y alto. Se recomienda utilizar los mismos valores utilizados durante el entrenamiento del modelo para mantener la coherencia en la inferencia.\n",
    "CONF=0.5 # Establece el umbral de confianza durante el proceso de predicción en la tarea de segmentación. Se recomienda establecer el valor hiperparámetro entre 0.5 y 0.10. Un umbral más alto mejora la precisión pero reduce la frecuencia de predicciones, mientras que un umbral más bajo aumenta la frecuencia pero disminuye la precisión en la inferencia.\n",
    "LINE_WIDTH= None # Determina el grosor en píxeles de los cuadros delimitadores que rodean los segmentos identificados por el modelo. Puede establecer el grosor de la línea como un número entero en el que, a mayor valor, la línea será más gruesa, también puede utilizar como valor None para que el grosor se ajuste de forma automatizada, proporcionando una línea proporcional al tamaño de la imagen.\n",
    "VISUALIZE=False # Determina si las características del modelo de segmentación deben mostrarse durante la predicción. Establecer esto en True permite que las características se muestren como mapas intermedias, lo que hace que el modelo sea más fácil de entender. Si se establece en False, no se mostrarán las características del modelo.\n",
    "SAVE=True #Permite que se guarden copias periódicas del modelo durante unos puntos de control en el entrenamiento.\n",
    "IOU=0.7 # El umbral predeterminado para la supresión no máxima (NMS) en la predicción YOLO es 0,7. Este umbral de IoU (intersección sobre unión) es fundamental para NMS porque determina el grado mínimo de superposición requerido para que dos cuadros delimitadores se consideren el mismo segmento. Un umbral de IoU más bajo hace que NMS sea más conservador, mientras que un umbral de IoU más alto permite que un NMS más relajado evite eliminar los verdaderos positivos.\n",
    "DEVICE='cpu' # Especifica el dispositivo de ejecución para la prueba de predicción en la operación de segmentación. Puede seleccionar entre CPU o GPU. Si no dispone de una GPU con Cuda, se recomienda utilizar la CPU mediante el parámetro device='cpu'. En caso de contar con Cuda, puede especificar una GPU con device='cuda:0'; el número representa el identificador de la GPU disponible en el sistema. También es posible utilizar múltiples GPUs mediante device='cuda:0,1,2'.\n",
    "VID_STRIDE=False # Controla la velocidad de los fotogramas durante el proceso de predicción en vídeos o secuencias de tiempo real. Al establecerlo en True el modelo se adapta a la velocidad de fotogramas especificada por la fuente de vídeo, procesando cada fotograma individualmente. Para desactivar esta función indique como valor False.\n",
    "STREAM_BUFFER=False # Controla el almacenamiento en búfer de los fotogramas para la segmentación. Si es True, se almacenan todos los fotogramas para el procesamiento en tiempo real de vídeos o transmisiones en directo; si es False, devuelve el fotograma más reciente.\n",
    "SAVE_FRAMES=False # Controla la captura y almacenamiento de los fotogramas predichos por el modelo de segmentación. Con True, se guardarán todos los fotogramas individuales predichos; con False, no se realizará el almacenamiento de los fotogramas.\n",
    "AUGMENT=False # Aplica transformaciones a las imágenes de entrada, tales como giros, rotaciones, recortes y cambios de color, para diversificar los datos y mejorar la predicción en la segmentación. Establecer en True para activar la función, False para desactivar.\n",
    "CLASSES=2 # Filtra los resultados por clase durante la predicción en segmentación. Puede establecerse con un solo ID de clase o una lista de ID de clases para incluir específicamente esas clases en los resultados. Por ejemplo, \"classes=0\" o \"classes=[0, 1]\", también puede establecer el valor a None que tomara todas las clases configuradas en el dataset.\n",
    "SAVE_CROP=True # Determina si se deben guardar imágenes recortadas con los resultados durante la predicción en la segmentación. Al establecerlo en \"False\", las imágenes recortadas no se guardarán, lo que reduce el tamaño del archivo. Con el valor \"True\", se guardarán las imágenes recortadas correspondientes a las áreas segmentadas.\n",
    "SHOW=False # Determina si se deben mostrar las imágenes o vídeos segmentados durante la predicción. Al establecerlo en \"True\", permite la visualización de las predicciones en el mismo entorno, proporcionando una representación visual de los resultados. Si se establece en \"False\", las predicciones no se mostrarán. \n",
    "RETINA_MASKS=False # Permite el uso de máscaras de segmentación de alta resolución durante la predicción, lo que proporciona como resultado detalles finos. Las máscaras de alta resolución pueden representar objetos con precisión pero aumentan el costo computacional. Para activar esta función, establezca el valor en Verdadero; de lo contrario, configúrelo en Falso.\n",
    "\n",
    "\n",
    "mascara_car=selected_model_seg.predict(name=NAME, source=SOURCE,conf=CONF, save_txt=True, max_det=MAX_DET, line_width=LINE_WIDTH, visualize=VISUALIZE, imgsz=IMGSZ, save=SAVE, iou=IOU, device=DEVICE, vid_stride=VID_STRIDE, stream_buffer=STREAM_BUFFER, classes=CLASSES,  save_crop=SAVE_CROP, show=SHOW, save_frames= SAVE_FRAMES, stream=False, retina_masks=RETINA_MASKS, augment=AUGMENT, pretrained=True                   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de área para mascaras segmentadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de área en formato mascaras normalizadas\n",
    "\n",
    "def calcular_area_mascara(coordenada, pixel_imagen):\n",
    "    width, height = pixel_imagen # Se asigna los valores de la tupla\n",
    "    x_coor = coordenada[:, 0] * width # Asigna los valores de la coordenada x en pixeles \n",
    "    y_coor = coordenada[:, 1] * height # Asigna los valores de la coordenada y en pixeles \n",
    "    return 0.5 * abs(np.dot(x_coor, np.roll(y_coor, 1)) - np.dot(y_coor, np.roll(x_coor, 1))) # Utiliza la formula de área de Gauss\n",
    "\n",
    "def Obtener_area_total(results):\n",
    "    for id_imagen, objeto in enumerate(results):\n",
    "        area_total_imagen = 0.0\n",
    "        \n",
    "        try:\n",
    "            mascaras = objeto.masks.xyn # Extrae las mascaras de segmentación de la region de interes en un tensor \n",
    "            pixel_imagen = objeto.masks.orig_shape # Extrae el tamaño original de la imagen en una tupla (alto, ancho)\n",
    "            print(f'\\nImagen {id_imagen + 1}: ')\n",
    "            \n",
    "            for indice, mascara in enumerate(mascaras):\n",
    "                area_mascara = calcular_area_mascara(mascara, pixel_imagen) # Envia a la función cada array con las coordenadas de cada mascara en la imagen\n",
    "                area_total_imagen += area_mascara\n",
    "                print(f'El área de la mascara {indice + 1} es: {area_mascara} px') \n",
    "            print(f'El área total afectada es: {area_total_imagen} px^2 ')\n",
    "        except Exception:\n",
    "            print(f'\\nImagen {id_imagen + 1}, no existe ninguna mascara en el objeto! ')\n",
    "            \n",
    "    print('\\nProceso Terminado! ')\n",
    "Obtener_area_total(mascara_principal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de área en formato normalizado actualizada\n",
    "\n",
    "def calcular_area(coordenada, pixel_img):\n",
    "    width, height = pixel_img \n",
    "    x = coordenada[:, 0] * width #\n",
    "    y = coordenada[:, 1] * height #\n",
    "    return 0.5 * abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1))) #\n",
    "\n",
    "def obtener_pixeles(pixel):\n",
    "    if pixel.masks is not None:\n",
    "        return pixel.masks.orig_shape #\n",
    "\n",
    "def procesar_imagen(results, mascara_car):\n",
    "    for mascara, obj in enumerate(results):\n",
    "        mascaras_principales = obj.masks #\n",
    "        print(f'\\nImagen {mascara + 1}: {obj.path}') \n",
    "\n",
    "        if mascaras_principales is not None:\n",
    "            mascaras_principales = mascaras_principales.xyn #\n",
    "            pixel = obtener_pixeles(obj)\n",
    "            area_base_total = procesar_mascaras(mascaras_principales, pixel, \"MASCARAS RAYON ABOLLADURA\")\n",
    "\n",
    "            if mascara < len(mascara_car):\n",
    "                mascaras_car = mascara_car[mascara].masks #\n",
    "                if mascaras_car is not None:\n",
    "                    mascaras_car = mascaras_car.xyn #\n",
    "                    pixel_image_car = obtener_pixeles(mascara_car[mascara]) #\n",
    "                    area_carro_total = procesar_mascaras(mascaras_car, pixel_image_car, \"MASCARAS CARRO\")\n",
    "                    area_total = area_carro_total - area_base_total\n",
    "                    print(f'Área total afectada en el carro: {area_total} px^2')\n",
    "                else:\n",
    "                    print(f'No hay máscaras correspondientes de carro! ')\n",
    "            else:\n",
    "                print(f'No hay máscaras correspondientes de carro! ')\n",
    "        else:\n",
    "            print(f'No se encontraron segmentaciones en la imagen! ')\n",
    "\n",
    "def procesar_mascaras(mascaras, pixelito, mensaje):\n",
    "    area_total = 0.0\n",
    "    print(f'{mensaje}: ')\n",
    "\n",
    "    for id_mascara, instancia_mascara in enumerate(mascaras):\n",
    "        coordenada_mascara = calcular_area(instancia_mascara, pixelito)\n",
    "        area_total += coordenada_mascara\n",
    "        print(f'Mascara {id_mascara + 1}, area: {coordenada_mascara} px ')\n",
    "\n",
    "    print(f'Área total afectada: {area_total} px^2 ')\n",
    "    return area_total\n",
    "\n",
    "procesar_imagen(mascara_principal, mascara_car)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de area en formato pixel\n",
    "\n",
    "def calcular_area_mascara(coordenada):\n",
    "    x_coor = coordenada[:, 0]  \n",
    "    y_coor = coordenada[:, 1]  \n",
    "    return 0.5 * abs(np.dot(x_coor, np.roll(y_coor, 1)) - np.dot(y_coor, np.roll(x_coor, 1)))\n",
    "\n",
    "def obtener_area_total(results):\n",
    "    \n",
    "    for id_imagen, objeto in enumerate(results):\n",
    "        area_total_imagen = 0.0\n",
    "        \n",
    "        try:\n",
    "            mascaras = objeto.masks.xy  \n",
    "            print(f'\\nImagen {id_imagen + 1}: ')\n",
    "            \n",
    "            for indice, mascara in enumerate(mascaras):\n",
    "                area_objeto = calcular_area_mascara(mascara)\n",
    "                area_total_imagen += area_objeto\n",
    "                print(f'El área de la mascara {indice + 1} en la imagen es: {area_objeto} px')\n",
    "                \n",
    "            print(f'El área total afectada es: {area_total_imagen} px^2')\n",
    "            \n",
    "        except Exception:\n",
    "            print(f'\\nImagen {id_imagen + 1}, no existe ninguna mascara en el objeto! ')\n",
    "                \n",
    "    print('\\nProceso Terminado! ')\n",
    "\n",
    "obtener_area_total(mascara_principal) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[    0.28125,     0.45618],\n",
      "       [    0.27969,     0.45837],\n",
      "       [    0.27969,     0.46056],\n",
      "       [    0.28125,     0.46056],\n",
      "       [    0.28281,     0.46275],\n",
      "       [    0.29219,     0.46275],\n",
      "       [    0.29688,     0.46932],\n",
      "       [    0.29844,     0.46932],\n",
      "       [        0.3,     0.47151],\n",
      "       [    0.30625,     0.47151],\n",
      "       [    0.30781,     0.47371],\n",
      "       [    0.30937,     0.47371],\n",
      "       [    0.31406,     0.48028],\n",
      "       [    0.32656,     0.48028],\n",
      "       [    0.33281,     0.48904],\n",
      "       [    0.34844,     0.48904],\n",
      "       [       0.35,     0.48685],\n",
      "       [    0.35625,     0.48685],\n",
      "       [    0.35625,     0.48466],\n",
      "       [    0.35156,     0.48466],\n",
      "       [       0.35,     0.48247],\n",
      "       [    0.34062,     0.48247],\n",
      "       [    0.33906,     0.48028],\n",
      "       [     0.3375,     0.48028],\n",
      "       [    0.33594,     0.47809],\n",
      "       [    0.33437,     0.47809],\n",
      "       [    0.33281,      0.4759],\n",
      "       [    0.33125,      0.4759],\n",
      "       [    0.32969,     0.47371],\n",
      "       [      0.325,     0.47371],\n",
      "       [    0.32187,     0.46932],\n",
      "       [    0.32031,     0.46932],\n",
      "       [    0.31875,     0.46713],\n",
      "       [    0.31562,     0.46713],\n",
      "       [    0.31406,     0.46494],\n",
      "       [    0.30312,     0.46494],\n",
      "       [    0.30156,     0.46275],\n",
      "       [    0.29844,     0.46275],\n",
      "       [    0.29531,     0.45837],\n",
      "       [    0.29375,     0.45837],\n",
      "       [    0.29219,     0.45618]], dtype=float32), array([[    0.28281,     0.45618],\n",
      "       [    0.28125,     0.45837],\n",
      "       [    0.27969,     0.45837],\n",
      "       [    0.27969,     0.46056],\n",
      "       [    0.28281,     0.46056],\n",
      "       [    0.28437,     0.46275],\n",
      "       [    0.29375,     0.46275],\n",
      "       [    0.29531,     0.46494],\n",
      "       [    0.29531,     0.46713],\n",
      "       [    0.29688,     0.46932],\n",
      "       [        0.3,     0.46932],\n",
      "       [    0.30156,     0.47151],\n",
      "       [    0.30625,     0.47151],\n",
      "       [    0.30781,     0.47371],\n",
      "       [    0.30937,     0.47371],\n",
      "       [    0.31406,     0.48028],\n",
      "       [      0.325,     0.48028],\n",
      "       [    0.32656,     0.48247],\n",
      "       [    0.32812,     0.48247],\n",
      "       [    0.33281,     0.48904],\n",
      "       [    0.33594,     0.48904],\n",
      "       [     0.3375,     0.49124],\n",
      "       [    0.33906,     0.49124],\n",
      "       [    0.34219,     0.49562],\n",
      "       [    0.34375,     0.49562],\n",
      "       [    0.34531,     0.49781],\n",
      "       [    0.35625,     0.49781],\n",
      "       [    0.35781,         0.5],\n",
      "       [    0.35938,         0.5],\n",
      "       [     0.3625,     0.50438],\n",
      "       [    0.36719,     0.50438],\n",
      "       [    0.36875,     0.50657],\n",
      "       [    0.37187,     0.50657],\n",
      "       [    0.37656,     0.51315],\n",
      "       [    0.38594,     0.51315],\n",
      "       [     0.3875,     0.51534],\n",
      "       [    0.38906,     0.51534],\n",
      "       [    0.39375,     0.52191],\n",
      "       [     0.4125,     0.52191],\n",
      "       [    0.41406,     0.51972],\n",
      "       [    0.41094,     0.51972],\n",
      "       [    0.40937,     0.51753],\n",
      "       [    0.40625,     0.51753],\n",
      "       [    0.40469,     0.51534],\n",
      "       [    0.40312,     0.51534],\n",
      "       [    0.40156,     0.51315],\n",
      "       [        0.4,     0.51315],\n",
      "       [    0.39844,     0.51096],\n",
      "       [    0.39844,     0.50876],\n",
      "       [    0.39687,     0.50657],\n",
      "       [    0.39687,     0.50438],\n",
      "       [    0.39531,     0.50219],\n",
      "       [    0.39062,     0.50219],\n",
      "       [    0.38906,         0.5],\n",
      "       [    0.37969,         0.5],\n",
      "       [    0.37812,     0.49781],\n",
      "       [    0.37656,     0.49781],\n",
      "       [    0.37344,     0.49343],\n",
      "       [    0.37031,     0.49343],\n",
      "       [    0.36875,     0.49124],\n",
      "       [    0.36406,     0.49124],\n",
      "       [     0.3625,     0.48904],\n",
      "       [    0.36094,     0.48904],\n",
      "       [    0.35938,     0.48685],\n",
      "       [    0.35781,     0.48685],\n",
      "       [    0.35625,     0.48466],\n",
      "       [       0.35,     0.48466],\n",
      "       [    0.34844,     0.48247],\n",
      "       [    0.34062,     0.48247],\n",
      "       [    0.33906,     0.48028],\n",
      "       [     0.3375,     0.48028],\n",
      "       [    0.33594,     0.47809],\n",
      "       [    0.33437,     0.47809],\n",
      "       [    0.33281,      0.4759],\n",
      "       [    0.33125,      0.4759],\n",
      "       [    0.32969,     0.47371],\n",
      "       [      0.325,     0.47371],\n",
      "       [    0.32187,     0.46932],\n",
      "       [    0.32031,     0.46932],\n",
      "       [    0.31875,     0.46713],\n",
      "       [    0.31562,     0.46713],\n",
      "       [    0.31406,     0.46494],\n",
      "       [    0.29844,     0.46494],\n",
      "       [    0.29375,     0.45837],\n",
      "       [    0.29219,     0.45837],\n",
      "       [    0.29062,     0.45618]], dtype=float32), array([[    0.60781,     0.75418],\n",
      "       [    0.60625,     0.75637],\n",
      "       [    0.60312,     0.75637],\n",
      "       [    0.60312,     0.75856],\n",
      "       [    0.60469,     0.75856],\n",
      "       [    0.60625,     0.76075],\n",
      "       [    0.60781,     0.76075],\n",
      "       [     0.6125,     0.76733],\n",
      "       [    0.61406,     0.76733],\n",
      "       [    0.61562,     0.76952],\n",
      "       [    0.61875,     0.76952],\n",
      "       [    0.62031,     0.77171],\n",
      "       [    0.62187,     0.77171],\n",
      "       [    0.62344,      0.7739],\n",
      "       [      0.625,      0.7739],\n",
      "       [    0.62656,     0.77609],\n",
      "       [    0.62969,     0.77609],\n",
      "       [    0.63125,     0.77828],\n",
      "       [    0.71094,     0.77828],\n",
      "       [     0.7125,     0.77609],\n",
      "       [    0.71719,     0.77609],\n",
      "       [    0.71875,      0.7739],\n",
      "       [    0.71719,      0.7739],\n",
      "       [    0.71562,     0.77171],\n",
      "       [    0.71406,     0.77171],\n",
      "       [    0.71094,     0.76733],\n",
      "       [    0.70937,     0.76733],\n",
      "       [    0.70781,     0.76513],\n",
      "       [    0.70156,     0.76513],\n",
      "       [        0.7,     0.76294],\n",
      "       [    0.67656,     0.76294],\n",
      "       [      0.675,     0.76075],\n",
      "       [    0.67344,     0.76075],\n",
      "       [    0.67188,     0.75856],\n",
      "       [    0.67031,     0.75856],\n",
      "       [    0.66875,     0.75637],\n",
      "       [    0.66562,     0.75637],\n",
      "       [    0.66406,     0.75418]], dtype=float32), array([[   0.090625,     0.34223],\n",
      "       [     0.0875,     0.34662],\n",
      "       [   0.089062,     0.34881],\n",
      "       [   0.090625,     0.34881],\n",
      "       [   0.095312,     0.35538],\n",
      "       [   0.096875,     0.35538],\n",
      "       [   0.098437,     0.35757],\n",
      "       [    0.10312,     0.35757],\n",
      "       [    0.10469,     0.35976],\n",
      "       [    0.10937,     0.35976],\n",
      "       [    0.11406,     0.36634],\n",
      "       [    0.11562,     0.36634],\n",
      "       [    0.11719,     0.36853],\n",
      "       [    0.11875,     0.36853],\n",
      "       [    0.12031,     0.37072],\n",
      "       [    0.12187,     0.37072],\n",
      "       [    0.12344,     0.37291],\n",
      "       [      0.125,     0.37291],\n",
      "       [    0.12656,      0.3751],\n",
      "       [    0.14062,      0.3751],\n",
      "       [    0.14062,     0.37072],\n",
      "       [    0.13906,     0.36853],\n",
      "       [    0.13281,     0.36853],\n",
      "       [    0.12656,     0.35976],\n",
      "       [    0.12031,     0.35976],\n",
      "       [    0.11719,     0.35538],\n",
      "       [    0.11719,     0.35319],\n",
      "       [    0.11562,     0.35319],\n",
      "       [    0.11406,       0.351],\n",
      "       [    0.10625,       0.351],\n",
      "       [    0.10469,     0.34881],\n",
      "       [    0.10312,     0.34881],\n",
      "       [        0.1,     0.34442],\n",
      "       [   0.098437,     0.34442],\n",
      "       [   0.096875,     0.34223]], dtype=float32)]\n",
      "[array([[    0.28125,     0.73324],\n",
      "       [    0.27969,     0.73601],\n",
      "       [    0.27812,     0.73601],\n",
      "       [    0.27344,     0.74434],\n",
      "       [    0.26406,     0.74434],\n",
      "       [     0.2625,     0.74712],\n",
      "       [     0.2625,      0.7499],\n",
      "       [    0.26406,     0.75267],\n",
      "       [    0.27344,     0.75267],\n",
      "       [      0.275,      0.7499],\n",
      "       [    0.27656,      0.7499],\n",
      "       [    0.28125,     0.74157],\n",
      "       [    0.31875,     0.74157],\n",
      "       [    0.32031,     0.74434],\n",
      "       [    0.32344,     0.74434],\n",
      "       [    0.32656,      0.7499],\n",
      "       [    0.32969,      0.7499],\n",
      "       [    0.33125,     0.74712],\n",
      "       [    0.33437,     0.74712],\n",
      "       [    0.33594,     0.74434],\n",
      "       [    0.34688,     0.74434],\n",
      "       [    0.34844,     0.74712],\n",
      "       [       0.35,     0.74712],\n",
      "       [    0.35156,      0.7499],\n",
      "       [    0.35625,      0.7499],\n",
      "       [    0.35781,     0.75267],\n",
      "       [    0.40312,     0.75267],\n",
      "       [    0.40469,      0.7499],\n",
      "       [    0.40625,      0.7499],\n",
      "       [    0.40625,     0.74712],\n",
      "       [    0.40469,     0.74434],\n",
      "       [    0.36875,     0.74434],\n",
      "       [    0.36719,     0.74157],\n",
      "       [    0.36406,     0.74157],\n",
      "       [    0.36094,     0.73601],\n",
      "       [    0.35781,     0.73601],\n",
      "       [    0.35625,     0.73324]], dtype=float32)]\n",
      "[array([[    0.39531,     0.18836],\n",
      "       [    0.39531,     0.19127],\n",
      "       [    0.39219,     0.19709],\n",
      "       [    0.39062,     0.19709],\n",
      "       [    0.38438,     0.20874],\n",
      "       [    0.38281,     0.20874],\n",
      "       [    0.38125,     0.21166],\n",
      "       [    0.38125,     0.21457],\n",
      "       [    0.37813,     0.22039],\n",
      "       [    0.37656,     0.22039],\n",
      "       [    0.37031,     0.23204],\n",
      "       [    0.36406,     0.23204],\n",
      "       [     0.3625,     0.23496],\n",
      "       [    0.36094,     0.23496],\n",
      "       [    0.36094,     0.23787],\n",
      "       [    0.35938,     0.24078],\n",
      "       [    0.35781,     0.24078],\n",
      "       [    0.35625,      0.2437],\n",
      "       [    0.35156,      0.2437],\n",
      "       [       0.35,     0.24661],\n",
      "       [       0.35,     0.25243],\n",
      "       [    0.34844,     0.25535],\n",
      "       [    0.33906,     0.25535],\n",
      "       [     0.3375,     0.25826],\n",
      "       [     0.3375,     0.26408],\n",
      "       [    0.33594,       0.267],\n",
      "       [    0.32969,       0.267],\n",
      "       [    0.32812,     0.26991],\n",
      "       [    0.32656,     0.26991],\n",
      "       [    0.32656,     0.27282],\n",
      "       [    0.32812,     0.27573],\n",
      "       [    0.33281,     0.27573],\n",
      "       [    0.33437,     0.27282],\n",
      "       [    0.33594,     0.27282],\n",
      "       [    0.33594,       0.267],\n",
      "       [     0.3375,     0.26408],\n",
      "       [    0.34531,     0.26408],\n",
      "       [    0.34688,     0.26117],\n",
      "       [    0.34844,     0.26117],\n",
      "       [    0.34844,     0.25535],\n",
      "       [       0.35,     0.25243],\n",
      "       [    0.35938,     0.25243],\n",
      "       [    0.36406,      0.2437],\n",
      "       [    0.36562,      0.2437],\n",
      "       [    0.36719,     0.24078],\n",
      "       [    0.37187,     0.24078],\n",
      "       [    0.37344,     0.23787],\n",
      "       [      0.375,     0.23787],\n",
      "       [    0.37813,     0.23204],\n",
      "       [    0.37969,     0.23204],\n",
      "       [    0.38125,     0.22913],\n",
      "       [    0.38281,     0.22913],\n",
      "       [    0.39844,     0.20001],\n",
      "       [    0.39844,     0.18836]], dtype=float32)]\n",
      "[array([[    0.73281,     0.42731],\n",
      "       [    0.73125,     0.42965],\n",
      "       [    0.71719,     0.42965],\n",
      "       [    0.71563,       0.432],\n",
      "       [    0.71094,       0.432],\n",
      "       [    0.70781,     0.43669],\n",
      "       [    0.70781,     0.43903],\n",
      "       [    0.70625,     0.44138],\n",
      "       [    0.70625,     0.44372],\n",
      "       [    0.70469,     0.44607],\n",
      "       [    0.70469,     0.44841],\n",
      "       [    0.67656,     0.49062],\n",
      "       [      0.675,     0.49062],\n",
      "       [      0.675,     0.49297],\n",
      "       [    0.67031,         0.5],\n",
      "       [    0.66875,         0.5],\n",
      "       [    0.66875,     0.50234],\n",
      "       [    0.66406,     0.50938],\n",
      "       [     0.6625,     0.50938],\n",
      "       [     0.6625,     0.51172],\n",
      "       [    0.65469,     0.52345],\n",
      "       [    0.65469,     0.52579],\n",
      "       [    0.65156,     0.53048],\n",
      "       [       0.65,     0.53048],\n",
      "       [       0.65,     0.53283],\n",
      "       [    0.63906,     0.54924],\n",
      "       [     0.6375,     0.54924],\n",
      "       [    0.63594,     0.55159],\n",
      "       [    0.63438,     0.55159],\n",
      "       [    0.63438,       0.568],\n",
      "       [    0.63281,     0.57035],\n",
      "       [    0.63281,     0.58442],\n",
      "       [    0.63125,     0.58676],\n",
      "       [    0.63125,      0.5938],\n",
      "       [    0.63281,     0.59614],\n",
      "       [    0.63281,     0.62663],\n",
      "       [    0.63438,     0.62897],\n",
      "       [    0.63438,     0.63131],\n",
      "       [    0.63594,     0.63366],\n",
      "       [    0.63594,     0.63835],\n",
      "       [     0.6375,     0.64069],\n",
      "       [     0.6375,     0.64538],\n",
      "       [    0.63906,     0.64773],\n",
      "       [    0.63906,     0.65242],\n",
      "       [    0.64062,     0.65476],\n",
      "       [    0.64062,     0.65711],\n",
      "       [    0.64219,     0.65945],\n",
      "       [    0.64219,     0.66414],\n",
      "       [    0.64375,     0.66649],\n",
      "       [    0.64375,     0.69228],\n",
      "       [    0.64219,     0.69463],\n",
      "       [    0.64219,     0.69697],\n",
      "       [    0.64062,     0.69932],\n",
      "       [    0.64062,     0.70166],\n",
      "       [    0.63906,     0.70401],\n",
      "       [    0.63906,     0.70635],\n",
      "       [    0.63438,     0.71339],\n",
      "       [    0.63438,     0.72511],\n",
      "       [    0.63594,     0.72746],\n",
      "       [    0.63594,     0.73684],\n",
      "       [     0.6375,     0.73918],\n",
      "       [    0.63594,     0.74153],\n",
      "       [    0.63594,     0.74856],\n",
      "       [     0.6375,     0.75091],\n",
      "       [    0.63906,     0.75091],\n",
      "       [    0.64219,     0.75559],\n",
      "       [    0.64219,     0.75794],\n",
      "       [    0.64062,     0.76028],\n",
      "       [    0.64062,     0.76497],\n",
      "       [    0.63906,     0.76732],\n",
      "       [    0.63906,     0.77435],\n",
      "       [    0.64375,     0.78139],\n",
      "       [    0.64375,     0.78373],\n",
      "       [    0.64531,     0.78608],\n",
      "       [    0.64531,     0.79311],\n",
      "       [    0.64687,     0.79546],\n",
      "       [    0.64687,      0.7978],\n",
      "       [    0.65156,     0.80484],\n",
      "       [    0.65156,     0.80718],\n",
      "       [    0.65313,     0.80953],\n",
      "       [    0.65313,     0.81187],\n",
      "       [    0.65625,     0.81656],\n",
      "       [    0.65625,     0.81891],\n",
      "       [    0.66563,     0.83298],\n",
      "       [    0.66719,     0.83298],\n",
      "       [    0.67031,     0.83767],\n",
      "       [    0.67344,     0.83767],\n",
      "       [      0.675,     0.84001],\n",
      "       [    0.67656,     0.84001],\n",
      "       [    0.67812,     0.84236],\n",
      "       [    0.67969,     0.84236],\n",
      "       [    0.68125,      0.8447],\n",
      "       [    0.68438,      0.8447],\n",
      "       [    0.68594,     0.84705],\n",
      "       [    0.68906,     0.84705],\n",
      "       [    0.69219,     0.85174],\n",
      "       [    0.69375,     0.85174],\n",
      "       [    0.69531,     0.85408],\n",
      "       [    0.69844,     0.85408],\n",
      "       [        0.7,     0.85643],\n",
      "       [    0.70312,     0.85643],\n",
      "       [    0.70625,     0.86112],\n",
      "       [    0.70937,     0.86112],\n",
      "       [    0.71094,     0.86346],\n",
      "       [    0.71563,     0.86346],\n",
      "       [    0.71719,     0.86581],\n",
      "       [    0.71875,     0.86581],\n",
      "       [    0.72031,     0.86815],\n",
      "       [    0.72188,     0.86815],\n",
      "       [    0.72344,      0.8705],\n",
      "       [    0.72656,      0.8705],\n",
      "       [    0.72813,     0.87284],\n",
      "       [    0.72969,     0.87284],\n",
      "       [    0.73125,     0.87519],\n",
      "       [    0.73281,     0.87519],\n",
      "       [    0.73438,     0.87753],\n",
      "       [    0.73594,     0.87753],\n",
      "       [    0.73906,     0.88222],\n",
      "       [    0.74062,     0.88222],\n",
      "       [    0.74219,     0.88456],\n",
      "       [    0.74375,     0.88456],\n",
      "       [    0.74688,     0.88925],\n",
      "       [    0.75156,     0.88925],\n",
      "       [    0.75313,      0.8916],\n",
      "       [    0.75625,      0.8916],\n",
      "       [    0.75781,     0.89394],\n",
      "       [    0.76562,     0.89394],\n",
      "       [    0.76719,     0.89629],\n",
      "       [    0.79375,     0.89629],\n",
      "       [    0.79531,     0.89394],\n",
      "       [    0.79688,     0.89394],\n",
      "       [    0.79844,      0.8916],\n",
      "       [        0.8,      0.8916],\n",
      "       [    0.80156,     0.88925],\n",
      "       [    0.80312,     0.88925],\n",
      "       [    0.80625,     0.88456],\n",
      "       [    0.80781,     0.88456],\n",
      "       [    0.80938,     0.88222],\n",
      "       [     0.8125,     0.88222],\n",
      "       [    0.81406,     0.87988],\n",
      "       [    0.81563,     0.87988],\n",
      "       [    0.82031,     0.87284],\n",
      "       [    0.82188,     0.87284],\n",
      "       [    0.82344,      0.8705],\n",
      "       [      0.825,      0.8705],\n",
      "       [    0.82656,     0.86815],\n",
      "       [    0.82812,     0.86815],\n",
      "       [    0.83437,     0.85877],\n",
      "       [    0.83437,     0.85643],\n",
      "       [    0.83906,     0.84939],\n",
      "       [    0.83906,      0.8447],\n",
      "       [    0.84063,     0.84236],\n",
      "       [    0.84063,     0.84001],\n",
      "       [    0.84688,     0.83063],\n",
      "       [    0.84688,     0.82829],\n",
      "       [     0.8625,     0.80484],\n",
      "       [     0.8625,     0.80249],\n",
      "       [    0.86406,     0.80015],\n",
      "       [    0.86562,     0.80015],\n",
      "       [    0.86875,     0.79546],\n",
      "       [    0.86875,     0.79311],\n",
      "       [    0.87031,     0.79077],\n",
      "       [    0.87188,     0.79077],\n",
      "       [      0.875,     0.78608],\n",
      "       [      0.875,     0.78373],\n",
      "       [    0.87656,     0.78139],\n",
      "       [    0.87813,     0.78139],\n",
      "       [    0.88594,     0.76966],\n",
      "       [    0.88594,     0.76732],\n",
      "       [     0.8875,     0.76497],\n",
      "       [     0.8875,     0.76263],\n",
      "       [    0.89062,     0.75794],\n",
      "       [    0.89062,     0.75559],\n",
      "       [    0.89375,     0.75091],\n",
      "       [    0.89375,     0.74622],\n",
      "       [    0.90313,     0.73215],\n",
      "       [    0.90781,     0.73215],\n",
      "       [    0.90781,     0.71808],\n",
      "       [    0.90938,     0.71573],\n",
      "       [    0.90938,     0.66649],\n",
      "       [    0.91094,     0.66414],\n",
      "       [    0.91094,       0.636],\n",
      "       [    0.90938,     0.63366],\n",
      "       [    0.90938,     0.56331],\n",
      "       [    0.90781,     0.56097],\n",
      "       [    0.90781,     0.55862],\n",
      "       [    0.90625,     0.56097],\n",
      "       [    0.90469,     0.56097],\n",
      "       [    0.90313,     0.56331],\n",
      "       [    0.87813,     0.56331],\n",
      "       [    0.87656,     0.56097],\n",
      "       [    0.87031,     0.56097],\n",
      "       [    0.86562,     0.55393],\n",
      "       [    0.86406,     0.55393],\n",
      "       [    0.84375,     0.52345],\n",
      "       [    0.84375,      0.5211],\n",
      "       [    0.84063,     0.51641],\n",
      "       [    0.83906,     0.51641],\n",
      "       [    0.83594,     0.51172],\n",
      "       [    0.83594,     0.50938],\n",
      "       [    0.82344,     0.49062],\n",
      "       [    0.82188,     0.49062],\n",
      "       [    0.81875,     0.48593],\n",
      "       [    0.81875,     0.48359],\n",
      "       [    0.81563,      0.4789],\n",
      "       [    0.81563,     0.47655],\n",
      "       [     0.8125,     0.47186],\n",
      "       [     0.8125,     0.46952],\n",
      "       [    0.80938,     0.46483],\n",
      "       [    0.80781,     0.46483],\n",
      "       [    0.80625,     0.46248],\n",
      "       [    0.80469,     0.46248],\n",
      "       [        0.8,     0.45545],\n",
      "       [    0.79844,     0.45545],\n",
      "       [    0.79688,      0.4531],\n",
      "       [    0.79531,      0.4531],\n",
      "       [    0.79375,     0.45076],\n",
      "       [    0.79063,     0.45076],\n",
      "       [     0.7875,     0.44607],\n",
      "       [    0.78594,     0.44607],\n",
      "       [    0.78438,     0.44372],\n",
      "       [    0.78281,     0.44372],\n",
      "       [    0.78125,     0.44138],\n",
      "       [    0.77656,     0.44138],\n",
      "       [      0.775,     0.43903],\n",
      "       [    0.77344,     0.43903],\n",
      "       [    0.77031,     0.43434],\n",
      "       [    0.76875,     0.43434],\n",
      "       [    0.76719,       0.432],\n",
      "       [    0.76406,       0.432],\n",
      "       [     0.7625,     0.42965],\n",
      "       [    0.75625,     0.42965],\n",
      "       [    0.75469,     0.42731]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in mascara_principal:\n",
    "    if i.masks is not None:\n",
    "        print(i.masks.xyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imagen 1: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\20170531_010133.jpg\n",
      "No se encontraron segmentaciones en la imagen! \n",
      "\n",
      "Imagen 2: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\OIP (1).jpg\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1, area: 98.75 px \n",
      "Mascara 2, area: 230.25 px \n",
      "Mascara 3, area: 317.0 px \n",
      "Mascara 4, area: 87.4921875 px \n",
      "Área total afectada en el carro: 733.4921875 px^2\n",
      "\n",
      "Imagen 3: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\R.jpg\n",
      "No se encontraron segmentaciones en la imagen! \n",
      "\n",
      "Imagen 4: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladura-en-un-coche-632c58a6e2ea5.jpg\n",
      "No se encontraron segmentaciones en la imagen! \n",
      "\n",
      "Imagen 5: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg\n",
      "No se encontraron segmentaciones en la imagen! \n",
      "\n",
      "Imagen 6: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\big_ray.jpg\n",
      "No se encontraron segmentaciones en la imagen! \n",
      "\n",
      "Imagen 7: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg\n",
      "No se encontraron segmentaciones en la imagen! \n",
      "\n",
      "Imagen 8: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayahori.webp\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1, area: 527.125 px \n",
      "Área total afectada en el carro: 527.125 px^2\n",
      "\n",
      "Imagen 9: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1, area: 303.4375 px \n",
      "MASCARAS CARRO: \n",
      "Mascara 1, area: 367066.0 px \n",
      "Área total afectada en el carro: 366762.5625 px^2\n",
      "\n",
      "Imagen 10: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1, area: 66108.0 px \n",
      "Área total afectada en el carro: 66108.0 px^2\n",
      "\n",
      "Proceso terminado! \n"
     ]
    }
   ],
   "source": [
    "# Función de área en formato pixel actualizada\n",
    "\n",
    "def calcular_area(vertices):\n",
    "    coordenada_x = vertices[:, 0] # Asigna todas filas correspondientes a la primer columna como coordenada X del formato masks que entrega por medio de arrays los vertices (x , y) de los puntos de contorno por medio de una lista para cada región segmentada.\n",
    "    coordenada_y = vertices[:, 1] # Asigna todas filas correspondientes a la segunda columna como coordenada Y del formato masks que entrega por medio de arrays los vertices (x , y) de los puntos de contorno por medio de una lista para cada región segmentada.\n",
    "    return 0.5 * abs(np.dot(coordenada_x, np.roll(coordenada_y, 1)) - np.dot(coordenada_y, np.roll(coordenada_x, 1))) # Se basa en la formula Shoelace o lazada de Gauss. Utiliza la suma y la resta de los productos cruzados de las coordenadas de los vertices del poligono; el termino np.roll(y, 1) y np.roll(x, 1) crean versiones desplazadas circularmente, es esencial para que np.dot() calcule el producto punto de los vertices del poligono, la diferencia entre los productos cruzados se multiplicara por 1/2 tomando el valor absoluto.\n",
    "\n",
    "def procesar_mascaras(mascaras, mensaje):\n",
    "    area_total_objeto = 0.0\n",
    "    print(f'{mensaje}: ')\n",
    "    for id_mascara, coordenadas in enumerate(mascaras): # Recorre con una instancia los valores de las coordenadas que obtuvo de las mascaras individualmente.\n",
    "        coordenada_mascara = calcular_area(coordenadas)\n",
    "        area_total_objeto += coordenada_mascara # Al obtener el area individual de cada mascara en un objeto ira sumando en caso de encontrar mas mascaras en una instancia.\n",
    "        print(f'Mascara {id_mascara + 1}, area: {coordenada_mascara} px^2 ') \n",
    "    return area_total_objeto\n",
    "\n",
    "def procesar_imagen(segmentacion_base, segmentacion_car):\n",
    "    for id_objeto, mascara_central in enumerate(segmentacion_base, 0): #Recorre los resultados que contienen la información de las segmentaciones de la mascara principal, obteniendo su posición y valor.\n",
    "        \n",
    "        print(f'\\nImagen {id_objeto + 1}: {mascara_central.path}') # Imprimira la posición del objeto, ademas de la ubicación del archivo en el equipo.\n",
    "        \n",
    "        mascaras_principales = mascara_central.masks.xy if mascara_central.masks is not None else None # Guarda en una variable los atributos que encontro sobre las mascaras de cada objeto, se compone de data, orig_shape, formatos de valores para las coordenadas; xy (formato en valores pixel) y xyn (formato en valores normalizados al tamaño de la imagen).\n",
    "        if mascaras_principales is not None and len(mascaras_principales) > 0: # Permite verificar si existen mascaras de segmentación en el objeto, debe contener la variable un valor mayor a 0.\n",
    "            area_base_total = procesar_mascaras(mascaras_principales, \"MASCARAS RAYON ABOLLADURA\")\n",
    "            \n",
    "            for mascara_auxiliar in segmentacion_car: # Recorre con una instancia los resultados de los atributos de segmentación carro.\n",
    "                if mascara_central.path == mascara_auxiliar.path: # Verifica si la instancia en la que se esta recorriendo los resultados de las mascaras de carro sea el mismo objeto en el que se hallo la mascara principal.\n",
    "                    mascaras_carro = mascara_auxiliar.masks.xy if mascara_auxiliar.masks is not None else None # Almacenara las instancias de las coordenadas en formato pixel de las mascaras segmentadas en una imagen, si no encuentra almacenara el valor de None. Es recomendable utilizar el mismo formato con el que solicito las coordenadas de la mascara principal.\n",
    "                    if mascaras_carro is not None and len(mascaras_carro) > 0: # Verifica que exista un valor valido en la variable que contiene las mascaras de segmentación.\n",
    "                        area_carro_total = procesar_mascaras(mascaras_carro, \"MASCARAS CARRO\")\n",
    "                        area_total_afectada = area_carro_total - area_base_total \n",
    "                        print(f'Área total afectada en el carro: {area_total_afectada} px^2')\n",
    "                    else:\n",
    "                        area_total_afectada = area_base_total # Al no contener mascaras de segmentación, el area total afectada pasa a ser solo el area total de la mascara principal.\n",
    "                        print(f'Área total afectada en el carro: {area_total_afectada} px^2')\n",
    "        else:\n",
    "            print(f'No se encontraron segmentaciones en la imagen! ') # Imprime por pantalla cuando el valor de la variable que contiene las mascaras de segmentación principal es None.\n",
    "                \n",
    "procesar_imagen(mascara_principal, mascara_car)\n",
    "\n",
    "print('\\nProceso terminado! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imagen 1: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\20170531_010133.jpg\n",
      "No se encontraron segmentaciones! \n",
      "\n",
      "Imagen 2: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\OIP (1).jpg\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1 area: 98.75 px\n",
      "Mascara 2 area: 230.25 px\n",
      "Mascara 3 area: 317.0 px\n",
      "Mascara 4 area: 87.4921875 px\n",
      "área total afectada según el tamaño imagen: 733.4921875 px^2\n",
      "\n",
      "Imagen 3: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\R.jpg\n",
      "No se encontraron segmentaciones! \n",
      "\n",
      "Imagen 4: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladura-en-un-coche-632c58a6e2ea5.jpg\n",
      "No se encontraron segmentaciones! \n",
      "\n",
      "Imagen 5: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\abolladuraautos-fd03b3bae67d7363172c41cc00198c51-1200x800.jpg\n",
      "No se encontraron segmentaciones! \n",
      "\n",
      "Imagen 6: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\big_ray.jpg\n",
      "No se encontraron segmentaciones! \n",
      "\n",
      "Imagen 7: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\coche-después-de-una-ruina-la-necesidad-ser-reparado-esperándola-es-demanda-de-seguro-29745503.jpg\n",
      "No se encontraron segmentaciones! \n",
      "\n",
      "Imagen 8: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayahori.webp\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1 area: 527.125 px\n",
      "área total afectada según el tamaño imagen: 527.125 px^2\n",
      "\n",
      "Imagen 9: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\rayonesauto-e68618ca9c3d6859cebc796c300aea97-1200x0.jpg\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1 area: 303.4375 px\n",
      "área total afectada según el tamaño imagen: 303.4375 px^2\n",
      "\n",
      "Imagen 10: C:\\Users\\matrix\\pruebayolo\\pruebaimagenes\\trucos-para-quitar-abolladuras-del-coche.imagen-1013x675.jpg\n",
      "MASCARAS RAYON ABOLLADURA: \n",
      "Mascara 1 area: 66108.0 px\n",
      "área total afectada según el tamaño imagen: 66108.0 px^2\n"
     ]
    }
   ],
   "source": [
    "# Función de área en formato pixel actualizada\n",
    "def calcular_area(coordenada):\n",
    "    x= coordenada[:, 0]\n",
    "    y= coordenada[:, 1]\n",
    "    return 0.5 * abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
    "\n",
    "for mascara, obj in enumerate(results):\n",
    "    mascaras_principales = obj.masks\n",
    "    print(f'\\nImagen {mascara + 1}: {obj.path}')\n",
    "    \n",
    "    if mascaras_principales is not None:\n",
    "        mascaras_principales = mascaras_principales.xy\n",
    "        area_base_total = 0.0  \n",
    "        \n",
    "        print('MASCARAS RAYON ABOLLADURA: ')\n",
    "        for id_ra, instancia_ra in enumerate(mascaras_principales):\n",
    "            coordenada_ra = calcular_area(instancia_ra)\n",
    "            area_base_total += coordenada_ra\n",
    "            print(f'Mascara {id_ra + 1} area: {coordenada_ra} px')\n",
    "\n",
    "        \n",
    "        print(f'área total afectada según el tamaño imagen: {area_base_total} px^2')\n",
    "\n",
    "\n",
    "        if mascara < len(mascara_car):\n",
    "            mascaras_car = mascara_car[mascara].masks\n",
    "            if mascaras_car is not None:\n",
    "                mascaras_car = mascaras_car.xy\n",
    "                area_carro_total = 0.0  \n",
    "                \n",
    "                print('\\nMASCARAS CARRO: ')\n",
    "                for id_car, instancia_car in enumerate(mascaras_car):\n",
    "                    coordenada_carro = calcular_area(instancia_car)\n",
    "                    area_carro_total += coordenada_carro\n",
    "                    print(f'Mascara {id_car + 1}, area: {coordenada_carro} px')\n",
    "\n",
    "                print(f'área total afectada mascara general: {area_carro_total}')\n",
    "\n",
    "                area_total = area_carro_total - area_base_total\n",
    "                print(f'Área total afectada en el carro: {area_total} px^2')\n",
    "\n",
    "    else:\n",
    "        print(f'No se encontraron segmentaciones! ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
